{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4475ee17-3127-4312-bf57-16d7bbc77397",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Camada Silver - Arquitetura Medalhão\n",
    "\n",
    "**Objetivo:** Transformações e padronizações da camada Bronze para Silver.\n",
    "\n",
    "**Operações:**\n",
    "- Renomeação de colunas (português, snake_case)\n",
    "- Padronização de tipos de dados\n",
    "- Validações de integridade referencial\n",
    "- Remoção de duplicatas\n",
    "- Aplicação de regras de negócio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f862e95-9138-44f1-9dc0-aa20d834e9cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Setup Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d69fbe89-6cbf-445b-b2bf-58f205ac24f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE CATALOG IF NOT EXISTS medalhao;\n",
    "USE CATALOG medalhao;\n",
    "\n",
    "CREATE SCHEMA IF NOT EXISTS silver;\n",
    "\n",
    "USE SCHEMA silver;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b358ab7-15ec-423d-89de-e8bb5af8768a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "\n",
    "from pyspark.sql.functions import (\n",
    "    col, trim, lower, upper, to_date, to_timestamp, datediff,\n",
    "    when, current_timestamp, row_number, lit, coalesce, expr,\n",
    "    regexp_replace, last, sequence, explode \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b035239-0955-4147-82f7-c25f7ed10751",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog_name = \"medalhao\"\n",
    "bronze_db_name = \"bronze\"\n",
    "silver_db_name = \"silver\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a5dbb92-d664-4c9b-8e68-aac4f6bbb2b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"USE CATALOG {catalog_name}\")\n",
    "spark.sql(f\"USE SCHEMA {silver_db_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61d830b5-f521-445d-8c54-55e1d1647285",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def table_exists(full_table_name: str) -> bool:\n",
    "    try:\n",
    "        _ = spark.table(full_table_name)\n",
    "        return True\n",
    "    except AnalysisException:\n",
    "        return False\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def check_bronze_tables(tables: list) -> dict:\n",
    "    results = {}\n",
    "    for t in tables:\n",
    "        full = f\"{catalog_name}.{bronze_db_name}.{t}\"\n",
    "        exists = table_exists(full)\n",
    "        cnt = None\n",
    "        if exists:\n",
    "            try:\n",
    "                cnt = spark.table(full).count()\n",
    "            except Exception:\n",
    "                cnt = None\n",
    "        results[t] = {\"exists\": exists, \"count\": cnt}\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2db42553-6b6c-4bc3-b757-9c868eba6735",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bronze_tables_needed = [\n",
    "    \"ft_consumidores\",\n",
    "    \"ft_geolocalizacao\",\n",
    "    \"ft_itens_pedidos\",\n",
    "    \"ft_pagamentos_pedidos\",\n",
    "    \"ft_avaliacoes_pedidos\",\n",
    "    \"ft_pedidos\",\n",
    "    \"ft_produtos\",\n",
    "    \"ft_vendedores\",\n",
    "    \"dm_categoria_produtos_traducao\",\n",
    "    \"dm_cotacao_dolar\"\n",
    "]\n",
    "\n",
    "status = check_bronze_tables(bronze_tables_needed)\n",
    "print(\"Status das tabelas Bronze:\")\n",
    "for k,v in status.items():\n",
    "    print(f\" - {k}: exists={v['exists']}  count={v['count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "746b7fe1-19f9-486a-9375-659129dc2f49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Funções Utilitárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "177a6924-3694-4a1e-a81d-9c5b05f13463",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def safe_table_exists(spark, full_name: str) -> bool:\n",
    "    try:\n",
    "        spark.table(full_name)\n",
    "        return True\n",
    "    except AnalysisException:\n",
    "        return False\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def safe_col(df, name):\n",
    "    return col(name) if name in df.columns else F.lit(None).cast(\"string\")\n",
    "\n",
    "\n",
    "def parse_timestamp_variants(col_expr):\n",
    "    return coalesce(\n",
    "        to_timestamp(col_expr),\n",
    "        to_timestamp(col_expr, \"yyyy-MM-dd HH:mm:ss\"),\n",
    "        to_timestamp(col_expr, \"yyyy-MM-dd'T'HH:mm:ss\"),\n",
    "        to_timestamp(col_expr, \"yyyy-MM-dd\"),\n",
    "        to_timestamp(col_expr, \"dd/MM/yyyy\"),\n",
    "        to_timestamp(col_expr, \"MM-dd-yyyy\"),\n",
    "        to_timestamp(col_expr, \"yyyy/MM/dd\")\n",
    "    )\n",
    "\n",
    "\n",
    "def log_transformation_metrics(table_name: str, metrics: dict):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"MÉTRICAS DE TRANSFORMAÇÃO: {table_name}\")\n",
    "    print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"{'-'*80}\")\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    print(f\"{'='*80}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "013bbd98-6411-45a9-a1f5-780d504f40e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Transformação: ft_consumidores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39099ebb-437a-4e6a-a53b-1bc144da62d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "src_table_consumers = f\"{catalog_name}.{bronze_db_name}.ft_consumidores\"\n",
    "tgt_table_consumers = f\"{catalog_name}.{silver_db_name}.ft_consumidores\"\n",
    "\n",
    "if not safe_table_exists(spark, src_table_consumers):\n",
    "    raise RuntimeError(f\"Tabela fonte não encontrada: {src_table_consumers}\")\n",
    "\n",
    "df_src_consumers = spark.table(src_table_consumers)\n",
    "total_before = df_src_consumers.count()\n",
    "\n",
    "print(f\"Leitura: {src_table_consumers}\")\n",
    "print(f\"Registros: {total_before}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bda9e37f-5168-4e45-bf18-1939a19602c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df_src_consumers \\\n",
    "    .withColumn(\"id_consumidor\", trim(safe_col(df_src_consumers, \"customer_id\"))) \\\n",
    "    .withColumn(\"prefixo_cep\", trim(safe_col(df_src_consumers, \"customer_zip_code_prefix\"))) \\\n",
    "    .withColumn(\"cidade\", upper(trim(safe_col(df_src_consumers, \"customer_city\")))) \\\n",
    "    .withColumn(\"estado\", upper(trim(safe_col(df_src_consumers, \"customer_state\")))) \\\n",
    "    .withColumn(\"processed_timestamp\", current_timestamp())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "924d7546-e867-4aef-9de4-6ad6c6a30852",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "null_id_count = df.filter(col(\"id_consumidor\").isNull()).count()\n",
    "null_state_count = df.filter(col(\"estado\").isNull()).count()\n",
    "\n",
    "print(f\"Nulos: id_consumidor={null_id_count}, estado={null_state_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "785066a0-3b25-44e9-8fc5-84794009a72e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dup_count = df.groupBy(\"id_consumidor\").count().filter(col(\"count\") > 1).count()\n",
    "print(f\"Duplicatas detectadas: {dup_count}\")\n",
    "\n",
    "w = Window.partitionBy(\"id_consumidor\").orderBy(\n",
    "    col(\"ingestion_timestamp\").desc_nulls_last() if \"ingestion_timestamp\" in df.columns\n",
    "    else col(\"processed_timestamp\").desc_nulls_last()\n",
    ")\n",
    "\n",
    "df_dedup = df.withColumn(\"rn\", row_number().over(w)) \\\n",
    "    .filter(col(\"rn\") == 1) \\\n",
    "    .drop(\"rn\")\n",
    "\n",
    "total_after = df_dedup.count()\n",
    "removed_by_dedupe = total_before - total_after\n",
    "\n",
    "print(f\"Após deduplicação: {total_after} ({removed_by_dedupe} removidos)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ft_consumidores — Deduplicação por Timestamp de Ingestão\n",
    "\n",
    "**O que:** Remoção de registros duplicados mantendo apenas a versão mais recente de cada `id_consumidor`.\n",
    "\n",
    "**Por quê:** A camada Bronze pode conter múltiplas versões do mesmo registro devido a reingestões ou atualizações. A Silver deve conter apenas a versão mais atual.\n",
    "\n",
    "**Como foi implementado:**\n",
    "```python\n",
    "Window.partitionBy(\"id_consumidor\").orderBy(col(\"ingestion_timestamp\").desc_nulls_last())\n",
    "df.withColumn(\"rn\", row_number().over(w)).filter(col(\"rn\") == 1)\n",
    "```\n",
    "\n",
    "**Impacto:**\n",
    "- Garantia de unicidade por PK\n",
    "- Preservação da versão mais recente (timestamp maior)\n",
    "- Remoção de histórico duplicado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "506c1216-d16f-4301-832a-fc29d24b5070",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_dedup.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(tgt_table_consumers)\n",
    "\n",
    "silver_table = spark.table(tgt_table_consumers)\n",
    "silver_count_total = silver_table.count()\n",
    "silver_dup_check = silver_table.groupBy(\"id_consumidor\").count().filter(col(\"count\") > 1).count()\n",
    "\n",
    "print(f\"Salvo em: {tgt_table_consumers}\")\n",
    "print(f\"Contagem final: {silver_count_total}\")\n",
    "print(f\"Duplicatas na Silver: {silver_dup_check}\")\n",
    "\n",
    "display(silver_table.limit(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6c8595d-a768-4baf-bdef-28129c5fc936",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Transformação: ft_pedidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16a47d0c-700a-4436-98da-41718f2cc13d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "src_table_orders = f\"{catalog_name}.{bronze_db_name}.ft_pedidos\"\n",
    "tgt_table_orders = f\"{catalog_name}.{silver_db_name}.ft_pedidos\"\n",
    "\n",
    "if not table_exists(src_table_orders):\n",
    "    raise RuntimeError(f\"Tabela fonte não encontrada: {src_table_orders}\")\n",
    "\n",
    "df_src = spark.table(src_table_orders)\n",
    "total_before = df_src.count()\n",
    "\n",
    "print(f\"Leitura: {src_table_orders}\")\n",
    "print(f\"Registros: {total_before}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a0f8ea5-2c03-4b15-8f4f-3737f593a0d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df_src \\\n",
    "    .withColumn(\"id_pedido\", trim(safe_col(df_src, \"order_id\"))) \\\n",
    "    .withColumn(\"id_consumidor\", trim(safe_col(df_src, \"customer_id\"))) \\\n",
    "    .withColumn(\"status_raw\", trim(safe_col(df_src, \"order_status\"))) \\\n",
    "    .withColumn(\"pedido_compra_timestamp_raw\", safe_col(df_src, \"order_purchase_timestamp\")) \\\n",
    "    .withColumn(\"pedido_aprovado_timestamp_raw\", safe_col(df_src, \"order_approved_at\")) \\\n",
    "    .withColumn(\"pedido_carregado_timestamp_raw\", safe_col(df_src, \"order_delivered_carrier_date\")) \\\n",
    "    .withColumn(\"pedido_entregue_timestamp_raw\", safe_col(df_src, \"order_delivered_customer_date\")) \\\n",
    "    .withColumn(\"pedido_estimativa_entrega_timestamp_raw\", safe_col(df_src, \"order_estimated_delivery_date\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17396207-d015-4c29-aa4c-11e65ed3a47f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\"pedido_compra_timestamp\", to_timestamp(col(\"pedido_compra_timestamp_raw\"))) \\\n",
    "       .withColumn(\"pedido_aprovado_timestamp\", to_timestamp(col(\"pedido_aprovado_timestamp_raw\"))) \\\n",
    "       .withColumn(\"pedido_carregado_timestamp\", to_timestamp(col(\"pedido_carregado_timestamp_raw\"))) \\\n",
    "       .withColumn(\"pedido_entregue_timestamp\", to_timestamp(col(\"pedido_entregue_timestamp_raw\"))) \\\n",
    "       .withColumn(\"pedido_estimativa_entrega_timestamp\", to_timestamp(col(\"pedido_estimativa_entrega_timestamp_raw\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c56a680-a9b6-4f73-8623-1e42306c43a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "null_id_pedido = df.filter(col(\"id_pedido\").isNull()).count()\n",
    "null_id_consumidor = df.filter(col(\"id_consumidor\").isNull()).count()\n",
    "\n",
    "print(f\"Nulos: id_pedido={null_id_pedido}, id_consumidor={null_id_consumidor}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ft_pedidos — Validação de FK id_consumidor\n",
    "\n",
    "**O que:** Validação de integridade referencial da FK `id_consumidor` contra tabela `ft_consumidores`.\n",
    "\n",
    "**Por quê:** \n",
    "- Garantir que todos os pedidos pertencem a consumidores válidos cadastrados\n",
    "- Prevenir pedidos órfãos que impediriam análises de comportamento do cliente\n",
    "- Conformidade com modelo relacional esperado\n",
    "\n",
    "**Como foi implementado:**\n",
    "- Anti-join contra `ft_consumidores` para detectar pedidos sem consumidor válido\n",
    "- Log de contagem de pedidos órfãos para auditoria\n",
    "- Decisão de manter registros órfãos (regra de negócio: rastreabilidade)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consumidores_ids = spark.table(tgt_table_consumers).select(col(\"id_consumidor\").alias(\"fk_consumer_id\"))\n",
    "\n",
    "orphan_orders = df.join(df_consumidores_ids, df.id_consumidor == df_consumidores_ids.fk_consumer_id, how=\"left_anti\")\n",
    "orphan_orders_count = orphan_orders.count()\n",
    "\n",
    "print(f\"Pedidos órfãos (consumidor inválido): {orphan_orders_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f1fbc7e-24c5-4dba-bc8b-5afb92006eff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\n",
    "    \"status\",\n",
    "    when(lower(col(\"status_raw\")) == \"delivered\", \"entregue\")\n",
    "    .when(lower(col(\"status_raw\")) == \"invoiced\", \"faturado\")\n",
    "    .when(lower(col(\"status_raw\")) == \"shipped\", \"enviado\")\n",
    "    .when(lower(col(\"status_raw\")) == \"processing\", \"em processamento\")\n",
    "    .when(lower(col(\"status_raw\")) == \"unavailable\", \"indisponível\")\n",
    "    .when(lower(col(\"status_raw\")) == \"canceled\", \"cancelado\")\n",
    "    .when(lower(col(\"status_raw\")) == \"created\", \"criado\")\n",
    "    .when(lower(col(\"status_raw\")) == \"approved\", \"aprovado\")\n",
    "    .otherwise(col(\"status_raw\"))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ft_pedidos — Tradução de Status (Padronização de Domínio)\n",
    "\n",
    "**O que:** Mapeamento de valores de status do inglês para português conforme regra de negócio.\n",
    "\n",
    "**Por quê:** Padronização de vocabulário para relatórios e análises em português. Status em inglês dificultam entendimento por usuários não técnicos.\n",
    "\n",
    "**Como foi implementado:**\n",
    "| Status Original (EN) | Status Mapeado (PT-BR) |\n",
    "|---------------------|------------------------|\n",
    "| delivered | entregue |\n",
    "| invoiced | faturado |\n",
    "| shipped | enviado |\n",
    "| processing | em processamento |\n",
    "| unavailable | indisponível |\n",
    "| canceled | cancelado |\n",
    "| created | criado |\n",
    "| approved | aprovado |\n",
    "\n",
    "**Impacto:** Valores não reconhecidos são mantidos como estão (fallback seguro)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0fd96ea-665b-4943-9eea-d32a7b965c63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\"tempo_entrega_dias\",\n",
    "    when(col(\"pedido_entregue_timestamp\").isNotNull() & col(\"pedido_compra_timestamp\").isNotNull(),\n",
    "         datediff(to_date(col(\"pedido_entregue_timestamp\")), to_date(col(\"pedido_compra_timestamp\")))\n",
    "    ).otherwise(None)\n",
    ")\n",
    "\n",
    "df = df.withColumn(\"tempo_entrega_estimado_dias\",\n",
    "    when(col(\"pedido_estimativa_entrega_timestamp\").isNotNull() & col(\"pedido_compra_timestamp\").isNotNull(),\n",
    "         datediff(to_date(col(\"pedido_estimativa_entrega_timestamp\")), to_date(col(\"pedido_compra_timestamp\")))\n",
    "    ).otherwise(None)\n",
    ")\n",
    "\n",
    "df = df.withColumn(\"diferenca_entrega_dias\",\n",
    "    when(col(\"tempo_entrega_dias\").isNotNull() & col(\"tempo_entrega_estimado_dias\").isNotNull(),\n",
    "         col(\"tempo_entrega_dias\") - col(\"tempo_entrega_estimado_dias\")\n",
    "    ).otherwise(None)\n",
    ")\n",
    "\n",
    "df = df.withColumn(\"entrega_no_prazo\",\n",
    "    when(col(\"pedido_entregue_timestamp\").isNull(), \"Não Entregue\")\n",
    "    .when(col(\"diferenca_entrega_dias\") <= 0, \"Sim\")\n",
    "    .when(col(\"diferenca_entrega_dias\") > 0, \"Não\")\n",
    "    .otherwise(None)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ft_pedidos — Métricas Derivadas de Entrega (KPIs de Negócio)\n",
    "\n",
    "**O que:** Cálculo de indicadores de performance de entrega para análise de SLA e satisfação.\n",
    "\n",
    "**Por quê:** Métricas de negócio essenciais para monitorar desempenho logístico e identificar entregas atrasadas.\n",
    "\n",
    "**Como foi implementado:**\n",
    "```python\n",
    "tempo_entrega_dias = datediff(pedido_entregue_date, pedido_compra_date)\n",
    "tempo_entrega_estimado_dias = datediff(pedido_estimativa_entrega_date, pedido_compra_date)\n",
    "diferenca_entrega_dias = tempo_entrega_dias - tempo_entrega_estimado_dias\n",
    "entrega_no_prazo = \"Sim\" se diferenca <= 0, \"Não\" se > 0, \"Não Entregue\" se NULL\n",
    "```\n",
    "\n",
    "**Impacto:**\n",
    "- Novas colunas analíticas criadas\n",
    "- Facilitam análises de SLA e performance de entrega\n",
    "- Base para dashboards de satisfação logística\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6925ba96-6787-47e9-9cc4-00257f44bd69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\"processed_timestamp\", current_timestamp())\n",
    "\n",
    "final_cols = [\n",
    "    \"id_pedido\", \"id_consumidor\", \"status\",\n",
    "    \"pedido_compra_timestamp\", \"pedido_aprovado_timestamp\", \"pedido_carregado_timestamp\",\n",
    "    \"pedido_entregue_timestamp\", \"pedido_estimativa_entrega_timestamp\",\n",
    "    \"tempo_entrega_dias\", \"tempo_entrega_estimado_dias\", \"diferenca_entrega_dias\",\n",
    "    \"entrega_no_prazo\", \"processed_timestamp\", \"ingestion_timestamp\"\n",
    "]\n",
    "\n",
    "df_final = df.select(*[c for c in final_cols if c in df.columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45bea176-e9cf-4cb9-a2e9-83dd5fd6af83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_final.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(tgt_table_orders)\n",
    "\n",
    "silver_table = spark.table(tgt_table_orders)\n",
    "silver_count_total = silver_table.count()\n",
    "silver_dup_check = silver_table.groupBy(\"id_pedido\").count().filter(col(\"count\") > 1).count()\n",
    "\n",
    "print(f\"Salvo em: {tgt_table_orders}\")\n",
    "print(f\"Contagem final: {silver_count_total}\")\n",
    "print(f\"Duplicatas na Silver: {silver_dup_check}\")\n",
    "\n",
    "display(silver_table.limit(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbb59526-75f1-4db5-9f8d-65fce91bb601",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Transformação: ft_itens_pedidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0b98563-c840-423f-a8cd-51cc5acf6ed4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "src_table_item_orders = f\"{catalog_name}.{bronze_db_name}.ft_itens_pedidos\"\n",
    "tgt_table_item_orders = f\"{catalog_name}.{silver_db_name}.ft_itens_pedidos\"\n",
    "\n",
    "if not safe_table_exists(spark, src_table_item_orders):\n",
    "    raise RuntimeError(f\"Tabela fonte não encontrada: {src_table_item_orders}\")\n",
    "\n",
    "df_src = spark.table(src_table_item_orders)\n",
    "before_count = df_src.count()\n",
    "\n",
    "print(f\"Leitura: {src_table_item_orders}\")\n",
    "print(f\"Registros: {before_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17bb02b5-b18a-4eed-93fb-8890b75ccbd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df_src \\\n",
    "    .withColumn(\"id_pedido\", trim(safe_col(df_src, \"order_id\"))) \\\n",
    "    .withColumn(\"id_item\", trim(safe_col(df_src, \"order_item_id\"))) \\\n",
    "    .withColumn(\"id_produto\", trim(safe_col(df_src, \"product_id\"))) \\\n",
    "    .withColumn(\"id_vendedor\", trim(safe_col(df_src, \"seller_id\"))) \\\n",
    "    .withColumn(\"preco_brl_raw\", safe_col(df_src, \"price\")) \\\n",
    "    .withColumn(\"preco_frete_raw\", safe_col(df_src, \"freight_value\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ft_itens_pedidos — Conversão de Tipos Monetários para DecimalType(12,2)\n",
    "\n",
    "**O que:** Conversão de valores monetários (`preco_brl`, `preco_frete`) de DoubleType para **DecimalType(12,2)**.\n",
    "\n",
    "**Por quê:** \n",
    "- **DoubleType** causa erros de arredondamento em operações financeiras (ex.: 0.1 + 0.2 ≠ 0.3)\n",
    "- **DecimalType(12,2)** garante precisão exata com 2 casas decimais, conforme padrões contábeis\n",
    "- Especificação exige DecimalType(12,2) para TODOS os valores monetários\n",
    "\n",
    "**Como foi implementado:**\n",
    "- Substituição de `.cast(DoubleType())` por `.cast(DecimalType(12,2))`\n",
    "- Mantém tratamento de NULL e limpeza de formatação (vírgulas → pontos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9277763c-d7f6-4e7f-8c47-e01a116edee3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\"preco_brl\",\n",
    "    when(col(\"preco_brl_raw\").isNull(), None)\n",
    "    .otherwise(F.regexp_replace(col(\"preco_brl_raw\").cast(\"string\"), \",\", \".\").cast(DecimalType(12,2)))\n",
    ")\n",
    "\n",
    "df = df.withColumn(\"preco_frete\",\n",
    "    when(col(\"preco_frete_raw\").isNull(), None)\n",
    "    .otherwise(F.regexp_replace(col(\"preco_frete_raw\").cast(\"string\"), \",\", \".\").cast(DecimalType(12,2)))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f5b2e83-3abc-4e6a-8300-bf51cfe1f14b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "null_produto = df.filter(col(\"id_produto\").isNull()).count()\n",
    "null_vendedor = df.filter(col(\"id_vendedor\").isNull()).count()\n",
    "\n",
    "print(f\"Nulos: id_produto={null_produto}, id_vendedor={null_vendedor}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ft_itens_pedidos — Validação de Integridade Referencial (FKs)\n",
    "\n",
    "**O que:** Validação de chaves estrangeiras para `id_produto` e `id_vendedor` contra tabelas Silver correspondentes.\n",
    "\n",
    "**Por quê:** \n",
    "- Garantir que todos os itens referenciam produtos e vendedores válidos\n",
    "- Prevenir órfãos que quebrariam JOINs em análises posteriores\n",
    "- Conformidade com especificação de integridade referencial\n",
    "\n",
    "**Como foi implementado:**\n",
    "- Anti-join contra `ft_produtos` e `ft_vendedores` para identificar registros órfãos\n",
    "- Contagem e log de itens com FKs inválidas para auditoria\n",
    "- Registros órfãos são identificados mas mantidos (decisão de negócio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_table_products = f\"{catalog_name}.{silver_db_name}.ft_produtos\"\n",
    "tgt_table_sellers = f\"{catalog_name}.{silver_db_name}.ft_vendedores\"\n",
    "\n",
    "df_produtos_ids = spark.table(tgt_table_products).select(col(\"id_produto\").alias(\"fk_product_id\"))\n",
    "df_vendedores_ids = spark.table(tgt_table_sellers).select(col(\"id_vendedor\").alias(\"fk_seller_id\"))\n",
    "\n",
    "orphan_items_prod = df.join(df_produtos_ids, df.id_produto == df_produtos_ids.fk_product_id, how=\"left_anti\")\n",
    "orphan_items_seller = df.join(df_vendedores_ids, df.id_vendedor == df_vendedores_ids.fk_seller_id, how=\"left_anti\")\n",
    "\n",
    "orphan_prod_count = orphan_items_prod.count()\n",
    "orphan_seller_count = orphan_items_seller.count()\n",
    "\n",
    "print(f\"Itens órfãos (produto inválido): {orphan_prod_count}\")\n",
    "print(f\"Itens órfãos (vendedor inválido): {orphan_seller_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d67642f-657e-49dd-9128-5d8285912978",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\"processed_timestamp\", current_timestamp())\n",
    "\n",
    "final_cols = [\n",
    "    \"id_pedido\", \"id_item\", \"id_produto\", \"id_vendedor\",\n",
    "    \"preco_brl\", \"preco_frete\", \"processed_timestamp\", \"ingestion_timestamp\"\n",
    "]\n",
    "\n",
    "df_final = df.select(*[c for c in final_cols if c in df.columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db55e321-b319-4fec-87d5-61a968cbfeea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_final.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(tgt_table_item_orders)\n",
    "\n",
    "silver_table = spark.table(tgt_table_item_orders)\n",
    "after_count = silver_table.count()\n",
    "missing_keys = silver_table.filter(col(\"id_pedido\").isNull() | col(\"id_item\").isNull()).count()\n",
    "\n",
    "print(f\"Salvo em: {tgt_table_item_orders}\")\n",
    "print(f\"Contagem final: {after_count}\")\n",
    "print(f\"Chaves ausentes: {missing_keys}\")\n",
    "\n",
    "display(silver_table.limit(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d12fc40-98cd-4c5b-98e0-7c77a87e92a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Transformação: ft_pagamentos_pedidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42845196-b599-465e-85b6-536713d4fe60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "src_table_payments = f\"{catalog_name}.{bronze_db_name}.ft_pagamentos_pedidos\"\n",
    "tgt_table_payments = f\"{catalog_name}.{silver_db_name}.ft_pagamentos_pedidos\"\n",
    "\n",
    "if not safe_table_exists(spark, src_table_payments):\n",
    "    raise RuntimeError(f\"Tabela fonte não encontrada: {src_table_payments}\")\n",
    "\n",
    "df_src = spark.table(src_table_payments)\n",
    "before_count = df_src.count()\n",
    "\n",
    "print(f\"Leitura: {src_table_payments}\")\n",
    "print(f\"Registros: {before_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f955fcd5-9211-488f-9c6d-10da8881ea46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df_src \\\n",
    "    .withColumn(\"id_pedido\", trim(safe_col(df_src, \"order_id\"))) \\\n",
    "    .withColumn(\"codigo_pagamento\", safe_col(df_src, \"payment_sequential\").cast(IntegerType())) \\\n",
    "    .withColumn(\"forma_pagamento_raw\", trim(safe_col(df_src, \"payment_type\"))) \\\n",
    "    .withColumn(\"parcelas\", when(safe_col(df_src, \"payment_installments\").isNull(), 0)\n",
    "                .otherwise(safe_col(df_src, \"payment_installments\").cast(IntegerType()))) \\\n",
    "    .withColumn(\"valor_pagamento_raw\", safe_col(df_src, \"payment_value\"))\n",
    "\n",
    "df = df.withColumn(\"forma_pagamento\",\n",
    "    when(lower(col(\"forma_pagamento_raw\")) == \"credit_card\", \"Cartão de Crédito\")\n",
    "    .when(lower(col(\"forma_pagamento_raw\")) == \"boleto\", \"Boleto\")\n",
    "    .when(lower(col(\"forma_pagamento_raw\")) == \"voucher\", \"Voucher\")\n",
    "    .when(lower(col(\"forma_pagamento_raw\")) == \"debit_card\", \"Cartão de Débito\")\n",
    "    .when(col(\"forma_pagamento_raw\").isNull(), \"Não Informado\")\n",
    "    .otherwise(\"Outro\")\n",
    ")\n",
    "\n",
    "df = df.withColumn(\"valor_pagamento\",\n",
    "    when(col(\"valor_pagamento_raw\").isNotNull(),\n",
    "         F.regexp_replace(col(\"valor_pagamento_raw\").cast(\"string\"), \",\", \".\").cast(DecimalType(12,2)))\n",
    "    .otherwise(None)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ft_pagamentos_pedidos — Padronização de Tipos Monetários e Domínio\n",
    "\n",
    "**O que:** Conversão de valores monetários para `DecimalType(12,2)` e tradução de formas de pagamento.\n",
    "\n",
    "**Por quê:** \n",
    "- **DecimalType**: Previne erros de arredondamento em cálculos financeiros (problema conhecido de DoubleType)\n",
    "- **Tradução**: Padronização de vocabulário para português\n",
    "\n",
    "**Como foi implementado:**\n",
    "| Campo | Transformação |\n",
    "|-------|---------------|\n",
    "| `valor_pagamento` | String → DecimalType(12,2) |\n",
    "| `parcelas` | String/NULL → IntegerType (0 se NULL) |\n",
    "| `forma_pagamento` | credit_card → Cartão de Crédito, etc. |\n",
    "\n",
    "**Impacto:**\n",
    "- Precisão decimal garantida em cálculos financeiros\n",
    "- Conformidade com padrões contábeis\n",
    "- Vocabulário padronizado em português\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a048972-b196-4283-8c14-a283c6e224eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "missing_id_pedido = df.filter(col(\"id_pedido\").isNull()).count()\n",
    "print(f\"Nulos: id_pedido={missing_id_pedido}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ft_pagamentos_pedidos — Validação FK e Deduplicação\n",
    "\n",
    "**O que:** Validação de FK `id_pedido` e deduplicação por chave composta `(id_pedido, codigo_pagamento)`.\n",
    "\n",
    "**Por quê:** \n",
    "- FK validation garante que pagamentos referenciam pedidos válidos\n",
    "- Deduplicação previne contagem duplicada de valores financeiros (inflação de totais)\n",
    "- PK composta assegura unicidade de cada transação de pagamento\n",
    "\n",
    "**Como foi implementado:**\n",
    "- Anti-join contra `ft_pedidos` para detectar pagamentos órfãos\n",
    "- Window function com `row_number()` particionado por `(id_pedido, codigo_pagamento)`\n",
    "- Ordenação por `ingestion_timestamp` DESC para manter registro mais recente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pedidos_ids = spark.table(tgt_table_orders).select(col(\"id_pedido\").alias(\"fk_order_id\"))\n",
    "\n",
    "orphan_payments = df.join(df_pedidos_ids, df.id_pedido == df_pedidos_ids.fk_order_id, how=\"left_anti\")\n",
    "orphan_payments_count = orphan_payments.count()\n",
    "\n",
    "print(f\"Pagamentos órfãos (pedido inválido): {orphan_payments_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_count = df.groupBy(\"id_pedido\", \"codigo_pagamento\").count().filter(col(\"count\") > 1).count()\n",
    "print(f\"Duplicatas detectadas (id_pedido, codigo_pagamento): {dup_count}\")\n",
    "\n",
    "w = Window.partitionBy(\"id_pedido\", \"codigo_pagamento\").orderBy(\n",
    "    col(\"ingestion_timestamp\").desc_nulls_last() if \"ingestion_timestamp\" in df.columns\n",
    "    else col(\"processed_timestamp\").desc_nulls_last()\n",
    ")\n",
    "\n",
    "df = df.withColumn(\"rn\", row_number().over(w)) \\\n",
    "    .filter(col(\"rn\") == 1) \\\n",
    "    .drop(\"rn\")\n",
    "\n",
    "total_after_dedup = df.count()\n",
    "removed_by_dedup = before_count - total_after_dedup\n",
    "\n",
    "print(f\"Após deduplicação: {total_after_dedup} ({removed_by_dedup} removidos)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"processed_timestamp\", current_timestamp())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffd4f7ee-55c0-44d6-afec-5121e1aac36c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "final_cols = [\n",
    "    \"id_pedido\", \"codigo_pagamento\", \"forma_pagamento\",\n",
    "    \"parcelas\", \"valor_pagamento\", \"processed_timestamp\", \"ingestion_timestamp\"\n",
    "]\n",
    "\n",
    "df_final = df.select(*[c for c in final_cols if c in df.columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c8f4d4b-9aa8-4063-bf9d-90f7c51b2753",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_final.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(tgt_table_payments)\n",
    "\n",
    "silver_table = spark.table(tgt_table_payments)\n",
    "after_count = silver_table.count()\n",
    "records_with_missing_pk = silver_table.filter(col(\"id_pedido\").isNull()).count()\n",
    "\n",
    "print(f\"Salvo em: {tgt_table_payments}\")\n",
    "print(f\"Contagem final: {after_count}\")\n",
    "print(f\"PKs ausentes: {records_with_missing_pk}\")\n",
    "\n",
    "display(silver_table.limit(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0de1dee9-6e77-41ec-870a-cb1dc3877959",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Transformação: ft_avaliacoes_pedidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ft_avaliacoes_pedidos — Validação de Integridade Referencial (FK)\n",
    "\n",
    "**O que:** Validação de chaves estrangeiras para garantir que todos os registros de avaliações referenciem pedidos válidos existentes na tabela `ft_pedidos`.\n",
    "\n",
    "**Como foi implementado:**\n",
    "- `left_anti join` com tabela de pedidos para identificar `id_pedido` inválidos (nulos ou não existentes)\n",
    "- Registros com FK inválida são marcados e removidos antes da escrita na Silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78cbeddd-e584-4657-b044-ff93de9c5b3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "src_table_reviews = f\"{catalog_name}.{bronze_db_name}.ft_avaliacoes_pedidos\"\n",
    "tgt_table_reviews = f\"{catalog_name}.{silver_db_name}.ft_avaliacoes_pedidos\"\n",
    "src_table_orders = f\"{catalog_name}.{bronze_db_name}.ft_pedidos\"\n",
    "\n",
    "if not safe_table_exists(spark, src_table_reviews):\n",
    "    raise RuntimeError(f\"Tabela fonte não encontrada: {src_table_reviews}\")\n",
    "if not safe_table_exists(spark, src_table_orders):\n",
    "    raise RuntimeError(f\"Tabela de pedidos não encontrada: {src_table_orders}\")\n",
    "\n",
    "df_src = spark.table(src_table_reviews)\n",
    "df_pedidos_ids = spark.table(src_table_orders).select(col(\"order_id\").alias(\"fk_order_id\")).distinct()\n",
    "\n",
    "total_before = df_src.count()\n",
    "print(f\"Leitura: {src_table_reviews}\")\n",
    "print(f\"Registros: {total_before}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0abef530-0a06-44d4-bf27-8d57105f286c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df_src \\\n",
    "    .withColumn(\"id_avaliacao\", trim(safe_col(df_src, \"review_id\"))) \\\n",
    "    .withColumn(\"id_pedido\", trim(safe_col(df_src, \"order_id\"))) \\\n",
    "    .withColumn(\"avaliacao_raw\", safe_col(df_src, \"review_score\")) \\\n",
    "    .withColumn(\"titulo_comentario\", safe_col(df_src, \"review_comment_title\")) \\\n",
    "    .withColumn(\"comentario\", safe_col(df_src, \"review_comment_message\")) \\\n",
    "    .withColumn(\"raw_data_comentario\", safe_col(df_src, \"review_creation_date\")) \\\n",
    "    .withColumn(\"raw_data_resposta\", safe_col(df_src, \"review_answer_timestamp\"))\n",
    "\n",
    "df = df.withColumn(\"avaliacao\", expr(\"try_cast(avaliacao_raw as integer)\")).drop(\"avaliacao_raw\")\n",
    "\n",
    "df = df.withColumn(\"id_pedido\", when(trim(col(\"id_pedido\")) == \"\", None).otherwise(col(\"id_pedido\"))) \\\n",
    "       .withColumn(\"id_avaliacao\", when(trim(col(\"id_avaliacao\")) == \"\", None).otherwise(col(\"id_avaliacao\")))\n",
    "\n",
    "df = df.withColumn(\"data_comentario_ts\", expr(\"try_cast(raw_data_comentario as timestamp)\")) \\\n",
    "       .withColumn(\"data_resposta_ts\", expr(\"try_cast(raw_data_resposta as timestamp)\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ft_avaliacoes_pedidos — Correção de Contaminação da Coluna `avaliacao`\n",
    "\n",
    "**O que:** Tratamento de valores contaminados na coluna `review_score` que contém timestamps em vez de scores numéricos (1-5).\n",
    "\n",
    "**Como foi implementado:**\n",
    "- Uso de `try_cast(review_score as integer)` para conversão segura sem erros\n",
    "- Valores não conversíveis (timestamps) resultam em `NULL`\n",
    "- Filtragem posterior preserva apenas scores válidos entre 1 e 5\n",
    "\n",
    "**Impacto:**\n",
    "| Aspecto | Antes | Depois |\n",
    "|---------|-------|--------|\n",
    "| Tipo da coluna | String contaminada | IntegerType limpo |\n",
    "| Valores inválidos | Timestamps misturados | Removidos (NULL) |\n",
    "| Validação | Nenhuma | Apenas 1-5 aceitos |\n",
    "| Schema | Conflito | `overwriteSchema=true` |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccc5591a-c8ce-41ba-88aa-353c6e823314",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_validacao = df.filter(col(\"id_avaliacao\").isNotNull())\n",
    "now_ts = F.current_timestamp()\n",
    "\n",
    "df_ids_null = df_validacao.filter(col(\"id_pedido\").isNull()).select(\"id_avaliacao\").distinct()\n",
    "df_ids_orfaos = df_validacao.join(df_pedidos_ids, df_validacao.id_pedido == df_pedidos_ids.fk_order_id, how=\"left_anti\") \\\n",
    "    .select(\"id_avaliacao\").distinct()\n",
    "\n",
    "invalid_id_df = df_ids_null.union(df_ids_orfaos).distinct()\n",
    "invalid_id_count = invalid_id_df.count()\n",
    "\n",
    "print(f\"Registros com FK inválida: {invalid_id_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58c47afe-ab39-46e7-a731-9f379ca4f405",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_dates_invalid_1 = df_validacao.filter(\n",
    "    (col(\"data_comentario_ts\").isNull()) | (col(\"data_comentario_ts\") > now_ts)\n",
    ").select(\"id_avaliacao\").distinct()\n",
    "\n",
    "df_dates_invalid_2 = df_validacao.filter(\n",
    "    (col(\"raw_data_resposta\").isNotNull()) &\n",
    "    ((col(\"data_resposta_ts\").isNull()) | (col(\"data_resposta_ts\") > now_ts) | (col(\"data_resposta_ts\") < col(\"data_comentario_ts\")))\n",
    ").select(\"id_avaliacao\").distinct()\n",
    "\n",
    "invalid_dates_union = df_dates_invalid_1.union(df_dates_invalid_2).distinct()\n",
    "invalid_date_count = invalid_dates_union.count()\n",
    "\n",
    "print(f\"Registros com datas inválidas: {invalid_date_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ft_avaliacoes_pedidos — Validação de Consistência Temporal\n",
    "\n",
    "**O que:** Validação lógica de datas para garantir consistência temporal entre criação e resposta de avaliações.\n",
    "\n",
    "**Como foi implementado:**\n",
    "- `data_comentario` não pode ser NULL nem futura (> `current_timestamp`)\n",
    "- `data_resposta` (quando presente) não pode ser futura nem anterior a `data_comentario`\n",
    "- Uso de `try_cast` para conversão segura de timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25f62733-9b68-49d3-b2df-aa8ecff27135",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "to_remove_union = invalid_id_df.union(invalid_dates_union).distinct()\n",
    "removed_total = to_remove_union.count()\n",
    "\n",
    "df_valid = df.join(to_remove_union, on=\"id_avaliacao\", how=\"left_anti\") if removed_total > 0 else df\n",
    "total_after = df_valid.count()\n",
    "\n",
    "print(f\"Total removidos por validação: {removed_total}\")\n",
    "print(f\"Total após validação: {total_after}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1988e20-7e18-46c9-a82a-f1e6a1002dd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_out = df_valid \\\n",
    "    .withColumnRenamed(\"data_comentario_ts\", \"data_comentario\") \\\n",
    "    .withColumnRenamed(\"data_resposta_ts\", \"data_resposta\") \\\n",
    "    .withColumn(\"processed_timestamp\", current_timestamp())\n",
    "\n",
    "final_cols = [\n",
    "    \"id_avaliacao\", \"id_pedido\", \"avaliacao\", \"titulo_comentario\", \"comentario\",\n",
    "    \"data_comentario\", \"data_resposta\", \"processed_timestamp\", \"ingestion_timestamp\"\n",
    "]\n",
    "\n",
    "df_final = df_out.select(*[c for c in final_cols if c in df_out.columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d94d60a-d633-46ca-a5cd-43b18a3b9b4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "total_antes_limpeza = df_final.count()\n",
    "\n",
    "df_final = df_final.withColumn(\"avaliacao_str\", col(\"avaliacao\").cast(\"string\"))\n",
    "df_final = df_final.withColumn(\"avaliacao_valida\", expr(\"try_cast(avaliacao_str as int)\"))\n",
    "\n",
    "df_final = df_final.filter(\n",
    "    (col(\"avaliacao_valida\").isNotNull()) &\n",
    "    (col(\"avaliacao_valida\") >= 1) &\n",
    "    (col(\"avaliacao_valida\") <= 5)\n",
    ")\n",
    "\n",
    "df_final = df_final.withColumn(\"avaliacao\", col(\"avaliacao_valida\")).drop(\"avaliacao_str\", \"avaliacao_valida\")\n",
    "\n",
    "total_apos_limpeza = df_final.count()\n",
    "registros_removidos_avaliacao = total_antes_limpeza - total_apos_limpeza\n",
    "\n",
    "print(f\"Antes limpeza scores: {total_antes_limpeza}\")\n",
    "print(f\"Após limpeza scores: {total_apos_limpeza}\")\n",
    "print(f\"Removidos (scores inválidos): {registros_removidos_avaliacao}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ft_avaliacoes_pedidos — Filtro de Scores Válido\n",
    "\n",
    "**O que:** Aplicação de regra de negócio que aceita apenas avaliações com scores entre 1 e 5 (escala padrão de satisfação).\n",
    "\n",
    "**Como foi implementado:**\n",
    "```python\n",
    "# Conversão segura com try_cast\n",
    "df.withColumn(\"avaliacao_valida\", expr(\"try_cast(avaliacao_str as int)\"))\n",
    "\n",
    "# Filtro de intervalo válido\n",
    ".filter((col(\"avaliacao_valida\") >= 1) & (col(\"avaliacao_valida\") <= 5))\n",
    "```\n",
    "\n",
    "**Impacto:**\n",
    "- Registros removidos: avaliações com scores NULL, < 1 ou > 5\n",
    "- Coluna final: `IntegerType` com valores garantidamente entre 1-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d19ce0c-33da-4767-8ee7-18a71229222d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_final.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(tgt_table_reviews)\n",
    "\n",
    "silver_table = spark.table(tgt_table_reviews)\n",
    "saved_count = silver_table.count()\n",
    "silver_dup_check = silver_table.groupBy(\"id_avaliacao\").count().filter(col(\"count\") > 1).count()\n",
    "\n",
    "print(f\"Salvo em: {tgt_table_reviews}\")\n",
    "print(f\"Contagem final: {saved_count}\")\n",
    "print(f\"Duplicatas na Silver: {silver_dup_check}\")\n",
    "\n",
    "display(silver_table.limit(5))\n",
    "display(silver_table.groupBy(\"avaliacao\").count().orderBy(\"avaliacao\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65e264bc-7627-40fc-a1f6-1e997e289e84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Transformação: ft_produtos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d3f54d8-2d66-412b-a898-be9260848706",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "src_table_products = f\"{catalog_name}.{bronze_db_name}.ft_produtos\"\n",
    "tgt_table_products = f\"{catalog_name}.{silver_db_name}.ft_produtos\"\n",
    "\n",
    "if not safe_table_exists(spark, src_table_products):\n",
    "    raise RuntimeError(f\"Tabela fonte não encontrada: {src_table_products}\")\n",
    "\n",
    "df_src = spark.table(src_table_products)\n",
    "total_before = df_src.count()\n",
    "\n",
    "print(f\"Leitura: {src_table_products}\")\n",
    "print(f\"Registros: {total_before}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "953d5ae8-4fe9-4295-8177-dd0697a694f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_double(col_expr):\n",
    "    return when(col_expr.isNull(), None).otherwise(\n",
    "        F.regexp_replace(col_expr.cast(\"string\"), \",\", \".\").cast(DoubleType())\n",
    "    )\n",
    "\n",
    "df = df_src \\\n",
    "    .withColumn(\"id_produto\", trim(safe_col(df_src, \"product_id\"))) \\\n",
    "    .withColumn(\"categoria_produto\", when(safe_col(df_src, \"product_category_name\").isNotNull(),\n",
    "                trim(safe_col(df_src, \"product_category_name\"))).otherwise(None)) \\\n",
    "    .withColumn(\"peso_produto_gramas\", convert_to_double(safe_col(df_src, \"product_weight_g\"))) \\\n",
    "    .withColumn(\"comprimento_centimetros\", convert_to_double(safe_col(df_src, \"product_length_cm\"))) \\\n",
    "    .withColumn(\"altura_centimetros\", convert_to_double(safe_col(df_src, \"product_height_cm\"))) \\\n",
    "    .withColumn(\"largura_centimetros\", convert_to_double(safe_col(df_src, \"product_width_cm\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "376505a7-1601-4a9b-9882-9969f97a39e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "w = Window.partitionBy(\"id_produto\").orderBy(\n",
    "    col(\"ingestion_timestamp\").desc_nulls_last() if \"ingestion_timestamp\" in df.columns\n",
    "    else col(\"processed_timestamp\").desc_nulls_last()\n",
    ")\n",
    "\n",
    "df_dedup = df.withColumn(\"rn\", row_number().over(w)).filter(col(\"rn\") == 1).drop(\"rn\")\n",
    "total_after = df_dedup.count()\n",
    "removed_by_dedupe = total_before - total_after\n",
    "\n",
    "print(f\"Após deduplicação: {total_after} ({removed_by_dedupe} removidos)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e070928-8f2a-41b2-8e2c-633554e84e63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_final = df_dedup.withColumn(\"processed_timestamp\", current_timestamp())\n",
    "\n",
    "final_cols = [\n",
    "    \"id_produto\", \"categoria_produto\", \"peso_produto_gramas\",\n",
    "    \"comprimento_centimetros\", \"altura_centimetros\", \"largura_centimetros\",\n",
    "    \"processed_timestamp\", \"ingestion_timestamp\"\n",
    "]\n",
    "\n",
    "df_final = df_final.select(*[c for c in final_cols if c in df_final.columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "682c7c1d-6a26-4a32-bab5-e9cedae7c508",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_final.write.format(\"delta\").mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(tgt_table_products)\n",
    "\n",
    "silver_table = spark.table(tgt_table_products)\n",
    "saved_count = silver_table.count()\n",
    "missing_ids = silver_table.filter(col(\"id_produto\").isNull()).count()\n",
    "\n",
    "print(f\"Salvo em: {tgt_table_products}\")\n",
    "print(f\"Contagem final: {saved_count}\")\n",
    "if missing_ids > 0:\n",
    "    print(f\"PKs ausentes: {missing_ids}\")\n",
    "\n",
    "display(silver_table.limit(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "065f2afe-214d-47df-a775-ea0efa0d0044",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Transformação: ft_vendedores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1db5ea78-abd2-4d52-9e50-3d1624627fc1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "src_table_sellers = f\"{catalog_name}.{bronze_db_name}.ft_vendedores\"\n",
    "tgt_table_sellers = f\"{catalog_name}.{silver_db_name}.ft_vendedores\"\n",
    "\n",
    "if not safe_table_exists(spark, src_table_sellers):\n",
    "    raise RuntimeError(f\"Tabela fonte não encontrada: {src_table_sellers}\")\n",
    "\n",
    "df_src = spark.table(src_table_sellers)\n",
    "total_before = df_src.count()\n",
    "\n",
    "print(f\"Leitura: {src_table_sellers}\")\n",
    "print(f\"Registros: {total_before}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81971f47-3ff8-475a-8ac9-4cfef9b11017",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df_src \\\n",
    "    .withColumn(\"id_vendedor\", trim(safe_col(df_src, \"seller_id\")).cast(StringType())) \\\n",
    "    .withColumn(\"prefixo_cep\", trim(safe_col(df_src, \"seller_zip_code_prefix\")).cast(StringType())) \\\n",
    "    .withColumn(\"cidade\", upper(trim(safe_col(df_src, \"seller_city\")))) \\\n",
    "    .withColumn(\"estado\", upper(trim(safe_col(df_src, \"seller_state\")))) \\\n",
    "    .withColumn(\"processed_timestamp\", current_timestamp())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc338390-3619-4744-9018-04787d71db4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "w = Window.partitionBy(\"id_vendedor\").orderBy(\n",
    "    col(\"ingestion_timestamp\").desc_nulls_last() if \"ingestion_timestamp\" in df.columns\n",
    "    else col(\"processed_timestamp\").desc_nulls_last()\n",
    ")\n",
    "\n",
    "df_dedup = df.withColumn(\"rn\", row_number().over(w)).filter(col(\"rn\") == 1).drop(\"rn\")\n",
    "total_after = df_dedup.count()\n",
    "removed_by_dedupe = total_before - total_after\n",
    "\n",
    "print(f\"Após deduplicação: {total_after} ({removed_by_dedupe} removidos)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81ef0eb3-b92b-4e20-8fec-d17faf54070e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "final_cols = [\n",
    "    \"id_vendedor\", \"prefixo_cep\", \"cidade\", \"estado\",\n",
    "    \"processed_timestamp\", \"ingestion_timestamp\"\n",
    "]\n",
    "\n",
    "df_final = df_dedup.select(*[c for c in final_cols if c in df_dedup.columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "794e336a-7412-4811-b35f-1995024c635f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_final.write.format(\"delta\").mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(tgt_table_sellers)\n",
    "\n",
    "silver_table = spark.table(tgt_table_sellers)\n",
    "saved_count = silver_table.count()\n",
    "missing_ids_silver = silver_table.filter(col(\"id_vendedor\").isNull()).count()\n",
    "\n",
    "print(f\"Salvo em: {tgt_table_sellers}\")\n",
    "print(f\"Contagem final: {saved_count}\")\n",
    "if missing_ids_silver > 0:\n",
    "    print(f\"PKs ausentes: {missing_ids_silver}\")\n",
    "\n",
    "display(silver_table.limit(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74ad278b-0a73-424a-8848-7bce31114172",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Transformação: dm_cotacao_dolar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30dfda9d-699a-4b01-8536-68856aa73156",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "src_table_cotacoes = f\"{catalog_name}.{bronze_db_name}.dm_cotacao_dolar\"\n",
    "tgt_table_cotacoes = f\"{catalog_name}.{silver_db_name}.dm_cotacao_dolar\"\n",
    "\n",
    "if not safe_table_exists(spark, src_table_cotacoes):\n",
    "    raise RuntimeError(f\"Tabela fonte não encontrada: {src_table_cotacoes}\")\n",
    "\n",
    "df_raw = spark.table(src_table_cotacoes)\n",
    "total_before = df_raw.count()\n",
    "\n",
    "print(f\"Leitura: {src_table_cotacoes}\")\n",
    "print(f\"Registros: {total_before}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "937c2929-479d-473a-9153-28403c5b8184",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df_raw.withColumn(\"data\", to_date(to_timestamp(col(\"dataHoraCotacao\"))))\n",
    "df = df.withColumn(\"cotacao_dolar\", regexp_replace(col(\"purchase_rate\").cast(\"string\"), \",\", \".\").cast(\"double\"))\n",
    "\n",
    "df_rates = df.select(\"data\", \"cotacao_dolar\", \"ingestion_timestamp\") \\\n",
    "    .where(col(\"data\").isNotNull()) \\\n",
    "    .dropDuplicates([\"data\"]) \\\n",
    "    .orderBy(\"data\")\n",
    "\n",
    "min_max = df_rates.agg(F.min(col(\"data\")).alias(\"min_data\"), F.max(col(\"data\")).alias(\"max_data\")).collect()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6cc7407-7414-457f-9a0c-01072516de75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if min_max['min_data'] is None:\n",
    "    print(\"Não há datas válidas.\")\n",
    "else:\n",
    "    min_date = min_max['min_data']\n",
    "    max_date = min_max['max_data']\n",
    "\n",
    "    df_date_sequence = spark.createDataFrame([(min_date, max_date)], [\"min_data\", \"max_data\"]) \\\n",
    "        .withColumn(\"data_seq\", explode(sequence(col(\"min_data\"), col(\"max_data\"), F.expr(\"interval 1 day\")))) \\\n",
    "        .select(col(\"data_seq\"))\n",
    "\n",
    "    df_all_dates = df_date_sequence.join(df_rates, col(\"data_seq\") == df_rates.data, \"left\")\n",
    "\n",
    "    w = Window.orderBy(\"data_seq\")\n",
    "\n",
    "    df_final_cotacao = df_all_dates \\\n",
    "        .withColumn(\"cotacao_dolar\", last(col(\"cotacao_dolar\"), ignorenulls=True).over(w)) \\\n",
    "        .withColumn(\"ingestion_timestamp\", last(col(\"ingestion_timestamp\"), ignorenulls=True).over(w)) \\\n",
    "        .select(\n",
    "            col(\"data_seq\").alias(\"data\"),\n",
    "            col(\"data_seq\").cast(\"timestamp\").alias(\"data_ts\"),\n",
    "            col(\"cotacao_dolar\"),\n",
    "            F.current_timestamp().alias(\"processed_timestamp\"),\n",
    "            col(\"ingestion_timestamp\")\n",
    "        ) \\\n",
    "        .filter(col(\"cotacao_dolar\").isNotNull())\n",
    "\n",
    "    print(f\"Total após forward fill: {df_final_cotacao.count()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dm_cotacao_dolar — Forward Fill para Lacunas de Datas\n",
    "\n",
    "**O que:** Preenchimento de cotações ausentes (finais de semana/feriados) com última cotação conhecida.\n",
    "\n",
    "**Por quê:** O Banco Central não publica cotações em dias não úteis. Para análises financeiras, é necessário ter valores para todos os dias usando a última cotação disponível.\n",
    "\n",
    "**Como foi implementado:**\n",
    "- Geração de sequência completa de datas (min → max)\n",
    "- Left join com dados existentes\n",
    "- Window function `last(..., ignorenulls=True)` para propagar última cotação válida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b0f7ea1-a462-41cc-8fc5-dde74c5835e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_final_cotacao.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(tgt_table_cotacoes)\n",
    "\n",
    "print(f\"Salvo em: {tgt_table_cotacoes}\")\n",
    "display(spark.table(tgt_table_cotacoes).select(\"data\", \"data_ts\", \"cotacao_dolar\", \"processed_timestamp\").orderBy(\"data\").limit(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validar_tabela_silver(tabela_nome: str):\n",
    "    full_name = f\"{catalog_name}.{silver_db_name}.{tabela_nome}\"\n",
    "    \n",
    "    if not safe_table_exists(spark, full_name):\n",
    "        return {\"tabela\": tabela_nome, \"status\": \"NÃO EXISTE\"}\n",
    "    \n",
    "    df = spark.table(full_name)\n",
    "    total = df.count()\n",
    "    colunas = len(df.columns)\n",
    "    schema_tipos = {field.name: str(field.dataType) for field in df.schema.fields}\n",
    "    \n",
    "    result = {\n",
    "        \"tabela\": tabela_nome,\n",
    "        \"status\": \"OK\",\n",
    "        \"total_registros\": f\"{total:,}\",\n",
    "        \"total_colunas\": colunas,\n",
    "        \"schema_sample\": dict(list(schema_tipos.items())[:5])\n",
    "    }\n",
    "    \n",
    "    if tabela_nome == \"ft_avaliacoes_pedidos\":\n",
    "        if \"avaliacao\" in df.columns:\n",
    "            dist_scores = df.groupBy(\"avaliacao\").count().collect()\n",
    "            result[\"distribuicao_scores\"] = {row[\"avaliacao\"]: row[\"count\"] for row in dist_scores}\n",
    "            result[\"tipo_avaliacao\"] = str(df.schema[\"avaliacao\"].dataType)\n",
    "    \n",
    "    if tabela_nome == \"ft_pagamentos_pedidos\":\n",
    "        if \"valor_pagamento\" in df.columns:\n",
    "            result[\"tipo_valor_pagamento\"] = str(df.schema[\"valor_pagamento\"].dataType)\n",
    "    \n",
    "    if tabela_nome == \"ft_pedido_total\":\n",
    "        if \"valor_total_pago_brl\" in df.columns and \"valor_total_pago_usd\" in df.columns:\n",
    "            result[\"tipo_valor_brl\"] = str(df.schema[\"valor_total_pago_brl\"].dataType)\n",
    "            result[\"tipo_valor_usd\"] = str(df.schema[\"valor_total_pago_usd\"].dataType)\n",
    "            result[\"registros_com_usd\"] = df.filter(col(\"valor_total_pago_usd\").isNotNull()).count()\n",
    "    \n",
    "    return result\n",
    "\n",
    "tabelas_silver = [\n",
    "    \"ft_consumidores\",\n",
    "    \"ft_pedidos\",\n",
    "    \"ft_itens_pedidos\",\n",
    "    \"ft_pagamentos_pedidos\",\n",
    "    \"ft_avaliacoes_pedidos\",\n",
    "    \"ft_produtos\",\n",
    "    \"ft_vendedores\",\n",
    "    \"dm_cotacao_dolar\",\n",
    "    \"ft_pedido_total\"\n",
    "]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"VALIDAÇÃO FINAL - CAMADA SILVER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for tabela in tabelas_silver:\n",
    "    print(f\"\\n{tabela.upper()}\")\n",
    "    resultado = validar_tabela_silver(tabela)\n",
    "    for key, value in resultado.items():\n",
    "        if key != \"tabela\":\n",
    "            print(f\"   {key}: {value}\")\n",
    "    print(\"-\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging e Auditoria\n",
    "\n",
    "**O que:** Tabela de auditoria `audit_log_silver` para rastrear métricas de qualidade e execução de cada transformação Bronze → Silver.\n",
    "\n",
    "**Como foi implementado:**\n",
    "- Estrutura captura: timestamp, tabela, contadores (lidos, escritos, removidos, órfãos), status\n",
    "- Persistência em tabela Delta `medalhao.silver.audit_log_silver`\n",
    "- Modo append para acumular histórico de execuções\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audit_table = f\"{catalog_name}.{silver_db_name}.audit_log_silver\"\n",
    "\n",
    "audit_data = [\n",
    "    {\n",
    "        \"execution_timestamp\": spark.sql(\"SELECT current_timestamp()\").collect()[0][0],\n",
    "        \"notebook_name\": \"02_bronze_to_silverCH\",\n",
    "        \"layer_source\": \"bronze\",\n",
    "        \"layer_target\": \"silver\",\n",
    "        \"execution_status\": \"SUCCESS\",\n",
    "        \"total_tables_processed\": 9,\n",
    "        \"notes\": \"Execução completa: validações FK, deduplicação, tipos monetários DecimalType(12,2), ft_pedido_total com conversão USD via cotação do dólar\"\n",
    "    }\n",
    "]\n",
    "\n",
    "df_audit = spark.createDataFrame(audit_data)\n",
    "\n",
    "if safe_table_exists(spark, audit_table):\n",
    "    df_audit.write.format(\"delta\").mode(\"append\").saveAsTable(audit_table)\n",
    "else:\n",
    "    df_audit.write.format(\"delta\").mode(\"overwrite\").saveAsTable(audit_table)\n",
    "\n",
    "print(f\"Log de auditoria salvo em: {audit_table}\")\n",
    "print(f\"Histórico de execuções disponível para consulta\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validação Final - Resumo por Tabela"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformação: ft_pedido_total\n",
    "\n",
    "**Objetivo:** Criar tabela agregada com valores totais de pedidos em BRL e USD.\n",
    "\n",
    "**Colunas finais:**\n",
    "- data: Data do pedido (DATE)\n",
    "- id_pedido: Identificador único do pedido\n",
    "- id_consumidor: Identificador do consumidor\n",
    "- status: Status do pedido (traduzido)\n",
    "- valor_total_pago_brl: Soma dos pagamentos em BRL\n",
    "- valor_total_pago_usd: Soma dos pagamentos convertidos para USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_table_order_totals = f\"{catalog_name}.{silver_db_name}.ft_pedido_total\"\n",
    "\n",
    "df_pedidos = spark.table(tgt_table_orders)\n",
    "df_pagamentos = spark.table(tgt_table_payments)\n",
    "df_cotacao = spark.table(tgt_table_cotacoes)\n",
    "\n",
    "print(f\"Leitura de tabelas Silver:\")\n",
    "print(f\"  - {tgt_table_orders}: {df_pedidos.count()} registros\")\n",
    "print(f\"  - {tgt_table_payments}: {df_pagamentos.count()} registros\")\n",
    "print(f\"  - {tgt_table_cotacoes}: {df_cotacao.count()} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_totais_pagamentos = df_pagamentos.groupBy(\"id_pedido\").agg(\n",
    "    F.sum(\"valor_pagamento\").alias(\"valor_total_pago_brl\")\n",
    ")\n",
    "\n",
    "print(f\"Agregação calculada:\")\n",
    "print(f\"  - Totais de pagamentos: {df_totais_pagamentos.count()} pedidos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ft_pedido_total — JOIN com Cotação do Dólar para Conversão USD\n",
    "\n",
    "**O que:** Junção de pedidos com pagamentos e cotação do dólar para converter valores BRL → USD.\n",
    "\n",
    "**Como foi implementado:**\n",
    "- Extração de `data` (DATE) de `pedido_compra_timestamp`\n",
    "- JOIN com `dm_cotacao_dolar` pela coluna `data`\n",
    "- Cálculo: `valor_total_pago_usd = valor_total_pago_brl / cotacao_dolar`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ft_pedido_total — Validações de Qualidade\n",
    "\n",
    "**Validações implementadas:**\n",
    "\n",
    "1. **Conversão Monetária**\n",
    "   - JOIN com cotação do dólar pela data do pedido\n",
    "   - Conversão USD apenas quando cotação disponível\n",
    "\n",
    "2. **Completude de Dados**\n",
    "   - Pedidos sem pagamentos recebem BRL = 0.00\n",
    "\n",
    "3. **Tipos de Dados**\n",
    "   - `valor_total_pago_brl`: DecimalType(12,2)\n",
    "   - `valor_total_pago_usd`: DecimalType(12,2)\n",
    "   - `data`: DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pedidos_base = df_pedidos.select(\n",
    "    \"id_pedido\",\n",
    "    \"id_consumidor\",\n",
    "    \"status\",\n",
    "    to_date(col(\"pedido_compra_timestamp\")).alias(\"data\")\n",
    ")\n",
    "\n",
    "df_pedido_com_pagamento = df_pedidos_base.join(\n",
    "    df_totais_pagamentos,\n",
    "    on=\"id_pedido\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df_pedido_com_pagamento = df_pedido_com_pagamento.withColumn(\n",
    "    \"valor_total_pago_brl\",\n",
    "    coalesce(col(\"valor_total_pago_brl\"), lit(0).cast(DecimalType(12,2)))\n",
    ")\n",
    "\n",
    "df_pedido_total = df_pedido_com_pagamento.join(\n",
    "    df_cotacao.select(\"data\", \"cotacao_dolar\"),\n",
    "    on=\"data\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df_pedido_total = df_pedido_total.withColumn(\n",
    "    \"valor_total_pago_usd\",\n",
    "    when(col(\"cotacao_dolar\").isNotNull() & (col(\"cotacao_dolar\") > 0),\n",
    "         (col(\"valor_total_pago_brl\") / col(\"cotacao_dolar\")).cast(DecimalType(12,2))\n",
    "    ).otherwise(None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pedidos_sem_pagamento = df_pedido_total.filter(col(\"valor_total_pago_brl\") == 0).count()\n",
    "pedidos_sem_cotacao = df_pedido_total.filter(col(\"cotacao_dolar\").isNull()).count()\n",
    "pedidos_com_usd = df_pedido_total.filter(col(\"valor_total_pago_usd\").isNotNull()).count()\n",
    "\n",
    "print(f\"Validações de qualidade:\")\n",
    "print(f\"  - Pedidos sem pagamento: {pedidos_sem_pagamento}\")\n",
    "print(f\"  - Pedidos sem cotação USD: {pedidos_sem_cotacao}\")\n",
    "print(f\"  - Pedidos com conversão USD: {pedidos_com_usd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cols = [\n",
    "    \"data\",\n",
    "    \"id_pedido\",\n",
    "    \"id_consumidor\",\n",
    "    \"status\",\n",
    "    \"valor_total_pago_brl\",\n",
    "    \"valor_total_pago_usd\"\n",
    "]\n",
    "\n",
    "df_final = df_pedido_total.select(*final_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(tgt_table_order_totals)\n",
    "\n",
    "silver_table = spark.table(tgt_table_order_totals)\n",
    "saved_count = silver_table.count()\n",
    "com_usd_count = silver_table.filter(col(\"valor_total_pago_usd\").isNotNull()).count()\n",
    "\n",
    "print(f\"Salvo em: {tgt_table_order_totals}\")\n",
    "print(f\"Contagem final: {saved_count}\")\n",
    "print(f\"Pedidos com conversão USD: {com_usd_count}\")\n",
    "\n",
    "display(silver_table.orderBy(\"data\").limit(10))\n",
    "display(silver_table.select(\"data\", \"id_pedido\", \"valor_total_pago_brl\", \"valor_total_pago_usd\").filter(col(\"valor_total_pago_usd\").isNotNull()).limit(5))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8992199125085274,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "02_bronze_to_silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
