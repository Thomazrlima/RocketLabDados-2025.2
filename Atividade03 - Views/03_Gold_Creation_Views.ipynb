{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4cb7bca-5a8f-46f9-85e9-112e81b2502c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Camada Gold - Arquitetura Medalhao\n",
    "\n",
    "**Objetivo:** Criar tabelas de negocio na camada Gold a partir das tabelas curadas da camada Silver.\n",
    "\n",
    "**Operacoes:**\n",
    "- Agregacao de dados para analises de negocios\n",
    "- Joins entre tabelas Silver para criar visoes consolidadas\n",
    "- Validacoes de integridade referencial\n",
    "- Particionamento para otimizacao de queries\n",
    "- Aplicacao de regras de negocio especificas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3cfafb5-2b19-44fc-9031-85a2dd22320c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Imports e Configuracoes Iniciais\n",
    "\n",
    "Importacao de todas as bibliotecas necessarias e configuracao do ambiente Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9a7dd25-b8d3-439b-ad0d-cc7dd0429eca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.sql.functions import col, to_date, year, upper, trim, coalesce, lit, when, current_timestamp, explode, sequence, month, quarter, dayofweek, dayofmonth, weekofyear, round as spark_round, avg\n",
    "from pyspark.sql.types import DecimalType, DateType, StringType, IntegerType\n",
    "from pyspark.sql.utils import AnalysisException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e15eda7b-2d68-4fc2-8e8a-52a338c7797c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Setup do Catalogo\n",
    "\n",
    "Configuracao do catalogo Medalhao e criacao dos schemas Silver e Gold caso nao existam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c554297-9989-4957-8b45-e412d261c1a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE CATALOG IF NOT EXISTS medalhao;\n",
    "USE CATALOG medalhao;\n",
    "\n",
    "CREATE SCHEMA IF NOT EXISTS silver;\n",
    "CREATE SCHEMA IF NOT EXISTS gold;\n",
    "\n",
    "USE SCHEMA gold;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76f81ab7-1918-4698-9784-dc6b43dd2ee3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Funcoes Utilitarias\n",
    "\n",
    "Funcoes auxiliares para gerenciamento de tabelas Delta, validacao de existencia e gravacao com particionamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc1d638b-3993-4197-bd71-121a61fed317",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog_name = \"medalhao\"\n",
    "silver_db_name = \"silver\"\n",
    "gold_db_name = \"gold\"\n",
    "\n",
    "def table_exists(full_table_name: str) -> bool:\n",
    "    try:\n",
    "        spark.table(full_table_name)\n",
    "        return True\n",
    "    except AnalysisException:\n",
    "        return False\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def ensure_database(db_name: str):\n",
    "    spark.sql(f\"CREATE DATABASE IF NOT EXISTS {db_name}\")\n",
    "\n",
    "def write_delta_overwrite(df, full_table_name: str, partition_cols: list = None):\n",
    "    writer = df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\")\n",
    "    if partition_cols:\n",
    "        writer = writer.partitionBy(*partition_cols)\n",
    "    writer.saveAsTable(full_table_name)\n",
    "\n",
    "def validar_tabela_silver(tabela_nome: str, catalog: str = \"medalhao\", schema: str = \"silver\"):\n",
    "    full_name = f\"{catalog}.{schema}.{tabela_nome}\"\n",
    "    if not table_exists(full_name):\n",
    "        raise RuntimeError(f\"Tabela Silver nao encontrada: {full_name}\")\n",
    "    \n",
    "    df = spark.table(full_name)\n",
    "    count = df.count()\n",
    "    print(f\"Leitura: {full_name}\")\n",
    "    print(f\"Registros: {count:,}\")\n",
    "    return df\n",
    "\n",
    "def log_metricas(table_name: str, metrics: dict):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"METRICAS DE TRANSFORMACAO: {table_name}\")\n",
    "    print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"{'-'*80}\")\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "def mapear_dia_semana(dia_num: int) -> str:\n",
    "    mapa = {1: \"Domingo\", 2: \"Segunda-feira\", 3: \"Terca-feira\", 4: \"Quarta-feira\", \n",
    "            5: \"Quinta-feira\", 6: \"Sexta-feira\", 7: \"Sabado\"}\n",
    "    return mapa.get(dia_num, \"Desconhecido\")\n",
    "\n",
    "def mapear_mes(mes_num: int) -> str:\n",
    "    mapa = {1: \"Janeiro\", 2: \"Fevereiro\", 3: \"Marco\", 4: \"Abril\", 5: \"Maio\", 6: \"Junho\",\n",
    "            7: \"Julho\", 8: \"Agosto\", 9: \"Setembro\", 10: \"Outubro\", 11: \"Novembro\", 12: \"Dezembro\"}\n",
    "    return mapa.get(mes_num, \"Desconhecido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7299e6a0-da50-4f62-99d2-6101e882a14a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Projeto 1 - Area de Logistica\n",
    "\n",
    "**Objetivo:** Criar tabela Gold para analise de vendas por localidade dos consumidores.\n",
    "\n",
    "**Contexto de Negocio:** Facilitar analises de distribuicao geografica de vendas, identificando regioes com maior volume de pedidos e faturamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d5f0847-d210-4118-a887-7f44dc5c3ff9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Questao 1.1 - ft_vendas_consumidor_local\n",
    "\n",
    "**Descricao:** Tabela fato consolidando pedidos com localizacao dos consumidores para analise geografica de vendas.\n",
    "\n",
    "**Origem dos Dados:**\n",
    "- silver.ft_pedido_total (dados de pedidos e valores)\n",
    "- silver.ft_consumidores (localizacao: cidade e estado)\n",
    "\n",
    "**Estrutura da Tabela:**\n",
    "- id_pedido: Identificador unico do pedido (STRING)\n",
    "- id_consumidor: Identificador do consumidor (STRING)\n",
    "- valor_total_pedido_brl: Valor total em BRL (DECIMAL(12,2))\n",
    "- cidade: Cidade do consumidor normalizada (STRING)\n",
    "- estado: Estado do consumidor normalizado (STRING)\n",
    "- data_pedido: Data do pedido (DATE)\n",
    "- ano: Ano extraido para particionamento (INT)\n",
    "\n",
    "**Estrategia de Particionamento:** Por estado e ano para otimizacao de queries geograficas e temporais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88f127ee-ef5b-41b9-aa88-27eb1746dffb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 3.1.1: Carregamento das Tabelas Silver\n",
    "\n",
    "Carrega as tabelas ft_pedido_total e ft_consumidores da camada Silver, validando existencia e exibindo metadados e amostras para verificacao inicial dos dados de origem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "960976d2-07f0-4540-95a8-f50c26956f23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"CARREGAMENTO DAS TABELAS SILVER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_pedido_total = validar_tabela_silver(\"ft_pedido_total\")\n",
    "df_consumidores = validar_tabela_silver(\"ft_consumidores\")\n",
    "\n",
    "print(\"\\nEstrutura: ft_pedido_total\")\n",
    "df_pedido_total.printSchema()\n",
    "\n",
    "print(\"\\nEstrutura: ft_consumidores\")\n",
    "df_consumidores.printSchema()\n",
    "\n",
    "print(\"\\nAmostra: ft_pedido_total\")\n",
    "display(df_pedido_total.limit(5))\n",
    "\n",
    "print(\"\\nAmostra: ft_consumidores\")\n",
    "display(df_consumidores.limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f32ba14c-2211-4ba9-a4fa-18fb197f97b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 2: Validacoes de Qualidade dos Dados\n",
    "\n",
    "Executa validacoes criticas de integridade dos dados Silver antes da transformacao Gold. Esta etapa garante que os dados de origem atendem aos requisitos minimos de qualidade, identificando problemas estruturais que podem impactar a camada Gold. As validacoes incluem verificacao de schema, integridade de chaves primarias e estrangeiras, e analise de valores monetarios anomalos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e370da77-8d69-4f21-a011-6f4239f8bf27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Validacao 2: Integridade das Chaves Primarias\n",
    "\n",
    "Verifica a presenca de valores nulos nas chaves primarias (id_pedido e id_consumidor). Chaves nulas comprometem a integridade referencial e podem causar perdas de dados nos JOINs da camada Gold. Esta validacao identifica problemas que requerem tratamento especifico durante a transformacao."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f589b4c-9cb3-41a6-bdfb-bd6d682882e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nValidacao 2: Integridade das chaves\")\n",
    "\n",
    "null_id_pedido = df_pedido_total.filter(col(\"id_pedido\").isNull()).count()\n",
    "null_id_consumidor_pedido = df_pedido_total.filter(col(\"id_consumidor\").isNull()).count()\n",
    "null_id_consumidor_cons = df_consumidores.filter(col(\"id_consumidor\").isNull()).count()\n",
    "\n",
    "print(f\"Nulos: id_pedido={null_id_pedido}, id_consumidor_pedido={null_id_consumidor_pedido}, id_consumidor_cons={null_id_consumidor_cons}\")\n",
    "\n",
    "if null_id_pedido > 0 or null_id_consumidor_pedido > 0 or null_id_consumidor_cons > 0:\n",
    "    print(\"Atencao: chaves nulas detectadas, serao tratadas no JOIN\")\n",
    "else:\n",
    "    print(\"Verificacao concluida: nenhuma chave nula\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec19c2c2-be88-4828-976f-5c36c5be5aa5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Validacao 3: Integridade Referencial (Foreign Keys)\n",
    "\n",
    "Valida a integridade referencial entre pedidos e consumidores, identificando pedidos orfaos (sem consumidor correspondente). Esta validacao e essencial para garantir a consistencia dos JOINs na camada Gold e identificar problemas de qualidade que podem ter origem em processos upstream ou falhas de integracao."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8eb0e5eb-6bee-410b-afae-f3da176c4bd7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nValidacao 3: Integridade referencial (FK)\")\n",
    "\n",
    "df_consumidores_ids = df_consumidores.select(col(\"id_consumidor\").alias(\"fk_consumidor_id\")).distinct()\n",
    "\n",
    "orphan_pedidos = df_pedido_total.join(\n",
    "    df_consumidores_ids,\n",
    "    df_pedido_total.id_consumidor == df_consumidores_ids.fk_consumidor_id,\n",
    "    how=\"left_anti\"\n",
    ")\n",
    "orphan_count = orphan_pedidos.count()\n",
    "\n",
    "print(f\"Pedidos orfaos (sem consumidor valido): {orphan_count}\")\n",
    "\n",
    "if orphan_count > 0:\n",
    "    print(f\"Atencao: {orphan_count} pedidos sem consumidor valido serao marcados na Gold\")\n",
    "    print(\"\\nExemplos de pedidos orfaos:\")\n",
    "    display(orphan_pedidos.select(\"id_pedido\", \"id_consumidor\").limit(5))\n",
    "else:\n",
    "    print(\"Verificacao concluida: todos os pedidos possuem consumidor valido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6277fe7c-5ded-4a2a-9c12-3cd61741732d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Validacao 4: Valores Monetarios Anomalos\n",
    "\n",
    "Analisa a qualidade dos valores monetarios, identificando registros com valores negativos ou nulos. Valores anomalos podem indicar erros de processamento upstream ou problemas de integracao. Esta validacao e fundamental para garantir a confiabilidade das analises financeiras na camada Gold, permitindo decisoes informadas sobre tratamento ou manutencao desses registros para auditoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8deea358-805b-4677-8e24-08de0380d89e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nValidacao 4: Valores monetarios\")\n",
    "\n",
    "valores_negativos = df_pedido_total.filter(col(\"valor_total_pago_brl\") < 0).count()\n",
    "valores_nulos = df_pedido_total.filter(col(\"valor_total_pago_brl\").isNull()).count()\n",
    "\n",
    "print(f\"Valores negativos: {valores_negativos}\")\n",
    "print(f\"Valores nulos: {valores_nulos}\")\n",
    "\n",
    "if valores_negativos > 0 or valores_nulos > 0:\n",
    "    print(\"Atencao: valores anomalos detectados, serao mantidos para auditoria\")\n",
    "else:\n",
    "    print(\"Verificacao concluida: todos os valores monetarios validos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b574747-1aec-40cc-9d0e-11bc7b3ed4a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 3: Transformacao e Enriquecimento dos Dados\n",
    "\n",
    "Prepara os dados de pedidos com conversao de tipos, normaliza dados de consumidores (uppercase, trim), executa LEFT JOIN para manter todos os pedidos, trata valores ausentes com defaults, adiciona coluna de particionamento (ano) e valida distribuicao final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "843dd1dc-90a9-4a79-a664-e04aaf765303",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRANSFORMACAO PARA CAMADA GOLD\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nEtapa 3.1: Preparacao dos pedidos\")\n",
    "\n",
    "df_pedidos_preparado = df_pedido_total.select(\n",
    "    col(\"id_pedido\").cast(\"string\").alias(\"id_pedido\"),\n",
    "    col(\"id_consumidor\").cast(\"string\").alias(\"id_consumidor\"),\n",
    "    col(\"valor_total_pago_brl\").cast(DecimalType(12,2)).alias(\"valor_total_pedido_brl\"),\n",
    "    col(\"data\").alias(\"data_pedido\")\n",
    ")\n",
    "\n",
    "total_pedidos_prep = df_pedidos_preparado.count()\n",
    "print(f\"Pedidos preparados: {total_pedidos_prep:,}\")\n",
    "\n",
    "print(\"\\nEtapa 3.2: Preparacao dos consumidores\")\n",
    "\n",
    "df_consumidores_preparado = df_consumidores.select(\n",
    "    col(\"id_consumidor\").cast(\"string\").alias(\"id_consumidor\"),\n",
    "    upper(trim(col(\"cidade\"))).alias(\"cidade\"),\n",
    "    upper(trim(col(\"estado\"))).alias(\"estado\")\n",
    ").dropDuplicates([\"id_consumidor\"])\n",
    "\n",
    "total_consumidores_unicos = df_consumidores_preparado.count()\n",
    "print(f\"Consumidores unicos: {total_consumidores_unicos:,}\")\n",
    "\n",
    "print(\"\\nEtapa 3.1.3: JOIN entre pedidos e consumidores\")\n",
    "\n",
    "df_joined = df_pedidos_preparado.join(\n",
    "    df_consumidores_preparado,\n",
    "    on=\"id_consumidor\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "total_apos_join = df_joined.count()\n",
    "print(f\"Registros apos JOIN: {total_apos_join:,}\")\n",
    "\n",
    "print(\"\\nEtapa 3.1.4: Tratamento de valores ausentes\")\n",
    "\n",
    "df_gold = df_joined.select(\n",
    "    col(\"id_pedido\"),\n",
    "    col(\"id_consumidor\"),\n",
    "    col(\"valor_total_pedido_brl\"),\n",
    "    coalesce(col(\"cidade\"), lit(\"NAO_INFORMADO\")).alias(\"cidade\"),\n",
    "    coalesce(col(\"estado\"), lit(\"XX\")).alias(\"estado\"),\n",
    "    col(\"data_pedido\")\n",
    ")\n",
    "\n",
    "registros_sem_localizacao = df_joined.filter(col(\"cidade\").isNull() | col(\"estado\").isNull()).count()\n",
    "print(f\"Registros com localizacao ausente tratados: {registros_sem_localizacao}\")\n",
    "\n",
    "print(\"\\nEtapa 3.1.5: Adicao de coluna de particionamento\")\n",
    "\n",
    "df_gold = df_gold.withColumn(\"ano\", year(col(\"data_pedido\")))\n",
    "\n",
    "total_final = df_gold.count()\n",
    "print(f\"Registros finais: {total_final:,}\")\n",
    "\n",
    "print(\"\\nEtapa 3.1.6: Validacao da distribuicao\")\n",
    "\n",
    "print(\"\\nDistribuicao por Estado (Top 10):\")\n",
    "display(df_gold.groupBy(\"estado\").count().orderBy(col(\"count\").desc()).limit(10))\n",
    "\n",
    "print(\"\\nDistribuicao por Ano:\")\n",
    "display(df_gold.groupBy(\"ano\").count().orderBy(\"ano\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35d389c0-ae95-4d1e-a417-67166dd91afc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 3.1.7: Gravacao da Tabela Gold\n",
    "\n",
    "Grava a tabela ft_vendas_consumidor_local no formato Delta com particionamento por estado e ano, seguida de validacao pos-gravacao incluindo verificacao de schema, tipos de dados, amostra de registros e estatisticas agregadas por particao."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1da8006-0dd1-4b7b-8b03-8b9f90c1c92c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GRAVACAO DA TABELA GOLD\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "ensure_database(gold_db_name)\n",
    "\n",
    "target_table = f\"{catalog_name}.{gold_db_name}.ft_vendas_consumidor_local\"\n",
    "partition_cols = [\"estado\", \"ano\"]\n",
    "\n",
    "print(f\"\\nTabela destino: {target_table}\")\n",
    "print(f\"Particionamento: {', '.join(partition_cols)}\")\n",
    "\n",
    "total_a_gravar = df_gold.count()\n",
    "print(f\"Registros a gravar: {total_a_gravar:,}\")\n",
    "\n",
    "print(\"\\nGravando tabela Delta...\")\n",
    "write_delta_overwrite(df_gold, target_table, partition_cols=partition_cols)\n",
    "\n",
    "print(\"Gravacao concluida\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VALIDACAO POS-GRAVACAO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_validacao = spark.table(target_table)\n",
    "count_validacao = df_validacao.count()\n",
    "\n",
    "print(f\"\\nRegistros gravados: {count_validacao:,}\")\n",
    "\n",
    "if count_validacao != total_a_gravar:\n",
    "    print(f\"ATENCAO: Divergencia de contagem (esperado: {total_a_gravar:,})\")\n",
    "\n",
    "print(f\"\\nSchema da tabela:\")\n",
    "df_validacao.printSchema()\n",
    "\n",
    "print(\"\\nTipos de dados:\")\n",
    "for field in df_validacao.schema.fields:\n",
    "    print(f\"  {field.name}: {field.dataType}\")\n",
    "\n",
    "print(\"\\nAmostra dos dados (20 registros mais recentes):\")\n",
    "display(df_validacao.orderBy(col(\"data_pedido\").desc()).limit(20))\n",
    "\n",
    "print(\"\\nEstatisticas por Estado (Top 10):\")\n",
    "display(\n",
    "    df_validacao.groupBy(\"estado\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"total_pedidos\"),\n",
    "        F.sum(\"valor_total_pedido_brl\").alias(\"valor_total_brl\"),\n",
    "        F.avg(\"valor_total_pedido_brl\").alias(\"valor_medio_brl\")\n",
    "    )\n",
    "    .orderBy(col(\"total_pedidos\").desc())\n",
    "    .limit(10)\n",
    ")\n",
    "\n",
    "print(\"\\nEstatisticas por Ano:\")\n",
    "display(\n",
    "    df_validacao.groupBy(\"ano\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"total_pedidos\"),\n",
    "        F.sum(\"valor_total_pedido_brl\").alias(\"valor_total_brl\"),\n",
    "        F.avg(\"valor_total_pedido_brl\").alias(\"valor_medio_brl\")\n",
    "    )\n",
    "    .orderBy(\"ano\")\n",
    ")\n",
    "\n",
    "metricas_finais = {\n",
    "    \"Tabela\": target_table,\n",
    "    \"Registros totais\": f\"{count_validacao:,}\",\n",
    "    \"Particionamento\": \", \".join(partition_cols),\n",
    "    \"Origem Silver\": \"ft_pedido_total, ft_consumidores\",\n",
    "    \"Formato\": \"Delta Lake\",\n",
    "    \"Status\": \"Concluido com sucesso\"\n",
    "}\n",
    "\n",
    "log_metricas(\"ft_vendas_consumidor_local\", metricas_finais)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "825d4ddd-ff6b-4dd1-bd88-c8aba8e34e2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Questao 1.2 - view_total_compras_por_consumidor\n",
    "\n",
    "**Descricao:** View que consolida o total de compras e o valor total vendido por cidade e estado, permitindo identificar localidades com maior concentracao de vendas.\n",
    "\n",
    "**Origem dos Dados:**\n",
    "- gold.ft_vendas_consumidor_local (tabela fato criada na Questao 1.1)\n",
    "\n",
    "**Estrutura da View:**\n",
    "- cidade: Cidade do cliente (STRING)\n",
    "- estado: Estado do cliente (STRING)\n",
    "- quantidade_vendas: Quantidade de pedidos realizados na localidade (BIGINT)\n",
    "- valor_total_localidade: Soma total dos valores pagos em BRL (DECIMAL)\n",
    "\n",
    "**Proposito:** Esta view facilita analises geograficas de vendas, identificando regioes com maior volume de pedidos e faturamento. Conecta-se diretamente a tabela Gold ft_vendas_consumidor_local para fornecer metricas consolidadas por localidade, essenciais para estrategias de expansao e logistica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fb49cdf-9942-4a35-aaa2-b213da82de77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"CRIACAO DA VIEW: view_total_compras_por_consumidor\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "view_name = f\"{catalog_name}.{gold_db_name}.view_total_compras_por_consumidor\"\n",
    "source_table = f\"{catalog_name}.{gold_db_name}.ft_vendas_consumidor_local\"\n",
    "\n",
    "print(f\"\\nView: {view_name}\")\n",
    "print(f\"Origem: {source_table}\")\n",
    "\n",
    "df_source = spark.table(source_table)\n",
    "\n",
    "df_view = df_source.groupBy(\"cidade\", \"estado\").agg(\n",
    "    F.count(\"id_pedido\").alias(\"quantidade_vendas\"),\n",
    "    F.sum(\"valor_total_pedido_brl\").alias(\"valor_total_localidade\")\n",
    ")\n",
    "\n",
    "df_view.write.format(\"delta\").mode(\"overwrite\").saveAsTable(view_name)\n",
    "print(\"\\nView criada com sucesso\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VALIDACAO DA VIEW\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_view_read = spark.table(view_name)\n",
    "count_view = df_view_read.count()\n",
    "\n",
    "print(f\"\\nTotal de localidades: {count_view:,}\")\n",
    "\n",
    "print(\"\\nSchema da view:\")\n",
    "df_view_read.printSchema()\n",
    "\n",
    "print(\"\\nTop 20 localidades por quantidade de vendas:\")\n",
    "display(df_view_read.orderBy(col(\"quantidade_vendas\").desc()).limit(20))\n",
    "\n",
    "print(\"\\nTop 20 localidades por valor total:\")\n",
    "display(df_view_read.orderBy(col(\"valor_total_localidade\").desc()).limit(20))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONSULTA: Total de vendas por estado\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_vendas_estado = df_view_read.groupBy(\"estado\").agg(\n",
    "    F.sum(\"quantidade_vendas\").alias(\"total_vendas_estado\"),\n",
    "    F.sum(\"valor_total_localidade\").alias(\"valor_total_estado\")\n",
    ").orderBy(col(\"total_vendas_estado\").desc())\n",
    "\n",
    "print(\"\\nTotal de vendas por estado:\")\n",
    "display(df_vendas_estado)\n",
    "\n",
    "metricas_view = {\n",
    "    \"View\": view_name,\n",
    "    \"Localidades unicas\": f\"{count_view:,}\",\n",
    "    \"Origem\": source_table,\n",
    "    \"Agrupamento\": \"cidade, estado\",\n",
    "    \"Status\": \"Criada com sucesso\"\n",
    "}\n",
    "\n",
    "log_metricas(\"view_total_compras_por_consumidor\", metricas_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12451e68-66a6-464c-8a70-f6208438eb9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Projeto 2 - Area de Logistica\n",
    "\n",
    "**Objetivo:** Analisar atrasos de entregas identificando regioes com maior ocorrencia de atrasos e vendedores associados.\n",
    "\n",
    "**Contexto de Negocio:** A equipe de Logistica enfrenta aumento nos indices de atraso e precisa identificar gargalos na cadeia de entrega, regioes problematicas e vendedores com maior incidencia de atrasos para otimizar processos logisticos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26d1b01f-004b-4c89-a980-56538c29979f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Questao 2.1 - ft_atrasos_pedidos_local_vendedor\n",
    "\n",
    "**Descricao:** Tabela fato contendo informacoes logisticas de cada pedido, incluindo metricas de atraso e identificacao de vendedor e localizacao.\n",
    "\n",
    "**Origem dos Dados:**\n",
    "- silver.ft_pedidos (datas de pedido, compra, entrega estimada e real)\n",
    "- silver.ft_consumidores (localizacao: cidade e estado)\n",
    "- silver.ft_itens_pedidos (identificacao do vendedor)\n",
    "\n",
    "**Estrutura da Tabela:**\n",
    "- id_pedido: Identificador unico do pedido (STRING)\n",
    "- id_vendedor: Identificador do vendedor responsavel (STRING)\n",
    "- id_consumidor: Identificador do cliente (STRING)\n",
    "- entrega_no_prazo: Classificacao da entrega - \"Sim\", \"Nao\" ou \"Nao Entregue\" (STRING)\n",
    "- tempo_entrega_dias: Tempo real de entrega em dias (INT)\n",
    "- tempo_entrega_estimado_dias: Tempo estimado de entrega em dias (INT)\n",
    "- cidade: Cidade do cliente normalizada (STRING)\n",
    "- estado: Estado do cliente normalizado (STRING)\n",
    "\n",
    "**Logica de Composicao:**\n",
    "- entrega_no_prazo: \"Sim\" quando data_entrega <= data_entrega_estimada; \"Nao\" quando data_entrega > data_entrega_estimada; \"Nao Entregue\" quando data_entrega e nula\n",
    "- tempo_entrega_dias: datediff(data_entrega, data_pedido_compra) - calculado apenas quando entrega foi realizada\n",
    "- tempo_entrega_estimado_dias: datediff(data_entrega_estimada, data_pedido_compra)\n",
    "- id_vendedor: obtido da primeira ocorrencia em ft_itens_pedidos (pedidos podem ter multiplos vendedores, seleciona-se o primeiro)\n",
    "\n",
    "**Proposito:** Esta tabela permite analise detalhada de atrasos por regiao e vendedor, identificando gargalos logisticos e padroes de desempenho para otimizacao da cadeia de entrega."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17c56c88-93c6-4c62-8c6b-bdf09dbbfb1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 3.2.1: Carregamento das Tabelas Silver (Projeto 2)\n",
    "\n",
    "Carrega as tres tabelas Silver necessarias para analise de atrasos: ft_pedidos (informacoes de datas), ft_consumidores (localizacao) e ft_itens_pedidos (identificacao do vendedor). Este carregamento estabelece a base de dados para calcular metricas logisticas e identificar gargalos na cadeia de entrega."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d035ecf7-9434-450e-b917-296be7585ef2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"CRIACAO DA TABELA: ft_atrasos_pedidos_local_vendedor\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nCarregamento das tabelas Silver\")\n",
    "\n",
    "df_pedidos = validar_tabela_silver(\"ft_pedidos\")\n",
    "df_consumidores = validar_tabela_silver(\"ft_consumidores\")\n",
    "df_itens_pedidos = validar_tabela_silver(\"ft_itens_pedidos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce69dae1-f8f9-4fc6-8e86-d466f4ee600c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 3.2.2: Preparacao dos Dados de Vendedores\n",
    "\n",
    "Extrai e deduplica os dados de vendedores da tabela ft_itens_pedidos. Como um pedido pode ter multiplos itens de diferentes vendedores, esta etapa seleciona o primeiro vendedor por pedido para simplificar a analise. Esta abordagem permite identificar o vendedor primario responsavel pelo pedido na analise de atrasos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44bced66-c70a-4448-adc1-bead2d8dc86c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nPreparacao dos dados de vendedores\")\n",
    "\n",
    "df_vendedores = df_itens_pedidos.select(\n",
    "    col(\"id_pedido\"),\n",
    "    col(\"id_vendedor\")\n",
    ").dropDuplicates([\"id_pedido\"])\n",
    "\n",
    "total_vendedores = df_vendedores.count()\n",
    "print(f\"Pedidos com vendedor identificado: {total_vendedores:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e93e020-7d8c-417b-abd1-bbd3a753f19c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 3.2.3: Preparacao dos Dados de Consumidores\n",
    "\n",
    "Normaliza os dados de localizacao dos consumidores aplicando uppercase e trim para garantir consistencia. Remove duplicatas de id_consumidor para manter apenas um registro por cliente. Esta padronizacao e essencial para analises geograficas consistentes e agregacoes precisas por cidade e estado na identificacao de regioes com maior incidencia de atrasos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20759637-d94d-47b2-b5f1-dc3b8044d750",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nPreparacao dos dados de consumidores\")\n",
    "\n",
    "df_consumidores_prep = df_consumidores.select(\n",
    "    col(\"id_consumidor\").cast(\"string\").alias(\"id_consumidor\"),\n",
    "    upper(trim(col(\"cidade\"))).alias(\"cidade\"),\n",
    "    upper(trim(col(\"estado\"))).alias(\"estado\")\n",
    ").dropDuplicates([\"id_consumidor\"])\n",
    "\n",
    "total_consumidores = df_consumidores_prep.count()\n",
    "print(f\"Consumidores unicos: {total_consumidores:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bebb9d7-b98d-470d-86ba-e8de8a203d65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 3.2.4: Calculo das Metricas Logisticas\n",
    "\n",
    "Calcula as metricas essenciais para analise de atrasos: tempo_entrega_dias (diferenca entre data_entrega e data_pedido_compra), tempo_entrega_estimado_dias (diferenca entre data_entrega_estimada e data_pedido_compra), e entrega_no_prazo (classificacao \"Sim\", \"Nao\" ou \"Nao Entregue\"). Estas metricas sao fundamentais para identificar padroes de atraso e avaliar performance logistica por regiao e vendedor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78cc987c-fc41-4109-83bd-9da7decad193",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nCalculo das metricas logisticas\")\n",
    "\n",
    "df_pedidos_metricas = df_pedidos.select(\n",
    "    col(\"id_pedido\").cast(\"string\").alias(\"id_pedido\"),\n",
    "    col(\"id_consumidor\").cast(\"string\").alias(\"id_consumidor\"),\n",
    "    col(\"entrega_no_prazo\"),\n",
    "    when(col(\"diferenca_entrega_dias\").isNotNull(), col(\"diferenca_entrega_dias\"))\n",
    "        .otherwise(lit(None)).cast(\"int\").alias(\"tempo_entrega_dias\"),\n",
    "    when(col(\"tempo_entrega_estimado_dias\").isNotNull(), col(\"tempo_entrega_estimado_dias\"))\n",
    "        .otherwise(lit(None)).cast(\"int\").alias(\"tempo_entrega_estimado_dias\")\n",
    ")\n",
    "\n",
    "total_pedidos = df_pedidos_metricas.count()\n",
    "print(f\"Pedidos processados: {total_pedidos:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ecd052c-f08c-4d93-87ae-d9ddce8eb9ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 3.2.5: Consolidacao e Tratamento de Dados Ausentes\n",
    "\n",
    "Executa JOINs left entre pedidos, vendedores e consumidores para manter todos os pedidos mesmo sem vendedor ou localizacao identificados. Aplica coalesce para tratar valores ausentes com defaults padronizados (\"NAO_INFORMADO\" para vendedor e cidade, \"XX\" para estado). Esta abordagem garante completude dos dados para analise sem perda de registros por ausencia de informacoes complementares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93c618a9-a296-4503-8e74-8d855536bdb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nConsolidacao dos dados\")\n",
    "\n",
    "df_gold_temp = df_pedidos_metricas.join(\n",
    "    df_vendedores,\n",
    "    on=\"id_pedido\",\n",
    "    how=\"left\"\n",
    ").join(\n",
    "    df_consumidores_prep,\n",
    "    on=\"id_consumidor\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df_gold = df_gold_temp.select(\n",
    "    col(\"id_pedido\"),\n",
    "    coalesce(col(\"id_vendedor\"), lit(\"NAO_INFORMADO\")).alias(\"id_vendedor\"),\n",
    "    col(\"id_consumidor\"),\n",
    "    col(\"entrega_no_prazo\"),\n",
    "    col(\"tempo_entrega_dias\"),\n",
    "    col(\"tempo_entrega_estimado_dias\"),\n",
    "    coalesce(col(\"cidade\"), lit(\"NAO_INFORMADO\")).alias(\"cidade\"),\n",
    "    coalesce(col(\"estado\"), lit(\"XX\")).alias(\"estado\")\n",
    ")\n",
    "\n",
    "total_final = df_gold.count()\n",
    "print(f\"Registros finais: {total_final:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "208d1ac4-0724-40ec-ac42-022411f8cafb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 3.2.6: Validacao da Distribuicao dos Dados\n",
    "\n",
    "Valida a distribuicao dos dados antes da gravacao, analisando a proporcao de entregas no prazo versus atrasadas por status e a distribuicao geografica por estado. Esta validacao preliminar permite identificar inconsistencias ou padroes inesperados antes da persistencia na camada Gold, garantindo qualidade dos dados para analises posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b760ec61-8cea-40c5-8bed-1276203f252d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nValidacao da distribuicao\")\n",
    "\n",
    "print(\"\\nDistribuicao por status de entrega:\")\n",
    "display(df_gold.groupBy(\"entrega_no_prazo\").count().orderBy(\"entrega_no_prazo\"))\n",
    "\n",
    "print(\"\\nDistribuicao por Estado (Top 10):\")\n",
    "display(df_gold.groupBy(\"estado\").count().orderBy(col(\"count\").desc()).limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e563488-9e3d-40f5-83f0-d4249d1b9cf6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 3.2.7: Gravacao da Tabela Gold\n",
    "\n",
    "Persiste a tabela ft_atrasos_pedidos_local_vendedor no formato Delta Lake no schema Gold. A gravacao em modo overwrite garante atualizacao completa dos dados, mantendo apenas a versao mais recente. Esta tabela Gold servira como fonte para analises de atrasos, identificacao de gargalos logisticos e avaliacao de performance por regiao e vendedor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ea8d2a4-ef0f-41c9-87a4-6cd90f232588",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GRAVACAO DA TABELA GOLD\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "target_table = f\"{catalog_name}.{gold_db_name}.ft_atrasos_pedidos_local_vendedor\"\n",
    "\n",
    "print(f\"\\nTabela destino: {target_table}\")\n",
    "\n",
    "total_a_gravar = df_gold.count()\n",
    "print(f\"Registros a gravar: {total_a_gravar:,}\")\n",
    "\n",
    "print(\"\\nGravando tabela Delta...\")\n",
    "write_delta_overwrite(df_gold, target_table)\n",
    "\n",
    "print(\"Gravacao concluida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16b12b99-ccb8-459a-ad66-b489bd9baa23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 3.2.8: Validacao Pos-Gravacao e Analise de Atrasos\n",
    "\n",
    "Valida a tabela gravada verificando contagem de registros, schema e tipos de dados. Exibe amostra dos dados e calcula estatisticas agregadas de atrasos por status de entrega, incluindo tempo medio de entrega real versus estimado. Esta validacao final confirma a integridade da tabela Gold e fornece insights preliminares sobre a distribuicao de atrasos para direcionar analises subsequentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb3a17ff-a684-44bd-8ba1-395c1258b37c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VALIDACAO POS-GRAVACAO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_validacao = spark.table(target_table)\n",
    "count_validacao = df_validacao.count()\n",
    "\n",
    "print(f\"\\nRegistros gravados: {count_validacao:,}\")\n",
    "\n",
    "if count_validacao != total_a_gravar:\n",
    "    print(f\"ATENCAO: Divergencia de contagem (esperado: {total_a_gravar:,})\")\n",
    "\n",
    "print(f\"\\nSchema da tabela:\")\n",
    "df_validacao.printSchema()\n",
    "\n",
    "print(\"\\nAmostra dos dados (20 registros):\")\n",
    "display(df_validacao.limit(20))\n",
    "\n",
    "print(\"\\nEstatisticas de atrasos:\")\n",
    "display(\n",
    "    df_validacao.groupBy(\"entrega_no_prazo\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"total_pedidos\"),\n",
    "        F.avg(\"tempo_entrega_dias\").alias(\"tempo_medio_entrega_dias\"),\n",
    "        F.avg(\"tempo_entrega_estimado_dias\").alias(\"tempo_medio_estimado_dias\")\n",
    "    )\n",
    "    .orderBy(\"entrega_no_prazo\")\n",
    ")\n",
    "\n",
    "metricas_finais = {\n",
    "    \"Tabela\": target_table,\n",
    "    \"Registros totais\": f\"{count_validacao:,}\",\n",
    "    \"Origem Silver\": \"ft_pedidos, ft_consumidores, ft_itens_pedidos\",\n",
    "    \"Formato\": \"Delta Lake\",\n",
    "    \"Status\": \"Concluido com sucesso\"\n",
    "}\n",
    "\n",
    "log_metricas(\"ft_atrasos_pedidos_local_vendedor\", metricas_finais)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d99c17e8-4f8b-4ad0-9982-9118142f32a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Questao 2.2 - Views Analiticas de Logistica\n",
    "\n",
    "**Objetivo:** Criar views Gold para analise de desempenho logistico por localidade e vendedor.\n",
    "\n",
    "**Contexto de Negocio:** A equipe de Logistica necessita de metricas agregadas para identificar regioes problematicas e vendedores com baixa pontualidade, permitindo acoes corretivas direcionadas e otimizacao da cadeia de entrega.\n",
    "\n",
    "**Views a serem criadas:**\n",
    "1. view_tempo_medio_entrega_localidade - Analise de tempos de entrega por regiao\n",
    "2. view_vendedor_pontualidade - Analise de desempenho e pontualidade por vendedor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3b6cf99-351d-4a5e-8fce-f8985943a3d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Questao 2.2.1 - view_tempo_medio_entrega_localidade\n",
    "\n",
    "**Descricao:** View agregando metricas de tempo de entrega por cidade e estado, comparando performance real versus estimada.\n",
    "\n",
    "**Origem dos Dados:**\n",
    "- gold.ft_atrasos_pedidos_local_vendedor\n",
    "\n",
    "**Estrutura da View:**\n",
    "- cidade: Cidade do cliente normalizada (STRING)\n",
    "- estado: Estado do cliente normalizado (STRING)\n",
    "- tempo_medio_entrega: Media do tempo real de entrega em dias, arredondada com 2 casas decimais (DECIMAL)\n",
    "- tempo_medio_estimado: Media do tempo estimado de entrega em dias, arredondada com 2 casas decimais (DECIMAL)\n",
    "- entrega_maior_que_estimado: Indicador se tempo real excede tempo estimado - \"SIM\" ou \"NAO\" (STRING)\n",
    "\n",
    "**Proposito:** Esta view permite identificar regioes onde o tempo real de entrega consistentemente excede as estimativas, indicando gargalos logisticos geograficos que requerem atencao. A comparacao entre tempo real e estimado por localidade auxilia no planejamento de melhorias operacionais e ajuste de expectativas de entrega."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "581251fd-d17c-497f-854d-4051c162510d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Etapa 1: Carregamento e Agregacao por Localidade\n",
    "\n",
    "Carrega a tabela gold.ft_atrasos_pedidos_local_vendedor e calcula as medias de tempo de entrega real e estimado por cidade e estado. Arredonda as medias para 2 casas decimais conforme requisito de padronizacao de metricas. Cria indicador booleano comparando se o tempo medio real excede o tempo medio estimado, classificando regioes com desempenho abaixo do esperado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "933a673c-18d8-4157-bfd4-a3b6442fe020",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"[ETAPA 1] Criacao da view: view_tempo_medio_entrega_localidade\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "source_table = f\"{catalog_name}.{gold_db_name}.ft_atrasos_pedidos_local_vendedor\"\n",
    "view_name = f\"{catalog_name}.{gold_db_name}.view_tempo_medio_entrega_localidade\"\n",
    "\n",
    "print(f\"\\nOrigem: {source_table}\")\n",
    "print(f\"Destino: {view_name}\")\n",
    "\n",
    "df_source = spark.table(source_table)\n",
    "\n",
    "df_source_filtrado = df_source.filter(\n",
    "    (col(\"entrega_no_prazo\").isin(\"Sim\", \"Nao\")) &\n",
    "    col(\"tempo_entrega_dias\").isNotNull() &\n",
    "    col(\"tempo_entrega_estimado_dias\").isNotNull()\n",
    ")\n",
    "\n",
    "total_pedidos_filtrados = df_source_filtrado.count()\n",
    "print(f\"\\nPedidos validos para calculo (excluindo 'Nao Entregue' e NULLs): {total_pedidos_filtrados:,}\")\n",
    "\n",
    "df_view_localidade = df_source_filtrado.groupBy(\"cidade\", \"estado\").agg(\n",
    "    spark_round(F.avg(\"tempo_entrega_dias\"), 2).alias(\"tempo_medio_entrega\"),\n",
    "    spark_round(F.avg(\"tempo_entrega_estimado_dias\"), 2).alias(\"tempo_medio_estimado\")\n",
    ").withColumn(\n",
    "    \"entrega_maior_que_estimado\",\n",
    "    when(col(\"tempo_medio_entrega\") > col(\"tempo_medio_estimado\"), lit(\"SIM\"))\n",
    "        .otherwise(lit(\"NAO\"))\n",
    ")\n",
    "\n",
    "total_localidades = df_view_localidade.count()\n",
    "print(f\"\\nLocalidades processadas: {total_localidades:,}\")\n",
    "\n",
    "df_view_localidade.write.format(\"delta\").mode(\"overwrite\").saveAsTable(view_name)\n",
    "print(f\"\\n[ETAPA 1] View criada com sucesso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42ce1b7e-af8a-4686-ab8f-c498f21647c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Etapa 2: Validacao e Analise da View de Localidade\n",
    "\n",
    "Valida a view criada verificando schema, tipos de dados e distribuicao dos indicadores. Exibe amostra de localidades com tempo real excedendo estimativa para validacao da logica de negocio. Calcula estatisticas agregadas para identificar proporcao de regioes problematicas onde entregas consistentemente ultrapassam o prazo estimado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3c29f0d-3cdc-4af9-8d20-9655a432c50e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[ETAPA 2] Validacao da view: view_tempo_medio_entrega_localidade\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_view_read = spark.table(view_name)\n",
    "count_view = df_view_read.count()\n",
    "\n",
    "print(f\"\\nTotal de localidades na view: {count_view:,}\")\n",
    "\n",
    "print(\"\\nSchema da view:\")\n",
    "df_view_read.printSchema()\n",
    "\n",
    "print(\"\\n[ETAPA 2] Amostra de localidades com entrega acima do estimado:\")\n",
    "display(\n",
    "    df_view_read.filter(col(\"entrega_maior_que_estimado\") == \"SIM\")\n",
    "    .orderBy(col(\"tempo_medio_entrega\").desc())\n",
    "    .limit(20)\n",
    ")\n",
    "\n",
    "print(\"\\n[ETAPA 2] Distribuicao por indicador:\")\n",
    "display(\n",
    "    df_view_read.groupBy(\"entrega_maior_que_estimado\")\n",
    "    .agg(F.count(\"*\").alias(\"total_localidades\"))\n",
    "    .orderBy(\"entrega_maior_que_estimado\")\n",
    ")\n",
    "\n",
    "print(\"\\n[ETAPA 2] Top 10 estados com maior tempo medio de entrega:\")\n",
    "display(\n",
    "    df_view_read.groupBy(\"estado\")\n",
    "    .agg(\n",
    "        F.round(F.avg(\"tempo_medio_entrega\"), 2).alias(\"tempo_medio_estado\"),\n",
    "        F.count(\"*\").alias(\"total_cidades\")\n",
    "    )\n",
    "    .orderBy(col(\"tempo_medio_estado\").desc())\n",
    "    .limit(10)\n",
    ")\n",
    "\n",
    "metricas_view_localidade = {\n",
    "    \"View\": view_name,\n",
    "    \"Total de localidades\": f\"{count_view:,}\",\n",
    "    \"Origem\": source_table,\n",
    "    \"Metricas\": \"tempo_medio_entrega (2 casas), tempo_medio_estimado (2 casas)\",\n",
    "    \"Status\": \"Criada e validada com sucesso\"\n",
    "}\n",
    "\n",
    "log_metricas(\"view_tempo_medio_entrega_localidade\", metricas_view_localidade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VALIDACAO ADICIONAL: Verificacao de Exclusoes\n",
    "\n",
    "Valida que a view excluiu corretamente pedidos \"Nao Entregue\" e valores NULL, garantindo que apenas tempos reais de entrega sejam considerados nas medias por localidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VALIDACAO: Verificacao de registros excluidos\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Contar pedidos \"Nao Entregue\" na tabela fonte\n",
    "df_source_original = spark.table(source_table)\n",
    "total_nao_entregue = df_source_original.filter(col(\"entrega_no_prazo\") == \"Nao Entregue\").count()\n",
    "total_null_tempo_entrega = df_source_original.filter(col(\"tempo_entrega_dias\").isNull()).count()\n",
    "total_null_tempo_estimado = df_source_original.filter(col(\"tempo_entrega_estimado_dias\").isNull()).count()\n",
    "\n",
    "print(f\"\\nRegistros excluidos da view:\")\n",
    "print(f\"  - Pedidos 'Nao Entregue': {total_nao_entregue:,}\")\n",
    "print(f\"  - Pedidos com tempo_entrega_dias NULL: {total_null_tempo_entrega:,}\")\n",
    "print(f\"  - Pedidos com tempo_entrega_estimado_dias NULL: {total_null_tempo_estimado:,}\")\n",
    "\n",
    "# Verificar que a view nao tem NULLs nas medias\n",
    "df_view_check = spark.table(view_name)\n",
    "medias_null = df_view_check.filter(\n",
    "    col(\"tempo_medio_entrega\").isNull() | col(\"tempo_medio_estimado\").isNull()\n",
    ").count()\n",
    "\n",
    "if medias_null > 0:\n",
    "    print(f\"\\n  ALERTA: {medias_null} localidades com medias NULL na view\")\n",
    "else:\n",
    "    print(f\"\\n  OK: Nenhuma localidade com medias NULL na view\")\n",
    "\n",
    "print(\"\\nAmostra de localidades com entregas validas:\")\n",
    "display(df_view_check.orderBy(col(\"tempo_medio_entrega\").desc()).limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "162a5d6a-a5d4-49ed-b1ac-71256da14717",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Questao 2.2.2 - view_vendedor_pontualidade\n",
    "\n",
    "**Descricao:** View agregando metricas de pontualidade por vendedor, calculando taxa de atraso para identificar vendedores com baixo desempenho logistico.\n",
    "\n",
    "**Origem dos Dados:**\n",
    "- gold.ft_atrasos_pedidos_local_vendedor\n",
    "\n",
    "**Estrutura da View:**\n",
    "- id_vendedor: Identificador do vendedor (STRING)\n",
    "- total_pedidos: Quantidade total de pedidos do vendedor (BIGINT)\n",
    "- total_atrasados: Quantidade de pedidos com atraso (entrega_no_prazo = \"Nao\") (BIGINT)\n",
    "- percentual_atraso: Proporcao percentual de pedidos atrasados, arredondada com 2 casas decimais (DECIMAL)\n",
    "\n",
    "**Regras de Negocio:**\n",
    "- Atraso e definido como entrega_no_prazo = \"Nao\"\n",
    "- percentual_atraso = (total_atrasados / total_pedidos) * 100\n",
    "- Vendedores com percentual_atraso alto requerem investigacao e acoes corretivas\n",
    "\n",
    "**Proposito:** Esta view permite identificar vendedores com maior incidencia de atrasos, facilitando acoes de melhoria operacional direcionadas. A metrica de percentual de atraso normaliza o desempenho independente do volume de pedidos, permitindo comparacao justa entre vendedores de diferentes portes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5705d2ed-b260-402a-a205-727c13bea292",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Etapa 1: Calculo de Metricas de Pontualidade por Vendedor\n",
    "\n",
    "Carrega a tabela gold.ft_atrasos_pedidos_local_vendedor e calcula tres metricas essenciais por vendedor: total de pedidos, total de pedidos atrasados (entrega_no_prazo = \"Nao\") e percentual de atraso. O percentual e calculado como proporcao de pedidos atrasados sobre o total, multiplicado por 100 e arredondado para 2 casas decimais. Esta agregacao permite identificar vendedores com desempenho logistico abaixo do esperado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abe49a05-2398-475d-b5a9-233f0eecb553",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"[ETAPA 1] Criacao da view: view_vendedor_pontualidade\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "view_name_vendedor = f\"{catalog_name}.{gold_db_name}.view_vendedor_pontualidade\"\n",
    "\n",
    "print(f\"\\nOrigem: {source_table}\")\n",
    "print(f\"Destino: {view_name_vendedor}\")\n",
    "\n",
    "df_source_vendedor = spark.table(source_table)\n",
    "\n",
    "df_view_vendedor = df_source_vendedor.groupBy(\"id_vendedor\").agg(\n",
    "    F.count(\"*\").alias(\"total_pedidos\"),\n",
    "    F.sum(when(col(\"entrega_no_prazo\") == \"Nao\", 1).otherwise(0)).alias(\"total_atrasados\")\n",
    ").withColumn(\n",
    "    \"percentual_atraso\",\n",
    "    F.round((col(\"total_atrasados\") / col(\"total_pedidos\")) * 100, 2)\n",
    ")\n",
    "\n",
    "total_vendedores = df_view_vendedor.count()\n",
    "print(f\"\\nVendedores processados: {total_vendedores:,}\")\n",
    "\n",
    "df_view_vendedor.write.format(\"delta\").mode(\"overwrite\").saveAsTable(view_name_vendedor)\n",
    "print(f\"\\n[ETAPA 1] View criada com sucesso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02b6f4d7-bd0d-465e-b177-dff00e5f30cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Etapa 2: Validacao e Analise da View de Pontualidade\n",
    "\n",
    "Valida a view criada verificando schema, tipos de dados e distribuicao de percentuais de atraso. Exibe vendedores com maior taxa de atraso para identificacao de casos criticos que requerem atencao imediata. Calcula estatisticas agregadas incluindo media e mediana de percentual de atraso, permitindo benchmark de desempenho e identificacao de outliers na pontualidade de entregas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ffe13cb-52de-4d62-8817-c95ad85c5be4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[ETAPA 2] Validacao da view: view_vendedor_pontualidade\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_view_vendedor_read = spark.table(view_name_vendedor)\n",
    "count_vendedores = df_view_vendedor_read.count()\n",
    "\n",
    "print(f\"\\nTotal de vendedores na view: {count_vendedores:,}\")\n",
    "\n",
    "print(\"\\nSchema da view:\")\n",
    "df_view_vendedor_read.printSchema()\n",
    "\n",
    "print(\"\\n[ETAPA 2] Top 20 vendedores com maior percentual de atraso:\")\n",
    "display(\n",
    "    df_view_vendedor_read.orderBy(col(\"percentual_atraso\").desc())\n",
    "    .limit(20)\n",
    ")\n",
    "\n",
    "print(\"\\n[ETAPA 2] Top 20 vendedores com melhor pontualidade:\")\n",
    "display(\n",
    "    df_view_vendedor_read.orderBy(col(\"percentual_atraso\").asc())\n",
    "    .limit(20)\n",
    ")\n",
    "\n",
    "print(\"\\n[ETAPA 2] Estatisticas gerais de pontualidade:\")\n",
    "display(\n",
    "    df_view_vendedor_read.select(\n",
    "        F.round(F.avg(\"percentual_atraso\"), 2).alias(\"percentual_medio_atraso\"),\n",
    "        F.round(F.min(\"percentual_atraso\"), 2).alias(\"percentual_minimo\"),\n",
    "        F.round(F.max(\"percentual_atraso\"), 2).alias(\"percentual_maximo\"),\n",
    "        F.sum(\"total_pedidos\").alias(\"total_geral_pedidos\"),\n",
    "        F.sum(\"total_atrasados\").alias(\"total_geral_atrasados\")\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"\\n[ETAPA 2] Distribuicao de vendedores por faixa de atraso:\")\n",
    "display(\n",
    "    df_view_vendedor_read.select(\n",
    "        when(col(\"percentual_atraso\") < 10, lit(\"0-10%\"))\n",
    "        .when(col(\"percentual_atraso\") < 20, lit(\"10-20%\"))\n",
    "        .when(col(\"percentual_atraso\") < 30, lit(\"20-30%\"))\n",
    "        .when(col(\"percentual_atraso\") < 40, lit(\"30-40%\"))\n",
    "        .otherwise(lit(\"40%+\")).alias(\"faixa_atraso\")\n",
    "    ).groupBy(\"faixa_atraso\")\n",
    "    .agg(F.count(\"*\").alias(\"total_vendedores\"))\n",
    "    .orderBy(\"faixa_atraso\")\n",
    ")\n",
    "\n",
    "metricas_view_vendedor = {\n",
    "    \"View\": view_name_vendedor,\n",
    "    \"Total de vendedores\": f\"{count_vendedores:,}\",\n",
    "    \"Origem\": source_table,\n",
    "    \"Metricas\": \"total_pedidos, total_atrasados, percentual_atraso (2 casas)\",\n",
    "    \"Status\": \"Criada e validada com sucesso\"\n",
    "}\n",
    "\n",
    "log_metricas(\"view_vendedor_pontualidade\", metricas_view_vendedor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff3fb50a-dbb0-46ad-9469-dfab15dc8362",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Projeto 3 - Area Comercial (Analises de Vendas por Periodo)\n",
    "\n",
    "**Objetivo:** Criar dimensao de tempo para suportar analises temporais de vendas com granularidade diaria.\n",
    "\n",
    "**Contexto de Negocio:** A equipe Comercial necessita de uma dimensao de tempo estruturada para realizar analises de vendas por diferentes perspectivas temporais (ano, trimestre, mes, semana, dia). Esta dimensao permite agregacoes temporais consistentes e facilita identificacao de sazonalidades e tendencias de vendas ao longo do tempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45b75f0e-2b84-4b67-8a8a-9675ae86e418",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Questao 3.1 - dm_tempo (Dimensao de Tempo)\n",
    "\n",
    "**Descricao:** Tabela dimensao contendo todos os dias dentro de um periodo definido, com atributos temporais para analises multidimensionais de vendas.\n",
    "\n",
    "**Estrutura da Tabela:**\n",
    "- sk_tempo: Chave substituta - a propria data (DATE)\n",
    "- ano: Ano extraido da data (INT)\n",
    "- trimestre: Trimestre do ano, valores 1 a 4 (INT)\n",
    "- mes: Mes do ano, valores 1 a 12 (INT)\n",
    "- semana_do_ano: Semana do ano conforme ISO 8601 (INT)\n",
    "- dia: Dia do mes (INT)\n",
    "- dia_da_semana_num: Dia da semana numerico, 1=Domingo, 7=Sabado (INT)\n",
    "- dia_da_semana_nome: Nome do dia em portugues (STRING)\n",
    "- mes_nome: Nome do mes em portugues (STRING)\n",
    "- eh_fim_de_semana: Indicador \"Sim\" para sabado/domingo, \"Nao\" caso contrario (STRING)\n",
    "\n",
    "**Estrategia de Geracao:** Utiliza sequence + explode para gerar array de datas entre data_inicio e data_fim, depois explode para criar um registro por dia. Mapeamento de nomes em portugues garante consistencia independente de locale do sistema.\n",
    "\n",
    "**Particionamento:** Por ano e mes para otimizacao de queries que filtram por periodos especificos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c515bf2-30fd-4b23-a160-235d5d496fc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 1: Definicao de Parametros\n",
    "\n",
    "Define o periodo de abrangencia da dimensao tempo atraves das datas de inicio e fim. O periodo deve cobrir todas as datas presentes nas tabelas de fato para garantir integridade referencial nas analises temporais. Esta etapa estabelece os limites para a geracao da sequencia de datas que comporao a dimensao."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51c395be-950e-49ab-8b2e-09e66a52529c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"[ETAPA 3.3.1] Definicao de parametros para dimensao tempo\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "data_inicio = '2016-01-01'\n",
    "data_fim = '2018-12-31'\n",
    "\n",
    "print(f\"\\nParametros definidos:\")\n",
    "print(f\"  data_inicio: {data_inicio}\")\n",
    "print(f\"  data_fim: {data_fim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f3fb2f8-ca24-42c2-a455-a8a131c3b551",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 2: Geracao da Sequencia de Datas\n",
    "\n",
    "Utiliza as funcoes sequence e explode do PySpark para gerar todas as datas entre data_inicio e data_fim. A funcao sequence cria um array de datas com granularidade diaria, e explode transforma cada elemento do array em uma linha individual. Esta abordagem e eficiente e escalavel, gerando a sequencia completa de datas em uma unica operacao sem necessidade de loops ou iteracoes manuais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83d21175-25c5-4e8f-9d9f-ca5c30afc358",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[ETAPA 3.3.2] Gerando sequencia de datas\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_sequencia = spark.sql(f\"\"\"\n",
    "    SELECT explode(sequence(to_date('{data_inicio}'), to_date('{data_fim}'), interval 1 day)) as sk_tempo\n",
    "\"\"\")\n",
    "\n",
    "total_datas = df_sequencia.count()\n",
    "print(f\"\\nDatas geradas: {total_datas:,}\")\n",
    "print(f\"Data minima: {data_inicio}\")\n",
    "print(f\"Data maxima: {data_fim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb6520fc-c9f1-4972-b95a-fbc081b8c63d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 3: Calculo de Atributos Temporais\n",
    "\n",
    "Enriquece cada data com atributos temporais essenciais para analises multidimensionais: ano, trimestre, mes, semana do ano, dia do mes e dia da semana. Cria mapeamentos explicitos para nomes de dias e meses em portugues usando UDFs registradas, garantindo consistencia independente de configuracoes de locale do sistema. Adiciona indicador de fim de semana para facilitar analises de sazonalidade semanal. Todos os atributos sao calculados de forma deterministica a partir da data base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68255b89-8ece-4e2e-a068-bda0bb15b716",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[ETAPA 3.3.3] Calculando atributos temporais\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "spark.udf.register(\"mapear_dia_semana_udf\", mapear_dia_semana, StringType())\n",
    "spark.udf.register(\"mapear_mes_udf\", mapear_mes, StringType())\n",
    "\n",
    "df_tempo = df_sequencia.withColumn(\"ano\", year(col(\"sk_tempo\"))) \\\n",
    "    .withColumn(\"trimestre\", quarter(col(\"sk_tempo\"))) \\\n",
    "    .withColumn(\"mes\", month(col(\"sk_tempo\"))) \\\n",
    "    .withColumn(\"semana_do_ano\", weekofyear(col(\"sk_tempo\"))) \\\n",
    "    .withColumn(\"dia\", dayofmonth(col(\"sk_tempo\"))) \\\n",
    "    .withColumn(\"dia_da_semana_num\", dayofweek(col(\"sk_tempo\"))) \\\n",
    "    .withColumn(\"dia_da_semana_nome\", F.expr(\"mapear_dia_semana_udf(dia_da_semana_num)\")) \\\n",
    "    .withColumn(\"mes_nome\", F.expr(\"mapear_mes_udf(mes)\")) \\\n",
    "    .withColumn(\"eh_fim_de_semana\", \n",
    "                when((col(\"dia_da_semana_num\") == 1) | (col(\"dia_da_semana_num\") == 7), lit(\"Sim\"))\n",
    "                .otherwise(lit(\"Nao\")))\n",
    "\n",
    "print(\"\\nAtributos calculados:\")\n",
    "print(\"  - ano, trimestre, mes, semana_do_ano, dia\")\n",
    "print(\"  - dia_da_semana_num (1=Domingo, 7=Sabado)\")\n",
    "print(\"  - dia_da_semana_nome (mapeamento em portugues)\")\n",
    "print(\"  - mes_nome (mapeamento em portugues)\")\n",
    "print(\"  - eh_fim_de_semana (Sim/Nao)\")\n",
    "\n",
    "print(\"\\nSchema da dimensao:\")\n",
    "df_tempo.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cb1fd5b-6820-48e6-b0c1-b1210b73a6b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 4: Gravacao da Tabela Delta\n",
    "\n",
    "Persiste a dimensao tempo no formato Delta Lake no schema Gold com particionamento por ano e mes. O particionamento otimiza queries que filtram por periodos especificos, reduzindo a quantidade de dados lidos. A gravacao em modo overwrite garante que a dimensao seja recriada completamente a cada execucao, mantendo consistencia com os parametros de data_inicio e data_fim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a24ee11-483c-4dca-8387-78570aea70be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[ETAPA 3.3.4] Gravando gold.dm_tempo em Delta\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "ensure_database(gold_db_name)\n",
    "\n",
    "target_table = f\"{catalog_name}.{gold_db_name}.dm_tempo\"\n",
    "partition_cols = [\"ano\", \"mes\"]\n",
    "\n",
    "print(f\"\\nTabela destino: {target_table}\")\n",
    "print(f\"Particionamento: {', '.join(partition_cols)}\")\n",
    "\n",
    "total_a_gravar = df_tempo.count()\n",
    "print(f\"Registros a gravar: {total_a_gravar:,}\")\n",
    "\n",
    "print(\"\\nGravando tabela Delta...\")\n",
    "write_delta_overwrite(df_tempo, target_table, partition_cols=partition_cols)\n",
    "\n",
    "print(\"[ETAPA 33] Gravacao concluida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "422742e1-1c63-44e2-9d8f-8a4e0becbe52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 5: Validacao da Dimensao Tempo\n",
    "\n",
    "Valida a dimensao criada verificando contagem total de registros, datas minima e maxima, schema e tipos de dados. Exibe amostras de registros para verificacao visual da qualidade dos dados e dos mapeamentos de nomes em portugues. Calcula estatisticas de distribuicao por ano, trimestre e indicador de fim de semana para garantir que a dimensao foi criada corretamente e cobre todo o periodo especificado de forma uniforme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78fb1e72-8a69-455a-9aa8-7bad6632ea72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[ETAPA 3.3.5] Validacao da dimensao tempo\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_validacao = spark.table(target_table)\n",
    "\n",
    "count_validacao = df_validacao.count()\n",
    "data_min = df_validacao.select(F.min(\"sk_tempo\")).collect()[0][0]\n",
    "data_max = df_validacao.select(F.max(\"sk_tempo\")).collect()[0][0]\n",
    "\n",
    "print(f\"\\nEstatisticas gerais:\")\n",
    "print(f\"  Total de registros: {count_validacao:,}\")\n",
    "print(f\"  Data minima: {data_min}\")\n",
    "print(f\"  Data maxima: {data_max}\")\n",
    "\n",
    "if count_validacao != total_a_gravar:\n",
    "    print(f\"\\n  ATENCAO: Divergencia de contagem (esperado: {total_a_gravar:,})\")\n",
    "\n",
    "print(\"\\nSchema da tabela:\")\n",
    "df_validacao.printSchema()\n",
    "\n",
    "print(\"\\n[ETAPA 34] Amostra de registros (primeiros 15 dias):\")\n",
    "display(df_validacao.orderBy(\"sk_tempo\").limit(15))\n",
    "\n",
    "print(\"\\n[ETAPA 34] Amostra de registros (ultimos 15 dias):\")\n",
    "display(df_validacao.orderBy(col(\"sk_tempo\").desc()).limit(15))\n",
    "\n",
    "print(\"\\n[ETAPA 34] Distribuicao por ano:\")\n",
    "display(\n",
    "    df_validacao.groupBy(\"ano\")\n",
    "    .agg(F.count(\"*\").alias(\"total_dias\"))\n",
    "    .orderBy(\"ano\")\n",
    ")\n",
    "\n",
    "print(\"\\n[ETAPA 34] Distribuicao por trimestre (ano 2017):\")\n",
    "display(\n",
    "    df_validacao.filter(col(\"ano\") == 2017)\n",
    "    .groupBy(\"trimestre\")\n",
    "    .agg(F.count(\"*\").alias(\"total_dias\"))\n",
    "    .orderBy(\"trimestre\")\n",
    ")\n",
    "\n",
    "print(\"\\n[ETAPA 34] Distribuicao por dia da semana:\")\n",
    "display(\n",
    "    df_validacao.groupBy(\"dia_da_semana_num\", \"dia_da_semana_nome\", \"eh_fim_de_semana\")\n",
    "    .agg(F.count(\"*\").alias(\"total_dias\"))\n",
    "    .orderBy(\"dia_da_semana_num\")\n",
    ")\n",
    "\n",
    "print(\"\\n[ETAPA 34] Distribuicao por mes (ano 2017):\")\n",
    "display(\n",
    "    df_validacao.filter(col(\"ano\") == 2017)\n",
    "    .groupBy(\"mes\", \"mes_nome\")\n",
    "    .agg(F.count(\"*\").alias(\"total_dias\"))\n",
    "    .orderBy(\"mes\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd5fd38b-4d84-48a3-a0eb-33425690fce4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 6: Metricas Finais e Conclusao\n",
    "\n",
    "Registra as metricas finais de criacao da dimensao tempo incluindo contagem total de registros, periodo coberto e status de conclusao. Esta etapa documenta o resultado da execucao e fornece confirmacao da criacao bem-sucedida da dimensao, que agora esta disponivel para uso em joins com tabelas fato para analises temporais de vendas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdf22eb7-66c7-43da-9d96-e79c2137f515",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "metricas_dm_tempo = {\n",
    "    \"Tabela\": target_table,\n",
    "    \"Total de registros\": f\"{count_validacao:,}\",\n",
    "    \"Data inicio\": str(data_min),\n",
    "    \"Data fim\": str(data_max),\n",
    "    \"Particionamento\": \", \".join(partition_cols),\n",
    "    \"Atributos\": \"ano, trimestre, mes, semana_do_ano, dia, dia_da_semana, mes_nome, eh_fim_de_semana\",\n",
    "    \"Formato\": \"Delta Lake\",\n",
    "    \"Status\": \"Criada com sucesso\"\n",
    "}\n",
    "\n",
    "log_metricas(\"dm_tempo\", metricas_dm_tempo)\n",
    "\n",
    "print(\"[ETAPA 3.3.6] Dimensao de tempo gold.dm_tempo criada com sucesso\")\n",
    "print(f\"[ETAPA 35] Registros: {count_validacao:,}, Inicio: {data_min}, Fim: {data_max}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ffabdef-3e7a-4240-aedb-431fab8ec132",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Questao 3.2 - ft_vendas_geral (Tabela Fato Consolidada)\n",
    "\n",
    "**Descricao:** Tabela fato unificada integrando todas as dimensoes e metricas de vendas, incluindo valores em BRL e USD, avaliacoes e metricas logisticas.\n",
    "\n",
    "**Origem dos Dados:**\n",
    "- silver.ft_pedidos (informacoes do pedido, status, datas)\n",
    "- silver.ft_itens_pedidos (itens, valores produto e frete)\n",
    "- silver.ft_consumidores (cliente)\n",
    "- silver.dm_produtos (produto)\n",
    "- silver.ft_avaliacoes_pedidos (avaliacoes agregadas por pedido)\n",
    "- silver.ft_cotacao_dolar (conversao BRL para USD)\n",
    "\n",
    "**Estrutura da Tabela:**\n",
    "- id_pedido: Identificador do pedido (STRING)\n",
    "- id_item: Identificador do item (STRING)\n",
    "- fk_cliente: Chave estrangeira para dimensao cliente (STRING)\n",
    "- fk_produto: Chave estrangeira para dimensao produto (STRING)\n",
    "- fk_vendedor: Chave estrangeira para dimensao vendedor (STRING)\n",
    "- fk_tempo: Data da compra para join com dm_tempo (DATE)\n",
    "- status_pedido: Status do pedido (STRING)\n",
    "- tempo_entrega_dias: Tempo real de entrega em dias (INT)\n",
    "- entrega_no_prazo: Classificacao \"Sim\", \"Nao\" ou \"Nao Entregue\" (STRING)\n",
    "- valor_produto_brl: Valor do produto em BRL (DECIMAL(12,2))\n",
    "- valor_frete_brl: Valor do frete em BRL (DECIMAL(12,2))\n",
    "- valor_total_item_brl: Soma produto + frete em BRL (DECIMAL(12,2))\n",
    "- valor_produto_usd: Valor do produto em USD (DECIMAL(12,2))\n",
    "- valor_frete_usd: Valor do frete em USD (DECIMAL(12,2))\n",
    "- valor_total_item_usd: Soma produto + frete em USD (DECIMAL(12,2))\n",
    "- cotacao_dolar: Cotacao do dolar utilizada na conversao (DECIMAL(8,4))\n",
    "- avaliacao_pedido: Media das avaliacoes do pedido (DECIMAL(3,2))\n",
    "\n",
    "**Regras de Negocio:**\n",
    "- Conversao BRL para USD usa cotacao do dia do pedido\n",
    "- Avaliacoes agregadas por pedido (media)\n",
    "- Todos os valores financeiros arredondados com 2 casas decimais\n",
    "- Integridade referencial garantida com todas as dimensoes\n",
    "\n",
    "**Proposito:** Esta tabela fato e o nucleo do data warehouse Gold, consolidando todas as informacoes de vendas para analises multidimensionais. Permite analises por tempo, cliente, produto, vendedor, localidade, com metricas financeiras em multiplas moedas e indicadores de qualidade de servico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97108439-61c5-4c48-b709-a8880c5bf20b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 1: Carregamento das Tabelas Silver\n",
    "\n",
    "Carrega todas as tabelas Silver necessarias para construcao da tabela fato: ft_pedidos (dados do pedido), ft_itens_pedidos (itens e valores), ft_consumidores (clientes), dm_produtos (produtos), ft_avaliacoes_pedidos (avaliacoes) e ft_cotacao_dolar (taxas de cambio). Esta etapa estabelece a base de dados para a integracao multidimensional que comporao a fato consolidada de vendas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5087dd6-182c-4dfb-88a5-cb4fa675ad10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"[ETAPA 3.4.1] Carregamento das tabelas Silver\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_pedidos_source = validar_tabela_silver(\"ft_pedidos\")\n",
    "df_itens_pedidos_source = validar_tabela_silver(\"ft_itens_pedidos\")\n",
    "df_consumidores_source = validar_tabela_silver(\"ft_consumidores\")\n",
    "df_produtos_source = validar_tabela_silver(\"ft_produtos\")\n",
    "df_avaliacoes_source = validar_tabela_silver(\"ft_avaliacoes_pedidos\")\n",
    "df_cotacao_source = validar_tabela_silver(\"dm_cotacao_dolar\")\n",
    "\n",
    "print(\"\\n[ETAPA 01] Todas as tabelas Silver carregadas com sucesso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a4da51a-2c75-4aee-b0e9-c08b663a8e3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 2: Agregacao de Avaliacoes por Pedido\n",
    "\n",
    "Calcula a media das avaliacoes por pedido a partir da tabela ft_avaliacoes_pedidos. Como um pedido pode ter multiplas avaliacoes ao longo do tempo, esta agregacao consolida a nota media final de cada pedido. A metrica de avaliacao e essencial para analises de satisfacao do cliente e qualidade do servico, permitindo correlacoes com outras dimensoes como vendedor, produto e tempo de entrega."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c811f43a-d624-4ddc-af32-03fadfc1f16e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[ETAPA 3.4.2] Agregacao de avaliacoes por pedido\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_avaliacoes_agg = df_avaliacoes_source.groupBy(\"id_pedido\").agg(\n",
    "    spark_round(avg(\"avaliacao\"), 2).alias(\"avaliacao_pedido\")\n",
    ")\n",
    "\n",
    "total_pedidos_avaliados = df_avaliacoes_agg.count()\n",
    "print(f\"\\nPedidos com avaliacao: {total_pedidos_avaliados:,}\")\n",
    "\n",
    "print(\"\\n[ETAPA 02] Agregacao concluida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97e71765-44cb-490d-8394-578818cbd0c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 3: Preparacao da Base de Itens de Pedidos\n",
    "\n",
    "Prepara o dataframe principal a partir de ft_itens_pedidos, que contem a granularidade item-a-item necessaria para a tabela fato. Seleciona e tipifica as colunas essenciais incluindo identificadores (pedido, item, produto, vendedor) e valores financeiros (produto e frete em BRL). Esta base sera enriquecida com informacoes de outras tabelas atraves de joins sucessivos, mantendo a granularidade de item como nivel atomico da fato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c9f52ab-a750-4c4a-b5b9-cc63dd3ae466",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[ETAPA 3.4.3] Preparacao da base de itens\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_base = df_itens_pedidos_source.select(\n",
    "    col(\"id_pedido\").cast(\"string\").alias(\"id_pedido\"),\n",
    "    col(\"id_item\").cast(\"string\").alias(\"id_item\"),\n",
    "    col(\"id_produto\").cast(\"string\").alias(\"fk_produto\"),\n",
    "    col(\"id_vendedor\").cast(\"string\").alias(\"fk_vendedor\"),\n",
    "    spark_round(col(\"preco_brl\"), 2).alias(\"valor_produto_brl\"),\n",
    "    spark_round(col(\"preco_frete\"), 2).alias(\"valor_frete_brl\")\n",
    ")\n",
    "\n",
    "total_itens = df_base.count()\n",
    "print(f\"\\nTotal de itens processados: {total_itens:,}\")\n",
    "\n",
    "print(\"\\n[ETAPA 03] Base preparada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf4d3a5b-1533-4c0c-8ad2-4ee0a586f49e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 4: Enriquecimento com Dados de Pedidos\n",
    "\n",
    "Executa join left entre a base de itens e ft_pedidos para adicionar informacoes do pedido: cliente (fk_cliente), data da compra (fk_tempo), status, metricas de entrega (tempo_entrega_dias, entrega_no_prazo) e diferenca de entrega. O join left garante que todos os itens sejam mantidos mesmo se houver inconsistencias nos dados de pedido. A data de compra e essencial para posterior join com cotacao do dolar e dimensao tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d38c6c5c-67f4-49c5-8bd6-d407e582a076",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[ETAPA 3.4.4] Enriquecimento com dados de pedidos\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_pedidos_prep = df_pedidos_source.select(\n",
    "    col(\"id_pedido\").cast(\"string\").alias(\"id_pedido\"),\n",
    "    col(\"id_consumidor\").cast(\"string\").alias(\"fk_cliente\"),\n",
    "    to_date(col(\"pedido_compra_timestamp\")).alias(\"fk_tempo\"),\n",
    "    col(\"status\").alias(\"status_pedido\"),\n",
    "    col(\"diferenca_entrega_dias\").cast(\"int\").alias(\"tempo_entrega_dias\"),\n",
    "    col(\"entrega_no_prazo\")\n",
    ")\n",
    "\n",
    "df_enriched = df_base.join(\n",
    "    df_pedidos_prep,\n",
    "    on=\"id_pedido\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "total_enriched = df_enriched.count()\n",
    "print(f\"\\nRegistros apos join com pedidos: {total_enriched:,}\")\n",
    "\n",
    "print(\"\\n[ETAPA 04] Enriquecimento concluido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0a56da0-9496-4347-86c7-4a367b4f8798",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 5: Adicao de Avaliacoes\n",
    "\n",
    "Executa join left entre o dataframe enriquecido e as avaliacoes agregadas por pedido. O join left garante que itens de pedidos sem avaliacao sejam mantidos com valor nulo. A metrica de avaliacao permite analises de correlacao entre satisfacao do cliente e outras dimensoes como vendedor, produto, tempo de entrega e localidade, sendo fundamental para estrategias de melhoria de qualidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "928e2ba1-db60-4ec9-97b2-8ce21c7c3a66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[ETAPA 3.4.5] Adicao de avaliacoes\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_with_avaliacoes = df_enriched.join(\n",
    "    df_avaliacoes_agg,\n",
    "    on=\"id_pedido\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "total_with_avaliacoes = df_with_avaliacoes.count()\n",
    "itens_com_avaliacao = df_with_avaliacoes.filter(col(\"avaliacao_pedido\").isNotNull()).count()\n",
    "\n",
    "print(f\"\\nRegistros totais: {total_with_avaliacoes:,}\")\n",
    "print(f\"Itens com avaliacao: {itens_com_avaliacao:,}\")\n",
    "print(f\"Itens sem avaliacao: {total_with_avaliacoes - itens_com_avaliacao:,}\")\n",
    "\n",
    "print(\"\\n[ETAPA 05] Avaliacoes adicionadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a160aea3-738e-4d80-927d-a70e162b6e93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 6: Conversao de Valores para USD\n",
    "\n",
    "Executa join left com ft_cotacao_dolar usando fk_tempo (data da compra) para obter a cotacao do dolar do dia. Calcula valores em USD dividindo valores BRL pela cotacao e arredondando para 2 casas decimais. Calcula tambem o valor total do item (produto + frete) em ambas as moedas. A conversao para USD permite analises comparativas internacionais e protege contra distorcoes inflacionarias, sendo essencial para analises de tendencias de longo prazo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2a40b36-8e0a-4770-a6bf-7df180c16b38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[ETAPA 3.4.6] Conversao de valores para USD\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_cotacao_prep = df_cotacao_source.select(\n",
    "    to_date(col(\"data\")).alias(\"data_cotacao\"),\n",
    "    col(\"cotacao_dolar\").cast(DecimalType(8,4)).alias(\"cotacao_dolar\")\n",
    ")\n",
    "\n",
    "df_with_cotacao = df_with_avaliacoes.join(\n",
    "    df_cotacao_prep,\n",
    "    df_with_avaliacoes.fk_tempo == df_cotacao_prep.data_cotacao,\n",
    "    how=\"left\"\n",
    ").drop(\"data_cotacao\")\n",
    "\n",
    "df_with_usd = df_with_cotacao.withColumn(\n",
    "    \"valor_total_item_brl\",\n",
    "    spark_round(col(\"valor_produto_brl\") + col(\"valor_frete_brl\"), 2)\n",
    ").withColumn(\n",
    "    \"valor_produto_usd\",\n",
    "    spark_round(col(\"valor_produto_brl\") / col(\"cotacao_dolar\"), 2)\n",
    ").withColumn(\n",
    "    \"valor_frete_usd\",\n",
    "    spark_round(col(\"valor_frete_brl\") / col(\"cotacao_dolar\"), 2)\n",
    ").withColumn(\n",
    "    \"valor_total_item_usd\",\n",
    "    spark_round((col(\"valor_produto_brl\") + col(\"valor_frete_brl\")) / col(\"cotacao_dolar\"), 2)\n",
    ")\n",
    "\n",
    "total_with_usd = df_with_usd.count()\n",
    "itens_com_cotacao = df_with_usd.filter(col(\"cotacao_dolar\").isNotNull()).count()\n",
    "\n",
    "print(f\"\\nRegistros totais: {total_with_usd:,}\")\n",
    "print(f\"Itens com cotacao: {itens_com_cotacao:,}\")\n",
    "print(f\"Itens sem cotacao: {total_with_usd - itens_com_cotacao:,}\")\n",
    "\n",
    "print(\"\\n[ETAPA 06] Conversao concluida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2df99fdf-d282-4138-9c18-aef92212be60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 7: Selecao Final de Colunas\n",
    "\n",
    "Seleciona e organiza as colunas finais na ordem especificada para a tabela fato, garantindo tipagem correta e nomenclatura padronizada. Esta etapa finaliza a estrutura da tabela fato com todas as chaves estrangeiras (fk_cliente, fk_produto, fk_vendedor, fk_tempo), metricas de negocio (valores financeiros em BRL e USD, tempo de entrega) e indicadores de qualidade (avaliacao, entrega no prazo). A tabela resultante esta pronta para validacoes de integridade antes da persistencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05f9b1ca-fcc9-4609-8045-d4ae2921f6dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[ETAPA 3.4.7] Selecao final de colunas\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_fato = df_with_usd.withColumn(\"ano\", year(col(\"fk_tempo\"))).select(\n",
    "    col(\"id_pedido\"),\n",
    "    col(\"id_item\"),\n",
    "    col(\"fk_cliente\"),\n",
    "    col(\"fk_produto\"),\n",
    "    col(\"fk_vendedor\"),\n",
    "    col(\"fk_tempo\"),\n",
    "    col(\"status_pedido\"),\n",
    "    col(\"tempo_entrega_dias\"),\n",
    "    col(\"entrega_no_prazo\"),\n",
    "    col(\"valor_produto_brl\"),\n",
    "    col(\"valor_frete_brl\"),\n",
    "    col(\"valor_total_item_brl\"),\n",
    "    col(\"valor_produto_usd\"),\n",
    "    col(\"valor_frete_usd\"),\n",
    "    col(\"valor_total_item_usd\"),\n",
    "    col(\"cotacao_dolar\"),\n",
    "    col(\"avaliacao_pedido\"),\n",
    "    col(\"ano\")\n",
    ")\n",
    "\n",
    "total_fato = df_fato.count()\n",
    "print(f\"\\nRegistros na tabela fato: {total_fato:,}\")\n",
    "\n",
    "print(\"\\n[ETAPA 07] Estrutura final criada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcccaddc-91c6-495f-87e9-7726be29d6c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 8: Validacoes de Integridade\n",
    "\n",
    "Executa validacoes criticas de qualidade antes da persistencia: verifica chaves nulas (id_pedido, id_item, fk_cliente, fk_produto, fk_vendedor, fk_tempo), detecta duplicatas na chave composta (id_pedido, id_item) e valida valores financeiros anomalos. Estas validacoes garantem a integridade referencial da tabela fato e identificam problemas de qualidade de dados que podem comprometer analises downstream. Falhas nessas validacoes indicam necessidade de tratamento na camada Silver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "179b28f3-097f-44d3-9db2-de1922c08500",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[ETAPA 3.4.8] Validacoes de integridade\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nValidacao 1: Chaves nulas\")\n",
    "null_id_pedido = df_fato.filter(col(\"id_pedido\").isNull()).count()\n",
    "null_id_item = df_fato.filter(col(\"id_item\").isNull()).count()\n",
    "null_fk_cliente = df_fato.filter(col(\"fk_cliente\").isNull()).count()\n",
    "null_fk_produto = df_fato.filter(col(\"fk_produto\").isNull()).count()\n",
    "null_fk_vendedor = df_fato.filter(col(\"fk_vendedor\").isNull()).count()\n",
    "null_fk_tempo = df_fato.filter(col(\"fk_tempo\").isNull()).count()\n",
    "\n",
    "print(f\"  id_pedido nulo: {null_id_pedido}\")\n",
    "print(f\"  id_item nulo: {null_id_item}\")\n",
    "print(f\"  fk_cliente nulo: {null_fk_cliente}\")\n",
    "print(f\"  fk_produto nulo: {null_fk_produto}\")\n",
    "print(f\"  fk_vendedor nulo: {null_fk_vendedor}\")\n",
    "print(f\"  fk_tempo nulo: {null_fk_tempo}\")\n",
    "\n",
    "if any([null_id_pedido, null_id_item, null_fk_cliente, null_fk_produto, null_fk_vendedor, null_fk_tempo]):\n",
    "    print(\"  ATENCAO: Chaves nulas detectadas\")\n",
    "else:\n",
    "    print(\"  OK: Nenhuma chave nula\")\n",
    "\n",
    "print(\"\\nValidacao 2: Duplicatas na chave composta\")\n",
    "total_registros = df_fato.count()\n",
    "registros_distintos = df_fato.select(\"id_pedido\", \"id_item\").distinct().count()\n",
    "duplicatas = total_registros - registros_distintos\n",
    "\n",
    "print(f\"  Total de registros: {total_registros:,}\")\n",
    "print(f\"  Registros distintos: {registros_distintos:,}\")\n",
    "print(f\"  Duplicatas: {duplicatas}\")\n",
    "\n",
    "if duplicatas > 0:\n",
    "    print(\"  ATENCAO: Duplicatas detectadas na chave (id_pedido, id_item)\")\n",
    "else:\n",
    "    print(\"  OK: Nenhuma duplicata\")\n",
    "\n",
    "print(\"\\nValidacao 3: Valores financeiros\")\n",
    "valores_negativos = df_fato.filter(\n",
    "    (col(\"valor_produto_brl\") < 0) | \n",
    "    (col(\"valor_frete_brl\") < 0) |\n",
    "    (col(\"valor_total_item_brl\") < 0)\n",
    ").count()\n",
    "\n",
    "valores_nulos = df_fato.filter(\n",
    "    col(\"valor_produto_brl\").isNull() |\n",
    "    col(\"valor_frete_brl\").isNull() |\n",
    "    col(\"valor_total_item_brl\").isNull()\n",
    ").count()\n",
    "\n",
    "print(f\"  Valores negativos: {valores_negativos}\")\n",
    "print(f\"  Valores nulos: {valores_nulos}\")\n",
    "\n",
    "if valores_negativos > 0 or valores_nulos > 0:\n",
    "    print(\"  ATENCAO: Valores anomalos detectados\")\n",
    "else:\n",
    "    print(\"  OK: Todos os valores financeiros validos\")\n",
    "\n",
    "print(\"\\n[ETAPA 08] Validacoes concluidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32f5a304-2227-483a-b71d-42ba4de997f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 9: Gravacao da Tabela Fato Gold\n",
    "\n",
    "Persiste a tabela fato ft_vendas_geral no formato Delta Lake no schema Gold. A tabela nao utiliza particionamento fisico pois a granularidade item-a-item e as multiplas dimensoes de analise tornariam o particionamento ineficiente. O Delta Lake fornece otimizacoes automaticas (Z-ordering, data skipping) que sao mais adequadas para este caso de uso. A gravacao em modo overwrite garante substituicao completa dos dados a cada execucao."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33428786-7fec-4db9-bf90-5776cfa99c18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[ETAPA 3.4.9] Gravacao da tabela fato Gold\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "ensure_database(gold_db_name)\n",
    "\n",
    "target_table = f\"{catalog_name}.{gold_db_name}.ft_vendas_geral\"\n",
    "\n",
    "print(f\"\\nTabela destino: {target_table}\")\n",
    "\n",
    "total_a_gravar = df_fato.count()\n",
    "print(f\"Registros a gravar: {total_a_gravar:,}\")\n",
    "\n",
    "print(\"\\nGravando tabela Delta...\")\n",
    "write_delta_overwrite(df_fato, target_table, partition_cols=[\"ano\"])\n",
    "\n",
    "print(\"\\n[ETAPA 09] Gravacao concluida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "623bc54f-86d9-4c77-8c09-83ba750b7013",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 10: Validacao Pos-Gravacao e Visualizacao\n",
    "\n",
    "Valida a tabela gravada verificando contagem de registros, schema, tipos de dados e distribuicoes. Exibe amostras dos dados para verificacao visual da qualidade e consistencia das transformacoes. Calcula estatisticas agregadas por dimensoes chave (status, entrega no prazo, periodo) para confirmar a integridade dos dados e fornecer insights preliminares. Esta etapa final confirma que a tabela fato esta pronta para uso em analises e dashboards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ace0c2b5-c581-4c62-81f5-936643602753",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[ETAPA 3.4.10] Validacao pos-gravacao\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_validacao = spark.table(target_table)\n",
    "count_validacao = df_validacao.count()\n",
    "\n",
    "print(f\"\\nRegistros gravados: {count_validacao:,}\")\n",
    "\n",
    "if count_validacao != total_a_gravar:\n",
    "    print(f\"ATENCAO: Divergencia de contagem (esperado: {total_a_gravar:,})\")\n",
    "else:\n",
    "    print(\"OK: Contagem validada\")\n",
    "\n",
    "print(\"\\nSchema da tabela:\")\n",
    "df_validacao.printSchema()\n",
    "\n",
    "print(\"\\n[ETAPA 10] Amostra dos dados (20 registros):\")\n",
    "display(df_validacao.limit(20))\n",
    "\n",
    "print(\"\\n[ETAPA 10] Estatisticas por status de pedido:\")\n",
    "display(\n",
    "    df_validacao.groupBy(\"status_pedido\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"total_itens\"),\n",
    "        spark_round(F.sum(\"valor_total_item_brl\"), 2).alias(\"valor_total_brl\"),\n",
    "        spark_round(F.sum(\"valor_total_item_usd\"), 2).alias(\"valor_total_usd\"),\n",
    "        spark_round(F.avg(\"avaliacao_pedido\"), 2).alias(\"avaliacao_media\")\n",
    "    )\n",
    "    .orderBy(col(\"total_itens\").desc())\n",
    ")\n",
    "\n",
    "print(\"\\n[ETAPA 10] Estatisticas por entrega no prazo:\")\n",
    "display(\n",
    "    df_validacao.groupBy(\"entrega_no_prazo\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"total_itens\"),\n",
    "        spark_round(F.avg(\"tempo_entrega_dias\"), 2).alias(\"tempo_medio_entrega\"),\n",
    "        spark_round(F.avg(\"avaliacao_pedido\"), 2).alias(\"avaliacao_media\")\n",
    "    )\n",
    "    .orderBy(\"entrega_no_prazo\")\n",
    ")\n",
    "\n",
    "print(\"\\n[ETAPA 10] Estatisticas por ano:\")\n",
    "display(\n",
    "    df_validacao.withColumn(\"ano\", year(col(\"fk_tempo\")))\n",
    "    .groupBy(\"ano\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"total_itens\"),\n",
    "        spark_round(F.sum(\"valor_total_item_brl\"), 2).alias(\"valor_total_brl\"),\n",
    "        spark_round(F.sum(\"valor_total_item_usd\"), 2).alias(\"valor_total_usd\")\n",
    "    )\n",
    "    .orderBy(\"ano\")\n",
    ")\n",
    "\n",
    "print(\"\\n[ETAPA 10] Cobertura de dados:\")\n",
    "total_registros = df_validacao.count()\n",
    "com_avaliacao = df_validacao.filter(col(\"avaliacao_pedido\").isNotNull()).count()\n",
    "com_cotacao = df_validacao.filter(col(\"cotacao_dolar\").isNotNull()).count()\n",
    "\n",
    "print(f\"  Total de itens: {total_registros:,}\")\n",
    "print(f\"  Com avaliacao: {com_avaliacao:,} ({100*com_avaliacao/total_registros:.1f}%)\")\n",
    "print(f\"  Com cotacao USD: {com_cotacao:,} ({100*com_cotacao/total_registros:.1f}%)\")\n",
    "\n",
    "metricas_fato = {\n",
    "    \"Tabela\": target_table,\n",
    "    \"Total de itens\": f\"{count_validacao:,}\",\n",
    "    \"Origem\": \"ft_pedidos, ft_itens_pedidos, ft_consumidores, dm_produtos, ft_avaliacoes_pedidos, ft_cotacao_dolar\",\n",
    "    \"Chaves estrangeiras\": \"fk_cliente, fk_produto, fk_vendedor, fk_tempo\",\n",
    "    \"Metricas\": \"valores BRL/USD, tempo entrega, avaliacao\",\n",
    "    \"Formato\": \"Delta Lake\",\n",
    "    \"Status\": \"Criada com sucesso\"\n",
    "}\n",
    "\n",
    "log_metricas(\"ft_vendas_geral\", metricas_fato)\n",
    "\n",
    "print(\"\\n[ETAPA 10] Tabela fato gold.ft_vendas_geral criada e validada com sucesso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b833184-2e95-4955-b322-8612d39107ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Questao 3.3 - view_vendas_por_periodo\n",
    "\n",
    "**Descricao:** View analitica consolidando vendas por diferentes granularidades temporais (ano, trimestre, mes, dia da semana) para analises de sazonalidade e tendencias.\n",
    "\n",
    "**Origem dos Dados:**\n",
    "- gold.ft_vendas_geral (metricas de vendas)\n",
    "- gold.dm_tempo (dimensao tempo para consistencia de nomes)\n",
    "\n",
    "**Estrutura da View:**\n",
    "- ano: Ano da venda (INT)\n",
    "- trimestre: Trimestre do ano, valores 1 a 4 (INT)\n",
    "- mes: Mes do ano, valores 1 a 12 (INT)\n",
    "- mes_nome: Nome do mes em portugues (STRING)\n",
    "- dia: Dia do mes (INT)\n",
    "- dia_da_semana_num: Dia da semana numerico, 1=Domingo, 7=Sabado (INT)\n",
    "- total_pedidos: Quantidade de pedidos distintos (BIGINT)\n",
    "- total_itens: Quantidade total de itens vendidos (BIGINT)\n",
    "- receita_total_brl: Receita total em BRL (DECIMAL(12,2))\n",
    "- receita_total_usd: Receita total em USD (DECIMAL(12,2))\n",
    "- ticket_medio_brl: Ticket medio por item em BRL (DECIMAL(12,2))\n",
    "- avaliacao_media: Media das avaliacoes de pedidos entregues/enviados (DECIMAL(3,2))\n",
    "\n",
    "**Regras de Negocio:**\n",
    "- ticket_medio_brl = receita_total_brl / total_itens\n",
    "- avaliacao_media considera apenas pedidos com status 'entregue' ou 'enviado'\n",
    "- Join com dm_tempo garante consistencia de nomes e numeracao de dias\n",
    "- Todos os valores arredondados com 2 casas decimais\n",
    "\n",
    "**Proposito:** Esta view permite analises temporais multidimensionais de vendas, identificando padroes de sazonalidade por diferentes granularidades (anual, trimestral, mensal, semanal). Essencial para previsao de demanda, planejamento de estoque e estrategias comerciais baseadas em ciclos temporais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ca68f7e-c326-4bf9-b17c-44f1ca279f7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 1: Carregamento das Tabelas Gold\n",
    "\n",
    "Carrega as tabelas gold.ft_vendas_geral (fonte das metricas de vendas) e gold.dm_tempo (dimensao tempo para garantir consistencia de nomes de meses e dias da semana). O join entre essas tabelas assegura que os atributos temporais estejam normalizados conforme a dimensao tempo, mantendo coerencia entre diferentes analises temporais no data warehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1c177a2-05ad-4102-82ee-74eccd925278",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"[ETAPA 3.5.1] Lendo tabelas Gold\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_vendas = spark.table(f\"{catalog_name}.{gold_db_name}.ft_vendas_geral\")\n",
    "df_tempo = spark.table(f\"{catalog_name}.{gold_db_name}.dm_tempo\")\n",
    "\n",
    "total_itens_vendas = df_vendas.count()\n",
    "total_datas_tempo = df_tempo.count()\n",
    "\n",
    "print(f\"\\nft_vendas_geral: {total_itens_vendas:,} registros\")\n",
    "print(f\"dm_tempo: {total_datas_tempo:,} registros\")\n",
    "\n",
    "print(\"\\n[ETAPA 3.5.1] Tabelas carregadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3edf6557-0148-4dc6-a2da-45a9fb42dfce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 2: Filtragem e Preparacao dos Dados\n",
    "\n",
    "Filtra registros da tabela fato removendo linhas com chaves nulas (fk_tempo, id_pedido, id_item) que comprometem a integridade da analise temporal. Executa join left com dm_tempo usando fk_tempo = sk_tempo para enriquecer os dados com atributos temporais normalizados (mes_nome, dia_da_semana_num). Esta preparacao garante qualidade e consistencia dos dados antes da agregacao."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17bd330f-5c1e-47f3-8919-0412dd72219b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[ETAPA 3.5.2] Filtragem e join com dimensao tempo\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_vendas_filtrado = df_vendas.filter(\n",
    "    col(\"fk_tempo\").isNotNull() &\n",
    "    col(\"id_pedido\").isNotNull() &\n",
    "    col(\"id_item\").isNotNull()\n",
    ")\n",
    "\n",
    "total_antes = df_vendas.count()\n",
    "total_depois = df_vendas_filtrado.count()\n",
    "registros_removidos = total_antes - total_depois\n",
    "\n",
    "print(f\"\\nRegistros antes do filtro: {total_antes:,}\")\n",
    "print(f\"Registros apos filtro: {total_depois:,}\")\n",
    "print(f\"Registros removidos: {registros_removidos:,}\")\n",
    "\n",
    "df_tempo_prep = df_tempo.select(\n",
    "    col(\"sk_tempo\"),\n",
    "    col(\"mes_nome\"),\n",
    "    col(\"dia_da_semana_num\")\n",
    ")\n",
    "\n",
    "df_vendas_enriched = df_vendas_filtrado.join(\n",
    "    df_tempo_prep,\n",
    "    df_vendas_filtrado.fk_tempo == df_tempo_prep.sk_tempo,\n",
    "    how=\"left\"\n",
    ").drop(\"sk_tempo\")\n",
    "\n",
    "total_enriched = df_vendas_enriched.count()\n",
    "print(f\"\\nRegistros apos join com dm_tempo: {total_enriched:,}\")\n",
    "\n",
    "print(\"\\n[ETAPA 3.5.2] Dados preparados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9f5b27d-79fc-4229-b35e-88763ee2177d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 3: Agregacao por Dimensoes Temporais\n",
    "\n",
    "Agrega os dados por ano, trimestre, mes, dia e dia da semana, calculando as metricas essenciais: total de pedidos distintos, total de itens, receitas em BRL e USD, ticket medio por item e avaliacao media. A avaliacao media e filtrada para considerar apenas pedidos com status 'entregue' ou 'enviado', refletindo a satisfacao real do cliente com pedidos completados. Todas as metricas financeiras sao arredondadas para 2 casas decimais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc245d6a-6799-4e5a-b1d7-6a4663123ad6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[ETAPA 3.5.3] Agregando por ano, trimestre, mes, dia da semana\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_agregado = df_vendas_enriched.groupBy(\n",
    "    year(col(\"fk_tempo\")).alias(\"ano\"),\n",
    "    quarter(col(\"fk_tempo\")).alias(\"trimestre\"),\n",
    "    month(col(\"fk_tempo\")).alias(\"mes\"),\n",
    "    col(\"mes_nome\"),\n",
    "    dayofmonth(col(\"fk_tempo\")).alias(\"dia\"),\n",
    "    col(\"dia_da_semana_num\")\n",
    ").agg(\n",
    "    F.countDistinct(\"id_pedido\").alias(\"total_pedidos\"),\n",
    "    F.count(\"id_item\").alias(\"total_itens\"),\n",
    "    spark_round(F.sum(\"valor_total_item_brl\"), 2).alias(\"receita_total_brl\"),\n",
    "    spark_round(F.sum(\"valor_total_item_usd\"), 2).alias(\"receita_total_usd\"),\n",
    "    spark_round(\n",
    "        F.avg(\n",
    "            when(\n",
    "                (col(\"status_pedido\") == \"entregue\") | (col(\"status_pedido\") == \"enviado\"),\n",
    "                col(\"avaliacao_pedido\")\n",
    "            )\n",
    "        ), 2\n",
    "    ).alias(\"avaliacao_media\")\n",
    ")\n",
    "\n",
    "df_view = df_agregado.withColumn(\n",
    "    \"ticket_medio_brl\",\n",
    "    spark_round(\n",
    "        when(col(\"total_itens\") > 0, col(\"receita_total_brl\") / col(\"total_itens\"))\n",
    "        .otherwise(lit(0)), \n",
    "        2\n",
    "    )\n",
    ")\n",
    "\n",
    "total_grupos = df_view.count()\n",
    "print(f\"\\nGrupos temporais criados: {total_grupos:,}\")\n",
    "\n",
    "print(\"\\n[ETAPA 3.5.3] Agregacao concluida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a325c837-64f2-428c-ad58-698685af0e16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 4: Criacao da View Gold\n",
    "\n",
    "Persiste o dataframe agregado como view gold.view_vendas_por_periodo no formato Delta. A view consolida vendas por multiplas granularidades temporais (ano, trimestre, mes, dia, dia da semana) com metricas essenciais de receita, volume e satisfacao. Esta estrutura permite analises rapidas de sazonalidade, tendencias e padroes de vendas sem necessidade de reprocessamento da tabela fato completa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23147615-8004-4071-8ddd-0e73d3a9c7c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[ETAPA 3.5.4] Criando view gold.view_vendas_por_periodo\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "view_name = f\"{catalog_name}.{gold_db_name}.view_vendas_por_periodo\"\n",
    "\n",
    "print(f\"\\nView: {view_name}\")\n",
    "\n",
    "df_view.write.format(\"delta\").mode(\"overwrite\").saveAsTable(view_name)\n",
    "\n",
    "print(\"\\n[ETAPA 3.5.4] View criada com sucesso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e01a29a-d884-4626-8140-7c2e9e7b3048",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 5: Validacao da View\n",
    "\n",
    "Valida a view criada verificando contagem total de registros, intervalo de anos cobertos (minimo e maximo), schema e tipos de dados. Exibe amostras dos dados para inspecao visual da qualidade das agregacoes. Valida a consistencia das metricas calculadas verificando que ticket_medio_brl = receita_total_brl / total_itens em amostras. Calcula estatisticas agregadas por ano e dia da semana para confirmar a distribuicao temporal dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6d77ce5-b7bf-4789-affd-579d135b1e57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[ETAPA 3.5.5] Validacao da view\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_view_read = spark.table(view_name)\n",
    "\n",
    "count_view = df_view_read.count()\n",
    "ano_min = df_view_read.select(F.min(\"ano\")).collect()[0][0]\n",
    "ano_max = df_view_read.select(F.max(\"ano\")).collect()[0][0]\n",
    "\n",
    "print(f\"\\nTotal de registros na view: {count_view:,}\")\n",
    "print(f\"Periodo coberto: {ano_min} a {ano_max}\")\n",
    "\n",
    "print(\"\\nSchema da view:\")\n",
    "df_view_read.printSchema()\n",
    "\n",
    "print(\"\\n[ETAPA 45] Amostra dos dados (20 registros ordenados por ano/mes/dia):\")\n",
    "display(\n",
    "    df_view_read.orderBy(\"ano\", \"mes\", \"dia\")\n",
    "    .limit(20)\n",
    ")\n",
    "\n",
    "print(\"\\n[ETAPA 45] Validacao do ticket medio (amostra):\")\n",
    "display(\n",
    "    df_view_read.withColumn(\n",
    "        \"ticket_calculado\",\n",
    "        spark_round(col(\"receita_total_brl\") / col(\"total_itens\"), 2)\n",
    "    ).withColumn(\n",
    "        \"diferenca\",\n",
    "        spark_round(col(\"ticket_medio_brl\") - col(\"ticket_calculado\"), 2)\n",
    "    ).select(\n",
    "        \"ano\", \"mes\", \"dia\",\n",
    "        \"receita_total_brl\", \"total_itens\",\n",
    "        \"ticket_medio_brl\", \"ticket_calculado\", \"diferenca\"\n",
    "    ).orderBy(\"ano\", \"mes\", \"dia\")\n",
    "    .limit(10)\n",
    ")\n",
    "\n",
    "print(\"\\n[ETAPA 45] Agregacao por ano:\")\n",
    "display(\n",
    "    df_view_read.groupBy(\"ano\")\n",
    "    .agg(\n",
    "        F.sum(\"total_pedidos\").alias(\"pedidos_ano\"),\n",
    "        F.sum(\"total_itens\").alias(\"itens_ano\"),\n",
    "        spark_round(F.sum(\"receita_total_brl\"), 2).alias(\"receita_ano_brl\"),\n",
    "        spark_round(F.sum(\"receita_total_usd\"), 2).alias(\"receita_ano_usd\")\n",
    "    )\n",
    "    .orderBy(\"ano\")\n",
    ")\n",
    "\n",
    "print(\"\\n[ETAPA 45] Agregacao por dia da semana:\")\n",
    "display(\n",
    "    df_view_read.groupBy(\"dia_da_semana_num\")\n",
    "    .agg(\n",
    "        F.sum(\"total_pedidos\").alias(\"pedidos_dia_semana\"),\n",
    "        F.sum(\"total_itens\").alias(\"itens_dia_semana\"),\n",
    "        spark_round(F.sum(\"receita_total_brl\"), 2).alias(\"receita_dia_semana_brl\"),\n",
    "        spark_round(F.avg(\"avaliacao_media\"), 2).alias(\"avaliacao_media_geral\")\n",
    "    )\n",
    "    .orderBy(\"dia_da_semana_num\")\n",
    ")\n",
    "\n",
    "print(\"\\n[ETAPA 45] Agregacao por mes (ano 2017):\")\n",
    "display(\n",
    "    df_view_read.filter(col(\"ano\") == 2017)\n",
    "    .groupBy(\"mes\", \"mes_nome\")\n",
    "    .agg(\n",
    "        F.sum(\"total_pedidos\").alias(\"pedidos_mes\"),\n",
    "        F.sum(\"total_itens\").alias(\"itens_mes\"),\n",
    "        spark_round(F.sum(\"receita_total_brl\"), 2).alias(\"receita_mes_brl\")\n",
    "    )\n",
    "    .orderBy(\"mes\")\n",
    ")\n",
    "\n",
    "metricas_view = {\n",
    "    \"View\": view_name,\n",
    "    \"Total de registros\": f\"{count_view:,}\",\n",
    "    \"Periodo\": f\"{ano_min} a {ano_max}\",\n",
    "    \"Origem\": \"ft_vendas_geral, dm_tempo\",\n",
    "    \"Granularidades\": \"ano, trimestre, mes, dia, dia_da_semana\",\n",
    "    \"Metricas\": \"pedidos, itens, receitas BRL/USD, ticket medio, avaliacao\",\n",
    "    \"Status\": \"Criada e validada com sucesso\"\n",
    "}\n",
    "\n",
    "log_metricas(\"view_vendas_por_periodo\", metricas_view)\n",
    "\n",
    "print(\"\\n[ETAPA 45] View gold.view_vendas_por_periodo validada com sucesso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f6ee38a-f9f0-44cb-93ce-cd6b6309d8b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Questao 3.3.1 - Consultas Analiticas\n",
    "\n",
    "**Objetivo:** Executar consultas analiticas solicitadas pela equipe Comercial para avaliar padroes de vendas e sazonalidade usando exclusivamente a view gold.view_vendas_por_periodo.\n",
    "\n",
    "**Consultas:**\n",
    "1. Dia da semana com maior receita total em BRL\n",
    "2. Mes com maior ticket medio no ultimo ano disponivel\n",
    "\n",
    "**Proposito:** Estas consultas demonstram o uso da view agregada para responder rapidamente perguntas de negocio sobre padroes temporais de vendas, sem necessidade de processar a tabela fato completa. Identificam oportunidades de otimizacao de operacoes e estrategias comerciais baseadas em sazonalidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "934f6efe-618f-4b99-a574-28db85aa5131",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Consulta 1: Dia da Semana com Maior Receita\n",
    "\n",
    "Identifica qual dia da semana gera maior receita total em BRL ao longo de todo o periodo analisado. Agrega a receita por dia da semana somando todas as ocorrencias daquele dia, independente do ano, mes ou data especifica. Esta analise revela padroes semanais de vendas que podem direcionar estrategias de marketing, promocoes e gestao de estoque conforme a demanda esperada em cada dia da semana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10c019d1-9d08-4a25-ba3c-590ae8a9c77a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"[ETAPA 3.5.1.1] Calculando receita por dia da semana\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_view_vendas = spark.table(f\"{catalog_name}.{gold_db_name}.view_vendas_por_periodo\")\n",
    "\n",
    "df_tempo_nomes = spark.table(f\"{catalog_name}.{gold_db_name}.dm_tempo\").select(\n",
    "    \"dia_da_semana_num\",\n",
    "    \"dia_da_semana_nome\"\n",
    ").distinct()\n",
    "\n",
    "df_receita_dia_semana = df_view_vendas.groupBy(\n",
    "    \"dia_da_semana_num\"\n",
    ").agg(\n",
    "    spark_round(F.sum(\"receita_total_brl\"), 2).alias(\"receita_total_brl\")\n",
    ").join(\n",
    "    df_tempo_nomes,\n",
    "    on=\"dia_da_semana_num\",\n",
    "    how=\"left\"\n",
    ").select(\n",
    "    \"dia_da_semana_num\",\n",
    "    \"dia_da_semana_nome\",\n",
    "    \"receita_total_brl\"\n",
    ").orderBy(col(\"receita_total_brl\").desc())\n",
    "\n",
    "print(\"\\n[ETAPA 51] Receita por dia da semana (ordenado por maior receita):\")\n",
    "display(df_receita_dia_semana)\n",
    "\n",
    "dia_maior_receita = df_receita_dia_semana.first()\n",
    "print(f\"\\n[ETAPA 51] Dia com maior receita: {dia_maior_receita['dia_da_semana_nome']} (#{dia_maior_receita['dia_da_semana_num']}) - R$ {dia_maior_receita['receita_total_brl']:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9099afa7-ec62-410c-b13d-89497c941944",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Consulta 2: Mes com Maior Ticket Medio no Ultimo Ano\n",
    "\n",
    "Identifica o mes com maior ticket medio de vendas no ultimo ano disponivel nos dados. Primeiro determina automaticamente qual e o ultimo ano com vendas registradas, depois agrega os dados por mes dentro daquele ano especifico. O ticket medio revela o valor medio gasto por item, sendo um indicador importante da qualidade das vendas e efetividade de estrategias de upselling e cross-selling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55340fa2-6b08-464b-ba63-1208873b1694",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[ETAPA 3.5.1.2] Buscando ultimo ano disponivel\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "ultimo_ano = df_view_vendas.select(F.max(\"ano\")).collect()[0][0]\n",
    "\n",
    "print(f\"\\nUltimo ano com dados: {ultimo_ano}\")\n",
    "\n",
    "print(\"\\n[ETAPA 52] Ultimo ano identificado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91d86b24-0d50-4f10-9d99-5f1a5793a7d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Etapa 2: Agregacao por Mes no Ultimo Ano\n",
    "\n",
    "Filtra os dados para o ultimo ano identificado e agrega por mes, calculando o ticket medio total de cada mes. Como a view ja contem o ticket_medio_brl pre-calculado por dia, precisamos recalcular a media ponderada considerando o volume de itens de cada dia dentro do mes. Ordena os resultados para identificar qual mes apresentou o maior valor medio por item vendido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95e5cbbd-de55-4af9-9d6e-abb493a9b535",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"[ETAPA 3.5.1.3] Calculando ticket medio por mes no ultimo ano\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_ultimo_ano = df_view_vendas.filter(col(\"ano\") == ultimo_ano)\n",
    "\n",
    "df_ticket_mes = df_ultimo_ano.groupBy(\n",
    "    \"mes\",\n",
    "    \"mes_nome\"\n",
    ").agg(\n",
    "    F.sum(\"receita_total_brl\").alias(\"receita_mes\"),\n",
    "    F.sum(\"total_itens\").alias(\"itens_mes\")\n",
    ").withColumn(\n",
    "    \"ticket_medio_brl\",\n",
    "    spark_round(\n",
    "        when(col(\"itens_mes\") > 0, col(\"receita_mes\") / col(\"itens_mes\"))\n",
    "        .otherwise(lit(0)),\n",
    "        2\n",
    "    )\n",
    ").select(\n",
    "    \"mes\",\n",
    "    \"mes_nome\",\n",
    "    \"ticket_medio_brl\"\n",
    ").orderBy(col(\"ticket_medio_brl\").desc())\n",
    "\n",
    "print(f\"\\n[ETAPA 53] Ticket medio por mes no ano {ultimo_ano} (ordenado por maior ticket):\")\n",
    "display(df_ticket_mes)\n",
    "\n",
    "mes_maior_ticket = df_ticket_mes.first()\n",
    "print(f\"\\n[ETAPA 53] Mes com maior ticket medio: {mes_maior_ticket['mes_nome']} (#{mes_maior_ticket['mes']}) - R$ {mes_maior_ticket['ticket_medio_brl']:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "686919f5-cb3f-459e-994e-30dc737a5f6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Questao 3.4 - view_top_produto\n",
    "\n",
    "**Descricao:** View analitica consolidando metricas de desempenho por produto e categoria para analises de gestao de produtos e estrategias comerciais.\n",
    "\n",
    "**Origem dos Dados:**\n",
    "- gold.ft_vendas_geral (vendas, receitas, avaliacoes)\n",
    "- silver.ft_produtos (informacoes de catalogo: categoria, peso)\n",
    "\n",
    "**Estrutura da View:**\n",
    "- id_produto: Identificador do produto (STRING)\n",
    "- categoria_produto: Categoria do produto (STRING)\n",
    "- quantidade_vendida: Total de unidades vendidas (BIGINT)\n",
    "- total_pedidos: Quantidade de pedidos distintos contendo o produto (BIGINT)\n",
    "- receita_brl: Receita total gerada em BRL (DECIMAL(12,2))\n",
    "- receita_usd: Receita total gerada em USD (DECIMAL(12,2))\n",
    "- preco_medio_brl: Preco medio unitario em BRL (DECIMAL(12,2))\n",
    "- avaliacao_media: Media das avaliacoes de pedidos contendo o produto (DECIMAL(3,2))\n",
    "- peso_medio_gramas: Peso medio do produto em gramas (DECIMAL(8,2))\n",
    "\n",
    "**Regras de Negocio:**\n",
    "- quantidade_vendida = count(id_item) por produto\n",
    "- total_pedidos = countDistinct(id_pedido) por produto\n",
    "- receita_brl = sum(valor_produto_brl)\n",
    "- receita_usd = sum(valor_produto_usd)\n",
    "- preco_medio_brl = receita_brl / quantidade_vendida\n",
    "- avaliacao_media = avg(avaliacao_pedido) com filtro de pedidos validos\n",
    "- peso_medio_gramas obtido do catalogo ft_produtos\n",
    "\n",
    "**Proposito:** Esta view permite a equipe de Gestao de Produtos identificar produtos e categorias de maior performance, avaliar estrategias de precificacao, detectar produtos com baixa avaliacao que requerem atencao e otimizar mix de produtos baseado em receita e demanda. Essencial para decisoes de descontinuacao, investimento e promocoes direcionadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a1dc2fa-66aa-4fc0-996b-3b81da14fe68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 1: Carregamento das Tabelas\n",
    "\n",
    "Carrega a tabela fato gold.ft_vendas_geral (fonte das metricas de vendas) e a tabela silver.ft_produtos (catalogo de produtos com informacoes de categoria e peso). O join entre essas tabelas permite enriquecer as metricas de vendas com atributos descritivos dos produtos essenciais para analises de gestao de catalogo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60a22471-5478-4040-94ab-e7cd7f2108b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"[ETAPA 3.6.1] Carregamento das tabelas\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_vendas_geral = spark.table(f\"{catalog_name}.{gold_db_name}.ft_vendas_geral\")\n",
    "df_produtos_cat = validar_tabela_silver(\"ft_produtos\")\n",
    "\n",
    "total_itens_vendas = df_vendas_geral.count()\n",
    "total_produtos_catalogo = df_produtos_cat.count()\n",
    "\n",
    "print(f\"\\nft_vendas_geral: {total_itens_vendas:,} registros\")\n",
    "print(f\"ft_produtos: {total_produtos_catalogo:,} registros\")\n",
    "\n",
    "print(\"\\n[ETAPA 3.6.1] Tabelas carregadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eba886e1-bdce-4a08-99e0-5a736e7c40d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 2: Validacao de Integridade\n",
    "\n",
    "Valida a integridade dos dados verificando produtos nulos na tabela fato e produtos orfaos (presentes nas vendas mas ausentes no catalogo). Produtos orfaos indicam problemas de sincronizacao entre sistemas ou exclusoes incorretas do catalogo. Esta validacao identifica inconsistencias que podem comprometer analises de categoria e atributos de produtos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a3b576a-e618-4076-8a64-1e629ff8c903",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"[ETAPA 62] Validacao de integridade dos dados\")\n",
    "\n",
    "produtos_nulos_vendas = df_vendas_geral.filter(col(\"fk_produto\").isNull()).count()\n",
    "print(f\"\\nProdutos nulos em ft_vendas_geral: {produtos_nulos_vendas:,}\")\n",
    "\n",
    "produtos_vendas_unicos = df_vendas_geral.select(\"fk_produto\").distinct()\n",
    "total_produtos_vendidos = produtos_vendas_unicos.count()\n",
    "print(f\"Total de produtos unicos vendidos: {total_produtos_vendidos:,}\")\n",
    "\n",
    "produtos_catalogo_ids = df_produtos_cat.select(col(\"id_produto\").alias(\"fk_produto\"))\n",
    "produtos_orfaos = produtos_vendas_unicos.join(produtos_catalogo_ids, \"fk_produto\", \"left_anti\")\n",
    "total_produtos_orfaos = produtos_orfaos.count()\n",
    "\n",
    "if total_produtos_orfaos > 0:\n",
    "    print(f\"\\nALERTA: {total_produtos_orfaos:,} produtos vendidos ausentes no catalogo\")\n",
    "else:\n",
    "    print(f\"\\nOK: Todos os produtos vendidos existem no catalogo\")\n",
    "\n",
    "print(\"\\n[ETAPA 62] Validacao concluida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65746669-a005-4f70-9c58-f39db01023e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 3: Agregacao por Produto\n",
    "\n",
    "Agrega as vendas por produto calculando as metricas fundamentais: quantidade total vendida (count de itens), numero de pedidos distintos (countDistinct de id_pedido), receita total em BRL e USD (sum dos valores), e avaliacao media (avg das notas). Estas metricas formam a base para identificar produtos top performance e avaliar estrategias de pricing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32c71e9e-0736-4ef2-beb4-93df0e7b3001",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"[ETAPA 3.6.3] Agregacao das metricas por produto\")\n",
    "\n",
    "df_produto_agg = df_vendas_geral.groupBy(\"fk_produto\").agg(\n",
    "    F.count(\"id_item\").alias(\"quantidade_vendida\"),\n",
    "    F.countDistinct(\"id_pedido\").alias(\"total_pedidos\"),\n",
    "    spark_round(F.sum(\"valor_produto_brl\"), 2).alias(\"receita_brl\"),\n",
    "    spark_round(F.sum(\"valor_produto_usd\"), 2).alias(\"receita_usd\"),\n",
    "    spark_round(F.avg(when(col(\"avaliacao_pedido\").isNotNull(), col(\"avaliacao_pedido\"))), 2).alias(\"avaliacao_media\")\n",
    ")\n",
    "\n",
    "total_produtos_agg = df_produto_agg.count()\n",
    "print(f\"\\nTotal de produtos agregados: {total_produtos_agg:,}\")\n",
    "\n",
    "print(\"\\nAmostra dos top 3 produtos por receita BRL:\")\n",
    "df_sample_top3 = df_produto_agg.orderBy(col(\"receita_brl\").desc()).limit(3)\n",
    "display(df_sample_top3)\n",
    "\n",
    "print(\"\\n[ETAPA 63] Agregacao concluida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cb61308-b2d0-4414-a6e8-61c2a43ac6a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 4: Enriquecimento com Catalogo de Produtos\n",
    "\n",
    "Realiza join entre as metricas agregadas e o catalogo de produtos para adicionar os atributos descritivos: categoria do produto (categoria_produto_ingles traduzida) e peso medio em gramas (peso_produto_gramas). O join left preserva todos os produtos vendidos mesmo que ausentes no catalogo (produtos orfaos identificados na Etapa 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a680efb-9396-4ba2-80f8-a71e8cba6d96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"[ETAPA 3.6.4] Enriquecimento com atributos do catalogo\")\n",
    "\n",
    "df_produtos_prep = df_produtos_cat.select(\n",
    "    col(\"id_produto\"),\n",
    "    col(\"categoria_produto\"),\n",
    "    col(\"peso_produto_gramas\")\n",
    ")\n",
    "\n",
    "df_produto_enriched = df_produto_agg.join(\n",
    "    df_produtos_prep,\n",
    "    df_produto_agg[\"fk_produto\"] == df_produtos_prep[\"id_produto\"],\n",
    "    \"left\"\n",
    ")\n",
    "\n",
    "produtos_sem_categoria = df_produto_enriched.filter(col(\"categoria_produto\").isNull()).count()\n",
    "print(f\"\\nProdutos sem categoria apos join: {produtos_sem_categoria:,}\")\n",
    "\n",
    "if produtos_sem_categoria > 0:\n",
    "    print(f\"ALERTA: {produtos_sem_categoria:,} produtos vendidos nao possuem categoria no catalogo\")\n",
    "else:\n",
    "    print(\"OK: Todos os produtos possuem categoria\")\n",
    "\n",
    "print(\"\\n[ETAPA 64] Enriquecimento concluido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d3c812d-62f6-47b8-9a4e-68998aef1859",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 5: Calculo de Metricas Derivadas\n",
    "\n",
    "Calcula o preco medio em BRL (receita_brl / quantidade_vendida) aplicando protecao contra divisao por zero. Esta metrica identifica produtos com pricing premium ou desconto agressivo. Apos o calculo, seleciona e renomeia as colunas conforme a estrutura definida da view (id_produto, categoria_produto, quantidade_vendida, total_pedidos, receita_brl, receita_usd, preco_medio_brl, avaliacao_media, peso_medio_gramas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "935ae9ac-edae-4263-8335-5d4736e7b2ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"[ETAPA 3.6.5] Calculo de metricas derivadas\")\n",
    "\n",
    "df_view_top_produto = df_produto_enriched.withColumn(\n",
    "    \"preco_medio_brl\",\n",
    "    spark_round(\n",
    "        when(col(\"quantidade_vendida\") > 0, col(\"receita_brl\") / col(\"quantidade_vendida\"))\n",
    "        .otherwise(lit(0)),\n",
    "        2\n",
    "    )\n",
    ").select(\n",
    "    col(\"fk_produto\").alias(\"id_produto\"),\n",
    "    col(\"categoria_produto\"),\n",
    "    col(\"quantidade_vendida\"),\n",
    "    col(\"total_pedidos\"),\n",
    "    col(\"receita_brl\"),\n",
    "    col(\"receita_usd\"),\n",
    "    col(\"preco_medio_brl\"),\n",
    "    col(\"avaliacao_media\"),\n",
    "    spark_round(col(\"peso_produto_gramas\"), 2).alias(\"peso_medio_gramas\")\n",
    ")\n",
    "\n",
    "total_produtos_view = df_view_top_produto.count()\n",
    "print(f\"\\nTotal de produtos na view: {total_produtos_view:,}\")\n",
    "\n",
    "print(\"\\nSchema da view:\")\n",
    "df_view_top_produto.printSchema()\n",
    "\n",
    "print(\"\\n[ETAPA 65] Metricas calculadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93dee359-2d37-4da3-8bff-54cb45c0febf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 6: Validacoes de Qualidade\n",
    "\n",
    "Valida a qualidade dos dados calculados verificando: distribuicao de valores nulos por coluna (categoria e peso podem ter nulos para produtos orfaos), consistencia das metricas calculadas (preco_medio_brl = receita_brl / quantidade_vendida), ranges de valores (avaliacoes entre 0-5, precos positivos), e identificacao de outliers. Esta validacao garante que a view forneca metricas confiaveis para tomada de decisao."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6b787bd-efae-43e9-a5c2-a8b3ab8b2f81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"[ETAPA 66] Validacoes de qualidade dos dados\")\n",
    "\n",
    "print(\"\\nDistribuicao de valores nulos:\")\n",
    "null_data = []\n",
    "for col_name in df_view_top_produto.columns:\n",
    "    null_count = df_view_top_produto.filter(\n",
    "        col(col_name).isNull()\n",
    "    ).count()\n",
    "    null_pct = (null_count / total_produtos_view) * 100\n",
    "    null_data.append((col_name, null_count, null_pct))\n",
    "\n",
    "df_nulos = spark.createDataFrame(\n",
    "    null_data,\n",
    "    [\"coluna\", \"valores_nulos\", \"percentual\"]\n",
    ")\n",
    "display(df_nulos)\n",
    "\n",
    "print(\"\\nValidacoes de integridade:\")\n",
    "avaliacoes_invalidas = df_view_top_produto.filter(\n",
    "    (col(\"avaliacao_media\").isNotNull()) &\n",
    "    ((col(\"avaliacao_media\") < 0) | (col(\"avaliacao_media\") > 5))\n",
    ").count()\n",
    "\n",
    "precos_invalidos = df_view_top_produto.filter(\n",
    "    (col(\"preco_medio_brl\").isNotNull()) &\n",
    "    (col(\"preco_medio_brl\") < 0)\n",
    ").count()\n",
    "\n",
    "receitas_inconsistentes = df_view_top_produto.filter(\n",
    "    (col(\"receita_brl\") > 0) & (col(\"quantidade_vendida\") == 0)\n",
    ").count()\n",
    "\n",
    "df_validacoes = spark.createDataFrame(\n",
    "    [\n",
    "        (\"Avaliacoes fora do range [0-5]\", avaliacoes_invalidas),\n",
    "        (\"Precos medios negativos\", precos_invalidos),\n",
    "        (\"Produtos com receita mas quantidade zero\", receitas_inconsistentes)\n",
    "    ],\n",
    "    [\"validacao\", \"total_inconsistencias\"]\n",
    ")\n",
    "display(df_validacoes)\n",
    "\n",
    "df_estatisticas = df_view_top_produto.select(\n",
    "    \"quantidade_vendida\",\n",
    "    \"receita_brl\",\n",
    "    \"preco_medio_brl\",\n",
    "    \"avaliacao_media\"\n",
    ").summary(\"count\", \"mean\", \"stddev\", \"min\", \"max\")\n",
    "display(df_estatisticas)\n",
    "\n",
    "print(\"\\n[ETAPA 66] Validacoes concluidas\")\n",
    "print(\"\\nEstatisticas descritivas:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddd59a2c-0484-4354-a38c-2920c77991ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 7: Criacao da View\n",
    "\n",
    "Cria a view Delta gold.view_top_produto gravando os dados validados no formato Delta para garantir ACID properties e versionamento. A view consolida as metricas de desempenho por produto permitindo analises de top performers, comparacoes de categorias, e identificacao de produtos com baixa avaliacao ou problemas de pricing. Utilizada pela equipe de gestao de produtos para decisoes estrategicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35cc85aa-1634-4be4-8a53-9682eabc51cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"[ETAPA 3.6.7] Criacao da view Delta\")\n",
    "\n",
    "view_name = f\"{catalog_name}.{gold_db_name}.view_top_produto\"\n",
    "\n",
    "df_view_top_produto.write.format(\"delta\").mode(\"overwrite\").saveAsTable(view_name)\n",
    "\n",
    "print(f\"\\nView criada: {view_name}\")\n",
    "print(f\"Formato: Delta\")\n",
    "print(f\"Modo: Overwrite\")\n",
    "\n",
    "registros_gravados = spark.table(view_name).count()\n",
    "print(f\"Registros gravados: {registros_gravados:,}\")\n",
    "\n",
    "print(\"\\n[ETAPA 67] View criada com sucesso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04b46295-7328-4cae-90ba-39c4fe06a024",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 8: Validacao Final\n",
    "\n",
    "Valida a view criada exibindo os top 10 produtos por receita BRL, distribuicao de produtos por categoria, e metricas agregadas gerais. Esta validacao confirma que a view esta acessivel, contem os dados esperados, e fornece insights imediatos sobre os produtos de maior desempenho no catalogo. Permite verificar se as agregacoes e joins foram executados corretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15e4adad-e8e2-4112-a44e-24108affe58b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"[ETAPA 3.6.8] Validacao final da view\")\n",
    "\n",
    "df_view_final = spark.table(view_name)\n",
    "\n",
    "print(\"\\nTop 10 produtos por receita BRL:\")\n",
    "df_top_10 = df_view_final.orderBy(col(\"receita_brl\").desc()).limit(10)\n",
    "display(df_top_10)\n",
    "\n",
    "print(\"\\nDistribuicao de produtos por categoria:\")\n",
    "df_categoria = df_view_final.groupBy(\"categoria_produto\").agg(\n",
    "    F.count(\"id_produto\").alias(\"total_produtos\"),\n",
    "    spark_round(F.sum(\"receita_brl\"), 2).alias(\"receita_total_brl\")\n",
    ").orderBy(col(\"receita_total_brl\").desc())\n",
    "display(df_categoria)\n",
    "\n",
    "print(\"\\nSumario de metricas gerais:\")\n",
    "df_sumario = df_view_final.agg(\n",
    "    F.count(\"id_produto\").alias(\"total_produtos_unicos\"),\n",
    "    F.sum(\"quantidade_vendida\").alias(\"quantidade_total_vendida\"),\n",
    "    F.sum(\"total_pedidos\").alias(\"total_pedidos\"),\n",
    "    spark_round(F.sum(\"receita_brl\"), 2).alias(\"receita_total_brl\"),\n",
    "    spark_round(F.sum(\"receita_usd\"), 2).alias(\"receita_total_usd\"),\n",
    "    spark_round(F.avg(\"preco_medio_brl\"), 2).alias(\"preco_medio_geral_brl\"),\n",
    "    spark_round(F.avg(\"avaliacao_media\"), 2).alias(\"avaliacao_media_geral\")\n",
    ")\n",
    "display(df_sumario)\n",
    "\n",
    "print(\"\\n[ETAPA 68] Validacao concluida\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a88f12d5-05cc-4ef2-bfa4-9d3d43f3ac8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Questao 3.5 - view_vendas_produtos_esteticos\n",
    "\n",
    "**Descricao:**\n",
    "View analitica para acompanhamento mensal de vendas de produtos da categoria Fashion. Consolida metricas de receita, volume de pedidos e avaliacao media por mes e categoria, permitindo a area de Fashion identificar tendencias sazonais, desempenho de categorias especificas e oportunidades de crescimento.\n",
    "\n",
    "**Origem dos Dados:**\n",
    "- `gold.ft_vendas_geral`: Base de vendas com itens, precos BRL/USD, avaliacoes e datas\n",
    "- `gold.dm_tempo`: Dimensao temporal para agregacao por ano/mes\n",
    "- `silver.ft_produtos`: Catalogo de produtos para filtro de categorias fashion\n",
    "\n",
    "**Estrutura da View:**\n",
    "| Campo | Tipo | Descricao |\n",
    "|-------|------|-----------|\n",
    "| ano | INT | Ano da venda (dm_tempo) |\n",
    "| mes | INT | Mes numerico 1-12 (dm_tempo) |\n",
    "| categoria_produto | STRING | Categoria iniciando com \"fashion_\" |\n",
    "| total_pedidos | BIGINT | Pedidos distintos no periodo |\n",
    "| total_itens_vendidos | BIGINT | Quantidade total de itens vendidos |\n",
    "| receita_total_brl | DECIMAL(12,2) | Soma receita em BRL |\n",
    "| receita_total_usd | DECIMAL(12,2) | Soma receita em USD (cotacao pedido) |\n",
    "| ticket_medio_brl | DECIMAL(12,2) | Receita BRL / itens vendidos |\n",
    "| ticket_medio_usd | DECIMAL(12,2) | Receita USD / itens vendidos |\n",
    "| avaliacao_media | DECIMAL(3,2) | Media avaliacoes pedidos entregues |\n",
    "\n",
    "**Regras de Negocio:**\n",
    "- Filtro obrigatorio: categoria_produto LIKE 'fashion%'\n",
    "- Agregacao: ano + mes + categoria_produto\n",
    "- Ticket medio: protecao contra divisao por zero\n",
    "- Avaliacao media: considerar apenas avaliacoes validas (NOT NULL)\n",
    "- Join temporal: via fk_tempo  sk_tempo\n",
    "\n",
    "**Proposito:**\n",
    "Fornece visao consolidada de performance mensal para equipe Fashion tomar decisoes sobre mix de produtos, acoes promocionais e investimentos em categorias especificas. Permite comparacao de receita BRL vs USD para avaliar impacto cambial nas vendas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "092440bc-1317-4dd3-bfac-639a37fe3906",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Estrutura de CTEs\n",
    "\n",
    "A implementacao utiliza Common Table Expressions (CTEs) para modularizar a logica de transformacao e agregacao, seguindo o padrao SQL recomendado para views complexas. As CTEs sao executadas em ordem sequencial:\n",
    "\n",
    "**CTE 1 - produtos_fashion:**\n",
    "Filtra produtos do catalogo cuja categoria inicia com 'fashion', obtendo id_produto e categoria_produto. Esta CTE reduz o volume de dados logo no inicio da pipeline, melhorando performance das operacoes subsequentes. Esta filtragem garante que apenas produtos da linha fashion sejam considerados, excluindo outras categorias como eletronicos, casa, etc. A categoria 'fashion' inclui subcategorias como fashion_bolsas, fashion_calcados, fashion_roupa, etc., representando o segmento de moda e acessorios da empresa.\n",
    "\n",
    "**CTE 2 - vendas_fashion:**\n",
    "Realiza join entre ft_vendas_geral e produtos_fashion, selecionando apenas vendas de produtos fashion. Mantem campos necessarios: fk_tempo, id_pedido, id_item, categoria, valores BRL/USD e avaliacao. Esta CTE consolida a base de vendas filtrada. O join inner garante que apenas vendas de produtos fashion sejam incluidas, filtrando transacoes de outras categorias. Os campos selecionados incluem identificadores unicos (id_pedido, id_item), chave temporal (fk_tempo), categoria para agrupamento, valores monetarios em ambas moedas para analises cambiais, e avaliacao para medir satisfacao do cliente com produtos fashion.\n",
    "\n",
    "**CTE 3 - vendas_tempo:**\n",
    "Enriquece vendas_fashion com atributos temporais (ano, mes) atraves de join com dm_tempo via fk_tempo  sk_tempo. Esta CTE adiciona a dimensao temporal necessaria para agregacao mensal. O join com dm_tempo adiciona contexto temporal padronizado, permitindo agregacoes consistentes por periodos. Os atributos ano e mes sao essenciais para analises sazonais, identificacao de tendencias mensais e comparacoes interanuais no segmento fashion.\n",
    "\n",
    "**CTE 4 - agregacao_mensal:**\n",
    "Agrega vendas por ano, mes e categoria calculando: total_pedidos (countDistinct), total_itens_vendidos (count), receitas BRL/USD (sum), avaliacao_media (avg). Esta CTE gera as metricas brutas antes dos calculos derivados. A agregacao por ano, mes e categoria permite analises multidimensionais: performance mensal por categoria, comparacao interanual, identificacao de categorias em crescimento ou declinio. As metricas calculadas fornecem indicadores chave de negocio: volume de vendas, receita em multiplas moedas e satisfacao media dos clientes.\n",
    "\n",
    "**CTE 5 - metricas_finais:**\n",
    "Calcula ticket medio BRL e USD (receita_total / total_itens) aplicando protecao contra divisao por zero. Esta CTE produz o dataset final com todas as 10 colunas da view. O ticket medio e um indicador fundamental de valor por transacao, revelando se o segmento fashion esta focado em produtos premium (ticket alto) ou volume (ticket baixo). A protecao contra divisao por zero evita erros em periodos sem vendas. As metricas finais permitem benchmarking entre categorias e periodos, suportando decisoes estrategicas de pricing e mix de produtos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92ea0914-59ed-4140-8732-6bb679fb1122",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 1: Validacao de Categorias Fashion\n",
    "\n",
    "Valida a existencia de produtos fashion no catalogo identificando quantas categorias iniciam com 'fashion' e o total de produtos nessas categorias. Esta validacao garante que o filtro da view tera dados suficientes para analise. Exibe amostra das categorias fashion disponiveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d3eea3e-4b3e-438b-8c66-1e5b535ec515",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"[ETAPA 3.7.1] Validacao de categorias fashion no catalogo\")\n",
    "\n",
    "df_produtos_catalogo = validar_tabela_silver(\"ft_produtos\")\n",
    "\n",
    "df_fashion_categorias = df_produtos_catalogo.filter(\n",
    "    col(\"categoria_produto\").startswith(\"fashion\")\n",
    ").select(\"categoria_produto\").distinct()\n",
    "\n",
    "total_categorias_fashion = df_fashion_categorias.count()\n",
    "print(f\"\\nTotal de categorias fashion: {total_categorias_fashion}\")\n",
    "\n",
    "if total_categorias_fashion == 0:\n",
    "    print(\"ALERTA: Nenhuma categoria fashion encontrada no catalogo\")\n",
    "else:\n",
    "    print(f\"OK: {total_categorias_fashion} categorias fashion disponiveis\")\n",
    "    print(\"\\nCategorias fashion identificadas:\")\n",
    "    display(df_fashion_categorias.orderBy(\"categoria_produto\"))\n",
    "\n",
    "df_produtos_fashion = df_produtos_catalogo.filter(\n",
    "    col(\"categoria_produto\").startswith(\"fashion\")\n",
    ")\n",
    "total_produtos_fashion = df_produtos_fashion.count()\n",
    "print(f\"\\nTotal de produtos fashion no catalogo: {total_produtos_fashion:,}\")\n",
    "\n",
    "print(\"\\n[ETAPA 3.7.1] Validacao concluida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18ce83be-918d-4516-a703-e7a09ef3ccf0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 2: Validacao de Vendas Fashion\n",
    "\n",
    "Valida a existencia de vendas de produtos fashion na tabela fato, cruzando ft_vendas_geral com produtos fashion. Verifica se ha itens vendidos dessas categorias e exibe amostra com valores, datas e avaliacoes. Esta validacao confirma que a view tera dados para todos os periodos analisados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b174190-3d10-4a1f-930e-0fb7ad3c1356",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"[ETAPA 3.7.2] Validacao de vendas de produtos fashion\")\n",
    "\n",
    "df_vendas = spark.table(f\"{catalog_name}.{gold_db_name}.ft_vendas_geral\")\n",
    "\n",
    "df_vendas_fashion_sample = df_vendas.join(\n",
    "    df_produtos_fashion.select(\"id_produto\", \"categoria_produto\"),\n",
    "    df_vendas[\"fk_produto\"] == df_produtos_fashion[\"id_produto\"],\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "total_itens_fashion = df_vendas_fashion_sample.count()\n",
    "print(f\"\\nTotal de itens vendidos (categoria fashion): {total_itens_fashion:,}\")\n",
    "\n",
    "if total_itens_fashion == 0:\n",
    "    print(\"ALERTA: Nenhum item fashion vendido encontrado\")\n",
    "else:\n",
    "    print(f\"OK: {total_itens_fashion:,} itens fashion vendidos disponiveis para analise\")\n",
    "    \n",
    "    pedidos_fashion = df_vendas_fashion_sample.select(\"id_pedido\").distinct().count()\n",
    "    print(f\"Total de pedidos com produtos fashion: {pedidos_fashion:,}\")\n",
    "    \n",
    "    print(\"\\nAmostra de vendas fashion:\")\n",
    "    df_sample = df_vendas_fashion_sample.select(\n",
    "        \"fk_tempo\", \"id_pedido\", \"categoria_produto\", \n",
    "        \"valor_produto_brl\", \"valor_produto_usd\", \"avaliacao_pedido\"\n",
    "    ).limit(5)\n",
    "    display(df_sample)\n",
    "\n",
    "print(\"\\n[ETAPA 3.7.2] Validacao concluida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a38492dc-97ff-48c3-a89e-6b274d2d3459",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 3: Criacao da View com CTEs\n",
    "\n",
    "Implementa a view usando SQL com CTEs (Common Table Expressions) para estruturar a logica em etapas modulares. Cada CTE representa uma transformacao especifica: filtragem de produtos fashion, join com vendas, enriquecimento temporal, agregacao mensal e calculo de metricas derivadas. A query final consolida todas as transformacoes em uma view Delta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "060c101d-a181-470c-bbca-46e823204f6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"[ETAPA 3.7.3] Criacao da view com CTEs\")\n",
    "\n",
    "query_view_fashion = f\"\"\"\n",
    "WITH produtos_fashion AS (\n",
    "    SELECT \n",
    "        id_produto,\n",
    "        categoria_produto\n",
    "    FROM {catalog_name}.silver.ft_produtos\n",
    "    WHERE categoria_produto LIKE 'fashion%'\n",
    "),\n",
    "vendas_fashion AS (\n",
    "    SELECT \n",
    "        v.fk_tempo,\n",
    "        v.id_pedido,\n",
    "        v.id_item,\n",
    "        p.categoria_produto,\n",
    "        v.valor_produto_brl,\n",
    "        v.valor_produto_usd,\n",
    "        v.avaliacao_pedido\n",
    "    FROM {catalog_name}.{gold_db_name}.ft_vendas_geral v\n",
    "    INNER JOIN produtos_fashion p ON v.fk_produto = p.id_produto\n",
    "),\n",
    "vendas_tempo AS (\n",
    "    SELECT \n",
    "        t.ano,\n",
    "        t.mes,\n",
    "        v.id_pedido,\n",
    "        v.id_item,\n",
    "        v.categoria_produto,\n",
    "        v.valor_produto_brl,\n",
    "        v.valor_produto_usd,\n",
    "        v.avaliacao_pedido\n",
    "    FROM vendas_fashion v\n",
    "    INNER JOIN {catalog_name}.{gold_db_name}.dm_tempo t ON v.fk_tempo = t.sk_tempo\n",
    "),\n",
    "agregacao_mensal AS (\n",
    "    SELECT \n",
    "        ano,\n",
    "        mes,\n",
    "        categoria_produto,\n",
    "        COUNT(DISTINCT id_pedido) AS total_pedidos,\n",
    "        COUNT(id_item) AS total_itens_vendidos,\n",
    "        ROUND(SUM(valor_produto_brl), 2) AS receita_total_brl,\n",
    "        ROUND(SUM(valor_produto_usd), 2) AS receita_total_usd,\n",
    "        ROUND(AVG(CASE WHEN avaliacao_pedido IS NOT NULL THEN avaliacao_pedido END), 2) AS avaliacao_media\n",
    "    FROM vendas_tempo\n",
    "    GROUP BY ano, mes, categoria_produto\n",
    "),\n",
    "metricas_finais AS (\n",
    "    SELECT \n",
    "        ano,\n",
    "        mes,\n",
    "        categoria_produto,\n",
    "        total_pedidos,\n",
    "        total_itens_vendidos,\n",
    "        receita_total_brl,\n",
    "        receita_total_usd,\n",
    "        ROUND(\n",
    "            CASE \n",
    "                WHEN total_itens_vendidos > 0 THEN receita_total_brl / total_itens_vendidos\n",
    "                ELSE 0 \n",
    "            END, \n",
    "            2\n",
    "        ) AS ticket_medio_brl,\n",
    "        ROUND(\n",
    "            CASE \n",
    "                WHEN total_itens_vendidos > 0 THEN receita_total_usd / total_itens_vendidos\n",
    "                ELSE 0 \n",
    "            END, \n",
    "            2\n",
    "        ) AS ticket_medio_usd,\n",
    "        avaliacao_media\n",
    "    FROM agregacao_mensal\n",
    ")\n",
    "SELECT * FROM metricas_finais\n",
    "ORDER BY ano, mes, categoria_produto\n",
    "\"\"\"\n",
    "\n",
    "view_fashion_name = f\"{catalog_name}.{gold_db_name}.view_vendas_produtos_esteticos\"\n",
    "\n",
    "df_view_fashion = spark.sql(query_view_fashion)\n",
    "df_view_fashion.write.format(\"delta\").mode(\"overwrite\").saveAsTable(view_fashion_name)\n",
    "\n",
    "print(f\"\\nView criada: {view_fashion_name}\")\n",
    "print(f\"Formato: Delta\")\n",
    "print(f\"Modo: Overwrite\")\n",
    "\n",
    "registros_view_fashion = spark.table(view_fashion_name).count()\n",
    "print(f\"Registros na view: {registros_view_fashion:,}\")\n",
    "\n",
    "print(\"\\n[ETAPA 3.7.3] View criada com sucesso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13666ba0-c4f0-4280-8016-67c9b88915af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 4: Validacao do Schema\n",
    "\n",
    "Valida que a view criada possui exatamente os 10 campos especificados com os tipos de dados corretos: ano (INT), mes (INT), categoria_produto (STRING), total_pedidos (BIGINT), total_itens_vendidos (BIGINT), receita_total_brl (DECIMAL), receita_total_usd (DECIMAL), ticket_medio_brl (DECIMAL), ticket_medio_usd (DECIMAL), avaliacao_media (DECIMAL). Exibe o schema completo para conferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "214e320a-ef6f-4e93-9e22-d074da0f5661",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"[ETAPA 3.7.4] Validacao do schema da view\")\n",
    "\n",
    "df_view_fashion_final = spark.table(view_fashion_name)\n",
    "\n",
    "print(\"\\nSchema da view:\")\n",
    "df_view_fashion_final.printSchema()\n",
    "\n",
    "campos_esperados = [\n",
    "    (\"ano\", \"int\"),\n",
    "    (\"mes\", \"int\"),\n",
    "    (\"categoria_produto\", \"string\"),\n",
    "    (\"total_pedidos\", \"bigint\"),\n",
    "    (\"total_itens_vendidos\", \"bigint\"),\n",
    "    (\"receita_total_brl\", \"decimal\"),\n",
    "    (\"receita_total_usd\", \"decimal\"),\n",
    "    (\"ticket_medio_brl\", \"decimal\"),\n",
    "    (\"ticket_medio_usd\", \"decimal\"),\n",
    "    (\"avaliacao_media\", \"decimal\")\n",
    "]\n",
    "\n",
    "schema_ok = True\n",
    "for campo_nome, campo_tipo in campos_esperados:\n",
    "    campo_encontrado = False\n",
    "    for field in df_view_fashion_final.schema.fields:\n",
    "        if field.name == campo_nome:\n",
    "            campo_encontrado = True\n",
    "            tipo_atual = str(field.dataType).lower()\n",
    "            if campo_tipo not in tipo_atual:\n",
    "                print(f\"ALERTA: Campo {campo_nome} com tipo incorreto: {field.dataType}\")\n",
    "                schema_ok = False\n",
    "            break\n",
    "    if not campo_encontrado:\n",
    "        print(f\"ERRO: Campo {campo_nome} nao encontrado\")\n",
    "        schema_ok = False\n",
    "\n",
    "if schema_ok:\n",
    "    print(\"\\nOK: Schema da view conforme especificado\")\n",
    "else:\n",
    "    print(\"\\nALERTA: Schema possui diferencas em relacao a especificacao\")\n",
    "\n",
    "print(\"\\n[ETAPA 3.7.4] Validacao de schema concluida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6d66036-7295-4f98-9070-7573a8f0547a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 5: Validacao de Cobertura Temporal\n",
    "\n",
    "Valida a cobertura temporal da view verificando periodo minimo e maximo (ano/mes), total de meses cobertos e distribuicao de registros por ano. Esta validacao confirma que a view possui dados historicos completos para analise de tendencias e sazonalidade das vendas fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81eba600-4b88-4521-b5ee-5c8cc7220a7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"[ETAPA 3.7.5] Validacao de cobertura temporal\")\n",
    "\n",
    "print(\"\\nPeriodo coberto pela view:\")\n",
    "df_periodo = df_view_fashion_final.agg(\n",
    "    F.min(\"ano\").alias(\"ano_min\"),\n",
    "    F.max(\"ano\").alias(\"ano_max\"),\n",
    "    F.min(\"mes\").alias(\"mes_min\"),\n",
    "    F.max(\"mes\").alias(\"mes_max\")\n",
    ")\n",
    "display(df_periodo)\n",
    "\n",
    "print(\"\\nDistribuicao de registros por ano:\")\n",
    "df_dist_ano = df_view_fashion_final.groupBy(\"ano\").agg(\n",
    "    F.count(\"*\").alias(\"total_registros\"),\n",
    "    F.countDistinct(\"categoria_produto\").alias(\"categorias_distintas\"),\n",
    "    spark_round(F.sum(\"receita_total_brl\"), 2).alias(\"receita_ano_brl\")\n",
    ").orderBy(\"ano\")\n",
    "display(df_dist_ano)\n",
    "\n",
    "print(\"\\nTotal de combinacoes ano/mes distintas:\")\n",
    "combinacoes_tempo = df_view_fashion_final.select(\"ano\", \"mes\").distinct().count()\n",
    "print(f\"Combinacoes ano/mes: {combinacoes_tempo}\")\n",
    "\n",
    "print(\"\\n[ETAPA 3.7.5] Validacao de cobertura temporal concluida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f77cb5e-9798-4ad9-93e1-8eda1d7883ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 6: Validacao de Metricas\n",
    "\n",
    "Valida a integridade das metricas calculadas verificando: valores nulos em campos obrigatorios, consistencia dos tickets medios (receita/itens), avaliacoes dentro do range valido (0-5), e identificacao de outliers. Exibe estatisticas descritivas das metricas principais para analise de distribuicao."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cd5b7d9-e671-4e54-9695-89e1fd0c5a64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"[ETAPA 3.7.6] Validacao de integridade das metricas\")\n",
    "\n",
    "print(\"\\nValidacoes de valores nulos em campos obrigatorios:\")\n",
    "campos_obrigatorios = [\"ano\", \"mes\", \"categoria_produto\", \"total_pedidos\", \"total_itens_vendidos\"]\n",
    "null_data = []\n",
    "for campo in campos_obrigatorios:\n",
    "    null_count = df_view_fashion_final.filter(col(campo).isNull()).count()\n",
    "    null_data.append((campo, null_count))\n",
    "\n",
    "df_null_check = spark.createDataFrame(null_data, [\"campo_obrigatorio\", \"valores_nulos\"])\n",
    "display(df_null_check)\n",
    "\n",
    "print(\"\\nValidacoes de consistencia:\")\n",
    "receitas_negativas_brl = df_view_fashion_final.filter(col(\"receita_total_brl\") < 0).count()\n",
    "receitas_negativas_usd = df_view_fashion_final.filter(col(\"receita_total_usd\") < 0).count()\n",
    "tickets_negativos_brl = df_view_fashion_final.filter(col(\"ticket_medio_brl\") < 0).count()\n",
    "tickets_negativos_usd = df_view_fashion_final.filter(col(\"ticket_medio_usd\") < 0).count()\n",
    "avaliacoes_invalidas = df_view_fashion_final.filter(\n",
    "    (col(\"avaliacao_media\").isNotNull()) &\n",
    "    ((col(\"avaliacao_media\") < 0) | (col(\"avaliacao_media\") > 5))\n",
    ").count()\n",
    "\n",
    "df_validacoes = spark.createDataFrame([\n",
    "    (\"Receitas BRL negativas\", receitas_negativas_brl),\n",
    "    (\"Receitas USD negativas\", receitas_negativas_usd),\n",
    "    (\"Tickets medios BRL negativos\", tickets_negativos_brl),\n",
    "    (\"Tickets medios USD negativos\", tickets_negativos_usd),\n",
    "    (\"Avaliacoes fora do range [0-5]\", avaliacoes_invalidas)\n",
    "], [\"validacao\", \"total_inconsistencias\"])\n",
    "display(df_validacoes)\n",
    "\n",
    "print(\"\\nEstatisticas descritivas das metricas:\")\n",
    "df_estatisticas = df_view_fashion_final.select(\n",
    "    \"total_pedidos\", \"total_itens_vendidos\", \"receita_total_brl\", \n",
    "    \"ticket_medio_brl\", \"avaliacao_media\"\n",
    ").summary(\"count\", \"mean\", \"stddev\", \"min\", \"max\")\n",
    "display(df_estatisticas)\n",
    "\n",
    "print(\"\\n[ETAPA 3.7.6] Validacao de metricas concluida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82be0924-0720-47b2-9d0d-d4ac4747b3ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 7: Analise de Performance por Categoria\n",
    "\n",
    "Exibe o ranking de categorias fashion por receita total BRL, identificando as categorias de maior performance. Calcula tambem metricas agregadas por categoria para comparacao: receita media mensal, ticket medio e avaliacao media. Esta analise fornece insights sobre quais subcategorias fashion tem melhor desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b658d81c-cdf8-466f-9b8c-2632a8680077",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"[ETAPA 3.7.7] Analise de performance por categoria fashion\")\n",
    "\n",
    "print(\"\\nRanking de categorias por receita total BRL:\")\n",
    "df_ranking_categorias = df_view_fashion_final.groupBy(\"categoria_produto\").agg(\n",
    "    F.sum(\"total_pedidos\").alias(\"total_pedidos\"),\n",
    "    F.sum(\"total_itens_vendidos\").alias(\"total_itens_vendidos\"),\n",
    "    spark_round(F.sum(\"receita_total_brl\"), 2).alias(\"receita_total_brl\"),\n",
    "    spark_round(F.sum(\"receita_total_usd\"), 2).alias(\"receita_total_usd\"),\n",
    "    spark_round(F.avg(\"ticket_medio_brl\"), 2).alias(\"ticket_medio_brl\"),\n",
    "    spark_round(F.avg(\"avaliacao_media\"), 2).alias(\"avaliacao_media_geral\")\n",
    ").orderBy(col(\"receita_total_brl\").desc())\n",
    "display(df_ranking_categorias)\n",
    "\n",
    "print(\"\\nTotal de categorias fashion distintas:\")\n",
    "total_categorias = df_view_fashion_final.select(\"categoria_produto\").distinct().count()\n",
    "print(f\"{total_categorias} categorias fashion na view\")\n",
    "\n",
    "print(\"\\n[ETAPA 3.7.7] Analise de performance concluida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26f35ba6-b3d4-4631-a805-315d8e84f0b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Etapa 8: Validacao Final da View\n",
    "\n",
    "Exibe amostra completa da view ordenada por ano, mes e receita para conferencia visual dos dados. Calcula sumario geral consolidando todas as metricas: total de registros, soma de pedidos, itens vendidos, receitas BRL/USD, tickets medios e avaliacao media geral. Esta validacao final confirma que a view esta pronta para uso pela equipe Fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edf284c1-565d-442e-ab9c-81a148f72b94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"[ETAPA 3.7.8] Validacao final da view\")\n",
    "\n",
    "print(\"\\nAmostra da view (top 20 registros por receita):\")\n",
    "df_amostra_final = df_view_fashion_final.orderBy(\n",
    "    col(\"ano\"), col(\"mes\"), col(\"receita_total_brl\").desc()\n",
    ").limit(20)\n",
    "display(df_amostra_final)\n",
    "\n",
    "print(\"\\nSumario geral de metricas:\")\n",
    "df_sumario_final = df_view_fashion_final.agg(\n",
    "    F.count(\"*\").alias(\"total_registros\"),\n",
    "    F.sum(\"total_pedidos\").alias(\"soma_pedidos\"),\n",
    "    F.sum(\"total_itens_vendidos\").alias(\"soma_itens_vendidos\"),\n",
    "    spark_round(F.sum(\"receita_total_brl\"), 2).alias(\"receita_acumulada_brl\"),\n",
    "    spark_round(F.sum(\"receita_total_usd\"), 2).alias(\"receita_acumulada_usd\"),\n",
    "    spark_round(F.avg(\"ticket_medio_brl\"), 2).alias(\"ticket_medio_geral_brl\"),\n",
    "    spark_round(F.avg(\"ticket_medio_usd\"), 2).alias(\"ticket_medio_geral_usd\"),\n",
    "    spark_round(F.avg(\"avaliacao_media\"), 2).alias(\"avaliacao_media_geral\")\n",
    ")\n",
    "display(df_sumario_final)\n",
    "\n",
    "print(\"\\n[ETAPA 3.7.8] Validacao final concluida\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5471777821580950,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "gold",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
